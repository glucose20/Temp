# üöÄ Quick Start - Ch·∫°y 60 Experiments tr√™n Server

## Setup ban ƒë·∫ßu (ch·ªâ 1 l·∫ßn)

```bash
# 1. Clone repo
git clone https://github.com/glucose20/Temp.git
cd Temp

# 2. Ch·∫°y script setup t·ª± ƒë·ªông
bash scripts/setup_server.sh

# 3. Test nhanh (2 epochs ƒë·ªÉ ki·ªÉm tra)
python code/train.py --fold 0 --cuda "0" --dataset davis --running_set warm --epochs 2
```

---

## Ch·∫°y T·∫§T C·∫¢ 60 experiments

### **C√°ch 1: Sequential (1 GPU, an to√†n nh·∫•t)**
```bash
# D√πng tmux ƒë·ªÉ tr√°nh disconnect
tmux new -s llmdta
bash scripts/run_all_experiments.sh

# Detach: Ctrl+B, D
# Reattach: tmux attach -t llmdta
```

### **C√°ch 2: Parallel (nhi·ªÅu GPU, nhanh nh·∫•t)**
```bash
# Edit s·ªë GPU tr∆∞·ªõc
nano scripts/run_all_experiments_parallel.sh
# S·ª≠a d√≤ng 12-13: NUM_GPUS=4 v√† GPU_DEVICES=(0 1 2 3)

# Ch·∫°y
tmux new -s llmdta
bash scripts/run_all_experiments_parallel.sh
```

### **C√°ch 3: T·ª´ng dataset (chia nh·ªè)**
```bash
# Terminal 1 (GPU 0)
CUDA_VISIBLE_DEVICES=0 bash scripts/run_single_dataset.sh davis

# Terminal 2 (GPU 1) 
CUDA_VISIBLE_DEVICES=1 bash scripts/run_single_dataset.sh kiba

# Terminal 3 (GPU 2)
CUDA_VISIBLE_DEVICES=2 bash scripts/run_single_dataset.sh metz
```

---

## Theo d√µi ti·∫øn ƒë·ªô

```bash
# Xem log real-time
tail -f ./results/experiment_master_log_*.txt

# GPU usage
watch -n 1 nvidia-smi

# ƒê·∫øm s·ªë runs ho√†n th√†nh
ls -1 ./savemodel/*.pth | wc -l  # M·ª•c ti√™u: 60 files
```

---

## T·ªïng h·ª£p k·∫øt qu·∫£ cu·ªëi

```bash
# T·∫°o b√°o c√°o t·ªïng h·ª£p
python code/generate_final_report.py

# Xem k·∫øt qu·∫£
cat ./log/FINAL_SUMMARY_REPORT_*.csv
```

---

## Th·ªùi gian ∆∞·ªõc t√≠nh

| Setup | Th·ªùi gian |
|-------|-----------|
| 1 GPU sequential | ~30-60 gi·ªù |
| 2 GPUs parallel | ~15-30 gi·ªù |
| 4 GPUs parallel | ~8-15 gi·ªù |

*M·ªói run: ~30-60 ph√∫t (t√πy early stopping)*

---

## Troubleshooting nhanh

```bash
# Out of memory ‚Üí gi·∫£m batch size
# Edit d√≤ng 8 trong script: BATCH_SIZE=8

# Xem l·ªói chi ti·∫øt
cat ./results/run_davis_warm_fold0.log

# Ch·∫°y l·∫°i 1 run c·ª• th·ªÉ
python code/train.py --fold 0 --cuda "0" --dataset davis --running_set warm --epochs 200 --batch_size 16
```

---

**ƒê·ªçc th√™m:** `EXPERIMENT_GUIDE.md` ƒë·ªÉ bi·∫øt chi ti·∫øt
