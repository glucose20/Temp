==========================================
Job ID: 2013094
Array Task ID: 4
Node: v100l-f-01
Start Time: Thu Nov 13 11:39:10 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 11:39:11 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:07:00.0 Off |                    0 |
| N/A   39C    P0             49W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 4...


============================================================
Starting training for Fold 4
Dataset: metz, Running Set: novel-pair
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 4 --cuda 0 --dataset metz --running_set novel-pair --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 4/4
Dataset: metz-novel-pair
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/metz/metz_drug_pretrain.pkl
Pretrain-./data/metz/metz_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run l8muknou
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_113917-l8muknou
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run metz-novel-pair-fold4
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/l8muknou
Weights & Biases initialized: LLMDTA
Loading fold 4 data...
  Train: ./data/dta-5fold-dataset/metz/novel-pair/fold_4_train.csv
  Valid: ./data/dta-5fold-dataset/metz/novel-pair/fold_4_valid.csv
  Test:  ./data/dta-5fold-dataset/metz/novel-pair/fold_4_test.csv
Dataset loaded: 12852 train, 16857 valid, 5550 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-4 epoch-1: mse-2.704657, rmse-1.644584, r2--0.183636
Valid at fold-4: mse-3.151854
Update best_mse, Valid at fold-4 epoch-1: mse-3.151854, rmse-1.775346, ci--1, r2--2.411736, pearson-0.383869, spearman-0.345585
Traing Log at fold-4 epoch-2: mse-0.977726, rmse-0.9888, r2--0.261394
Valid at fold-4: mse-1.061886
Update best_mse, Valid at fold-4 epoch-2: mse-1.061886, rmse-1.030479, ci--1, r2--0.149443, pearson-0.488753, spearman-0.484276
Traing Log at fold-4 epoch-3: mse-0.745932, rmse-0.863674, r2--0.145748
Valid at fold-4: mse-1.055947
Update best_mse, Valid at fold-4 epoch-3: mse-1.055947, rmse-1.027593, ci--1, r2--0.143014, pearson-0.446646, spearman-0.425135
Traing Log at fold-4 epoch-4: mse-0.662572, rmse-0.813985, r2--0.099344
Valid at fold-4: mse-0.754779
Update best_mse, Valid at fold-4 epoch-4: mse-0.754779, rmse-0.86878, ci--1, r2-0.182987, pearson-0.58867, spearman-0.541913
Traing Log at fold-4 epoch-5: mse-0.60771, rmse-0.779558, r2--0.044433
Valid at fold-4: mse-0.632877
Update best_mse, Valid at fold-4 epoch-5: mse-0.632877, rmse-0.795536, ci--1, r2-0.31494, pearson-0.590008, spearman-0.547775
Traing Log at fold-4 epoch-6: mse-0.556386, rmse-0.745913, r2--0.004864
Valid at fold-4: mse-0.627071
Update best_mse, Valid at fold-4 epoch-6: mse-0.627071, rmse-0.791878, ci--1, r2-0.321225, pearson-0.591815, spearman-0.553248
Traing Log at fold-4 epoch-7: mse-0.528431, rmse-0.726933, r2-0.044886
Valid at fold-4: mse-0.579892
Update best_mse, Valid at fold-4 epoch-7: mse-0.579892, rmse-0.761506, ci--1, r2-0.372294, pearson-0.641668, spearman-0.594196
Traing Log at fold-4 epoch-8: mse-0.472061, rmse-0.687067, r2-0.124847
Valid at fold-4: mse-0.593916
Traing Log at fold-4 epoch-9: mse-0.449359, rmse-0.670342, r2-0.172149
Valid at fold-4: mse-0.513211
Update best_mse, Valid at fold-4 epoch-9: mse-0.513211, rmse-0.716388, ci--1, r2-0.444473, pearson-0.670426, spearman-0.621332
Traing Log at fold-4 epoch-10: mse-0.424889, rmse-0.651835, r2-0.21033
Valid at fold-4: mse-0.561207
Traing Log at fold-4 epoch-11: mse-0.403933, rmse-0.635557, r2-0.264191
Valid at fold-4: mse-0.471355
Update best_mse, Valid at fold-4 epoch-11: mse-0.471355, rmse-0.686553, ci--1, r2-0.48978, pearson-0.700852, spearman-0.64511
Traing Log at fold-4 epoch-12: mse-0.388451, rmse-0.623258, r2-0.299773
Valid at fold-4: mse-0.481316
Traing Log at fold-4 epoch-13: mse-0.36806, rmse-0.60668, r2-0.347444
Valid at fold-4: mse-0.47867
Traing Log at fold-4 epoch-14: mse-0.352481, rmse-0.593701, r2-0.384145
Valid at fold-4: mse-0.463777
Update best_mse, Valid at fold-4 epoch-14: mse-0.463777, rmse-0.681012, ci--1, r2-0.497982, pearson-0.720713, spearman-0.664935
Traing Log at fold-4 epoch-15: mse-0.347779, rmse-0.589728, r2-0.39994
Valid at fold-4: mse-0.445681
Update best_mse, Valid at fold-4 epoch-15: mse-0.445681, rmse-0.667593, ci--1, r2-0.517571, pearson-0.721085, spearman-0.666821
Traing Log at fold-4 epoch-16: mse-0.330055, rmse-0.574504, r2-0.438432
Valid at fold-4: mse-0.432594
Update best_mse, Valid at fold-4 epoch-16: mse-0.432594, rmse-0.657719, ci--1, r2-0.531737, pearson-0.733012, spearman-0.682669
Traing Log at fold-4 epoch-17: mse-0.322535, rmse-0.567922, r2-0.456743
Valid at fold-4: mse-0.433034
Traing Log at fold-4 epoch-18: mse-0.310224, rmse-0.556977, r2-0.48674
Valid at fold-4: mse-0.442882
Traing Log at fold-4 epoch-19: mse-0.303644, rmse-0.551039, r2-0.507746
Valid at fold-4: mse-0.428812
Update best_mse, Valid at fold-4 epoch-19: mse-0.428812, rmse-0.654838, ci--1, r2-0.53583, pearson-0.741621, spearman-0.68894
Traing Log at fold-4 epoch-20: mse-0.291018, rmse-0.539461, r2-0.529338
Valid at fold-4: mse-0.440839
Traing Log at fold-4 epoch-21: mse-0.280889, rmse-0.529989, r2-0.551685
Valid at fold-4: mse-0.432322
Traing Log at fold-4 epoch-22: mse-0.278583, rmse-0.52781, r2-0.560681
Valid at fold-4: mse-0.425427
Update best_mse, Valid at fold-4 epoch-22: mse-0.425427, rmse-0.652247, ci--1, r2-0.539495, pearson-0.738289, spearman-0.690357
Traing Log at fold-4 epoch-23: mse-0.265117, rmse-0.514895, r2-0.587418
Valid at fold-4: mse-0.408548
Update best_mse, Valid at fold-4 epoch-23: mse-0.408548, rmse-0.639178, ci--1, r2-0.557766, pearson-0.748804, spearman-0.697275
Traing Log at fold-4 epoch-24: mse-0.255439, rmse-0.50541, r2-0.608381
Valid at fold-4: mse-0.430951
Traing Log at fold-4 epoch-25: mse-0.249871, rmse-0.499871, r2-0.62061
Valid at fold-4: mse-0.415123
Traing Log at fold-4 epoch-26: mse-0.243707, rmse-0.493667, r2-0.630823
Valid at fold-4: mse-0.396131
Update best_mse, Valid at fold-4 epoch-26: mse-0.396131, rmse-0.629389, ci--1, r2-0.571207, pearson-0.758552, spearman-0.706153
Traing Log at fold-4 epoch-27: mse-0.238276, rmse-0.488136, r2-0.641255
Valid at fold-4: mse-0.410766
Traing Log at fold-4 epoch-28: mse-0.230441, rmse-0.480043, r2-0.658113
Valid at fold-4: mse-0.409195
Traing Log at fold-4 epoch-29: mse-0.221812, rmse-0.470969, r2-0.675373
Valid at fold-4: mse-0.395686
Update best_mse, Valid at fold-4 epoch-29: mse-0.395686, rmse-0.629035, ci--1, r2-0.571689, pearson-0.759933, spearman-0.707685
Traing Log at fold-4 epoch-30: mse-0.213207, rmse-0.461743, r2-0.691431
Valid at fold-4: mse-0.39768
Traing Log at fold-4 epoch-31: mse-0.214604, rmse-0.463253, r2-0.689636
Valid at fold-4: mse-0.404543
Traing Log at fold-4 epoch-32: mse-0.210942, rmse-0.459284, r2-0.695961
Valid at fold-4: mse-0.388304
Update best_mse, Valid at fold-4 epoch-32: mse-0.388304, rmse-0.62314, ci--1, r2-0.579679, pearson-0.764195, spearman-0.716938
Traing Log at fold-4 epoch-33: mse-0.203475, rmse-0.451082, r2-0.710675
Valid at fold-4: mse-0.406237
Traing Log at fold-4 epoch-34: mse-0.201901, rmse-0.449334, r2-0.712771
Valid at fold-4: mse-0.383816
Update best_mse, Valid at fold-4 epoch-34: mse-0.383816, rmse-0.619529, ci--1, r2-0.584536, pearson-0.768038, spearman-0.714531
Traing Log at fold-4 epoch-35: mse-0.194, rmse-0.440454, r2-0.727188
Valid at fold-4: mse-0.39921
Traing Log at fold-4 epoch-36: mse-0.191026, rmse-0.437065, r2-0.732708
Valid at fold-4: mse-0.381074
Update best_mse, Valid at fold-4 epoch-36: mse-0.381074, rmse-0.617312, ci--1, r2-0.587505, pearson-0.770495, spearman-0.721708
Traing Log at fold-4 epoch-37: mse-0.188311, rmse-0.433948, r2-0.736463
Valid at fold-4: mse-0.387081
Traing Log at fold-4 epoch-38: mse-0.181035, rmse-0.425482, r2-0.749484
Valid at fold-4: mse-0.387345
Traing Log at fold-4 epoch-39: mse-0.174692, rmse-0.417962, r2-0.760104
Valid at fold-4: mse-0.379769
Update best_mse, Valid at fold-4 epoch-39: mse-0.379769, rmse-0.616254, ci--1, r2-0.588917, pearson-0.77489, spearman-0.7285
Traing Log at fold-4 epoch-40: mse-0.174242, rmse-0.417422, r2-0.762302
Valid at fold-4: mse-0.389721
Traing Log at fold-4 epoch-41: mse-0.166218, rmse-0.407699, r2-0.773505
Valid at fold-4: mse-0.384013
Traing Log at fold-4 epoch-42: mse-0.165429, rmse-0.406729, r2-0.777589
Valid at fold-4: mse-0.377336
Update best_mse, Valid at fold-4 epoch-42: mse-0.377336, rmse-0.614277, ci--1, r2-0.591551, pearson-0.773813, spearman-0.722946
Traing Log at fold-4 epoch-43: mse-0.157595, rmse-0.396982, r2-0.787893
Valid at fold-4: mse-0.384104
Traing Log at fold-4 epoch-44: mse-0.160181, rmse-0.400226, r2-0.784413
Valid at fold-4: mse-0.378815
Traing Log at fold-4 epoch-45: mse-0.155573, rmse-0.394427, r2-0.792546
Valid at fold-4: mse-0.379927
Traing Log at fold-4 epoch-46: mse-0.15003, rmse-0.387337, r2-0.801711
Valid at fold-4: mse-0.38677
Traing Log at fold-4 epoch-47: mse-0.149512, rmse-0.386667, r2-0.801555
Valid at fold-4: mse-0.391532
Traing Log at fold-4 epoch-48: mse-0.145467, rmse-0.381401, r2-0.80819
Valid at fold-4: mse-0.382426
Traing Log at fold-4 epoch-49: mse-0.144079, rmse-0.379578, r2-0.811068
Valid at fold-4: mse-0.389516
Traing Log at fold-4 epoch-50: mse-0.137456, rmse-0.370751, r2-0.819987
Valid at fold-4: mse-0.393777
Traing Log at fold-4 epoch-51: mse-0.141598, rmse-0.376294, r2-0.814433
Valid at fold-4: mse-0.380057
Traing Log at fold-4 epoch-52: mse-0.135651, rmse-0.368308, r2-0.823883
Valid at fold-4: mse-0.399254
Traing Log at fold-4 epoch-53: mse-0.135177, rmse-0.367665, r2-0.824278
Valid at fold-4: mse-0.381069
Traing Log at fold-4 epoch-54: mse-0.129525, rmse-0.359896, r2-0.83261
Valid at fold-4: mse-0.380373
Traing Log at fold-4 epoch-55: mse-0.128998, rmse-0.359162, r2-0.833965
Valid at fold-4: mse-0.385585
Traing Log at fold-4 epoch-56: mse-0.126777, rmse-0.356058, r2-0.837486
Valid at fold-4: mse-0.383669
Traing Log at fold-4 epoch-57: mse-0.121908, rmse-0.349154, r2-0.844065
Valid at fold-4: mse-0.368419
Update best_mse, Valid at fold-4 epoch-57: mse-0.368419, rmse-0.606975, ci--1, r2-0.601204, pearson-0.780263, spearman-0.730638
Traing Log at fold-4 epoch-58: mse-0.120549, rmse-0.347202, r2-0.846694
Valid at fold-4: mse-0.387802
Traing Log at fold-4 epoch-59: mse-0.123746, rmse-0.351775, r2-0.841483
Valid at fold-4: mse-0.379959
Traing Log at fold-4 epoch-60: mse-0.117039, rmse-0.342109, r2-0.851178
Valid at fold-4: mse-0.369069
Traing Log at fold-4 epoch-61: mse-0.115433, rmse-0.339755, r2-0.853276
Valid at fold-4: mse-0.384616
Traing Log at fold-4 epoch-62: mse-0.114722, rmse-0.338707, r2-0.855495
Valid at fold-4: mse-0.363172
Update best_mse, Valid at fold-4 epoch-62: mse-0.363172, rmse-0.602637, ci--1, r2-0.606883, pearson-0.784394, spearman-0.735799
Traing Log at fold-4 epoch-63: mse-0.112958, rmse-0.336092, r2-0.857137
Valid at fold-4: mse-0.385681
Traing Log at fold-4 epoch-64: mse-0.111097, rmse-0.333311, r2-0.860248
Valid at fold-4: mse-0.37891
Traing Log at fold-4 epoch-65: mse-0.106951, rmse-0.327034, r2-0.865859
Valid at fold-4: mse-0.375377
Traing Log at fold-4 epoch-66: mse-0.107092, rmse-0.327249, r2-0.866049
Valid at fold-4: mse-0.366255
Traing Log at fold-4 epoch-67: mse-0.105625, rmse-0.325, r2-0.868014
Valid at fold-4: mse-0.366793
Traing Log at fold-4 epoch-68: mse-0.104434, rmse-0.323162, r2-0.869129
Valid at fold-4: mse-0.370087
Traing Log at fold-4 epoch-69: mse-0.099203, rmse-0.314965, r2-0.877091
Valid at fold-4: mse-0.373404
Traing Log at fold-4 epoch-70: mse-0.100011, rmse-0.316245, r2-0.875861
Valid at fold-4: mse-0.358291
Update best_mse, Valid at fold-4 epoch-70: mse-0.358291, rmse-0.598575, ci--1, r2-0.612166, pearson-0.789549, spearman-0.743416
Traing Log at fold-4 epoch-71: mse-0.098022, rmse-0.313085, r2-0.87859
Valid at fold-4: mse-0.361661
Traing Log at fold-4 epoch-72: mse-0.097514, rmse-0.312272, r2-0.879123
Valid at fold-4: mse-0.369885
Traing Log at fold-4 epoch-73: mse-0.096926, rmse-0.311329, r2-0.87973
Valid at fold-4: mse-0.369276
Traing Log at fold-4 epoch-74: mse-0.096306, rmse-0.310332, r2-0.88173
Valid at fold-4: mse-0.358633
Traing Log at fold-4 epoch-75: mse-0.093311, rmse-0.305468, r2-0.884758
Valid at fold-4: mse-0.366055
Traing Log at fold-4 epoch-76: mse-0.092638, rmse-0.304366, r2-0.885955
Valid at fold-4: mse-0.354075
Update best_mse, Valid at fold-4 epoch-76: mse-0.354075, rmse-0.595042, ci--1, r2-0.61673, pearson-0.79162, spearman-0.743802
Traing Log at fold-4 epoch-77: mse-0.089331, rmse-0.298882, r2-0.890519
Valid at fold-4: mse-0.366522
Traing Log at fold-4 epoch-78: mse-0.092545, rmse-0.304212, r2-0.886459
Valid at fold-4: mse-0.370897
Traing Log at fold-4 epoch-79: mse-0.088854, rmse-0.298084, r2-0.891425
Valid at fold-4: mse-0.368797
Traing Log at fold-4 epoch-80: mse-0.086972, rmse-0.29491, r2-0.893745
Valid at fold-4: mse-0.365454
Traing Log at fold-4 epoch-81: mse-0.08478, rmse-0.29117, r2-0.896854
Valid at fold-4: mse-0.362174
Traing Log at fold-4 epoch-82: mse-0.086352, rmse-0.293857, r2-0.894478
Valid at fold-4: mse-0.365807
Traing Log at fold-4 epoch-83: mse-0.083348, rmse-0.288701, r2-0.898709
Valid at fold-4: mse-0.378626
Traing Log at fold-4 epoch-84: mse-0.085182, rmse-0.29186, r2-0.895835
Valid at fold-4: mse-0.36591
Traing Log at fold-4 epoch-85: mse-0.082011, rmse-0.286376, r2-0.900403
Valid at fold-4: mse-0.358147
Traing Log at fold-4 epoch-86: mse-0.081015, rmse-0.284631, r2-0.901682
Valid at fold-4: mse-0.3645
Traing Log at fold-4 epoch-87: mse-0.081118, rmse-0.284813, r2-0.901893
Valid at fold-4: mse-0.360546
Traing Log at fold-4 epoch-88: mse-0.079441, rmse-0.281853, r2-0.903879
Valid at fold-4: mse-0.353612
Update best_mse, Valid at fold-4 epoch-88: mse-0.353612, rmse-0.594653, ci--1, r2-0.617231, pearson-0.793266, spearman-0.748117
Traing Log at fold-4 epoch-89: mse-0.079062, rmse-0.28118, r2-0.90438
Valid at fold-4: mse-0.356982
Traing Log at fold-4 epoch-90: mse-0.079015, rmse-0.281096, r2-0.904432
Valid at fold-4: mse-0.35873
Traing Log at fold-4 epoch-91: mse-0.078378, rmse-0.27996, r2-0.905274
Valid at fold-4: mse-0.36178
Traing Log at fold-4 epoch-92: mse-0.075489, rmse-0.274752, r2-0.909068
Valid at fold-4: mse-0.35551
Traing Log at fold-4 epoch-93: mse-0.074245, rmse-0.27248, r2-0.91064
Valid at fold-4: mse-0.361611
Traing Log at fold-4 epoch-94: mse-0.074532, rmse-0.273006, r2-0.91033
Valid at fold-4: mse-0.357304
Traing Log at fold-4 epoch-95: mse-0.074163, rmse-0.272329, r2-0.910795
Valid at fold-4: mse-0.36362
Traing Log at fold-4 epoch-96: mse-0.072279, rmse-0.268847, r2-0.913337
Valid at fold-4: mse-0.354854
Traing Log at fold-4 epoch-97: mse-0.072291, rmse-0.26887, r2-0.913391
Valid at fold-4: mse-0.359646
Traing Log at fold-4 epoch-98: mse-0.07163, rmse-0.267637, r2-0.914052
Valid at fold-4: mse-0.366471
Traing Log at fold-4 epoch-99: mse-0.072837, rmse-0.269884, r2-0.912617
Valid at fold-4: mse-0.378574
Traing Log at fold-4 epoch-100: mse-0.069768, rmse-0.264135, r2-0.916419
Valid at fold-4: mse-0.360381
Traing Log at fold-4 epoch-101: mse-0.068495, rmse-0.261715, r2-0.918436
Valid at fold-4: mse-0.361749
Traing Log at fold-4 epoch-102: mse-0.069275, rmse-0.263202, r2-0.91711
Valid at fold-4: mse-0.370311
Traing Log at fold-4 epoch-103: mse-0.069904, rmse-0.264395, r2-0.916408
Valid at fold-4: mse-0.358894
Traing Log at fold-4 epoch-104: mse-0.068071, rmse-0.260904, r2-0.918884
Valid at fold-4: mse-0.361165
Traing Log at fold-4 epoch-105: mse-0.068247, rmse-0.261241, r2-0.918378
Valid at fold-4: mse-0.362547
Traing Log at fold-4 epoch-106: mse-0.065239, rmse-0.25542, r2-0.922433
Valid at fold-4: mse-0.356147
Traing Log at fold-4 epoch-107: mse-0.066516, rmse-0.257907, r2-0.920852
Valid at fold-4: mse-0.352437
Update best_mse, Valid at fold-4 epoch-107: mse-0.352437, rmse-0.593664, ci--1, r2-0.618503, pearson-0.789898, spearman-0.743314
Traing Log at fold-4 epoch-108: mse-0.066868, rmse-0.258588, r2-0.919979
Valid at fold-4: mse-0.36072
Traing Log at fold-4 epoch-109: mse-0.064968, rmse-0.254888, r2-0.923059
Valid at fold-4: mse-0.352137
Update best_mse, Valid at fold-4 epoch-109: mse-0.352137, rmse-0.593412, ci--1, r2-0.618828, pearson-0.79445, spearman-0.747194
Traing Log at fold-4 epoch-110: mse-0.064195, rmse-0.253367, r2-0.923896
Valid at fold-4: mse-0.352065
Update best_mse, Valid at fold-4 epoch-110: mse-0.352065, rmse-0.59335, ci--1, r2-0.618906, pearson-0.792092, spearman-0.748521
Traing Log at fold-4 epoch-111: mse-0.064542, rmse-0.254052, r2-0.923008
Valid at fold-4: mse-0.355954
Traing Log at fold-4 epoch-112: mse-0.062493, rmse-0.249986, r2-0.925946
Valid at fold-4: mse-0.358662
Traing Log at fold-4 epoch-113: mse-0.063332, rmse-0.251658, r2-0.924821
Valid at fold-4: mse-0.356502
Traing Log at fold-4 epoch-114: mse-0.06343, rmse-0.251853, r2-0.924709
Valid at fold-4: mse-0.353159
Traing Log at fold-4 epoch-115: mse-0.061201, rmse-0.247389, r2-0.927589
Valid at fold-4: mse-0.357832
Traing Log at fold-4 epoch-116: mse-0.061236, rmse-0.247458, r2-0.927639
Valid at fold-4: mse-0.346761
Update best_mse, Valid at fold-4 epoch-116: mse-0.346761, rmse-0.588865, ci--1, r2-0.624647, pearson-0.793303, spearman-0.747701
Traing Log at fold-4 epoch-117: mse-0.062892, rmse-0.250782, r2-0.92547
Valid at fold-4: mse-0.358295
Traing Log at fold-4 epoch-118: mse-0.062037, rmse-0.249072, r2-0.926626
Valid at fold-4: mse-0.352859
Traing Log at fold-4 epoch-119: mse-0.060964, rmse-0.246908, r2-0.927742
Valid at fold-4: mse-0.351209
Traing Log at fold-4 epoch-120: mse-0.06027, rmse-0.245499, r2-0.9287
Valid at fold-4: mse-0.352259
Traing Log at fold-4 epoch-121: mse-0.059879, rmse-0.244701, r2-0.929259
Valid at fold-4: mse-0.346365
Update best_mse, Valid at fold-4 epoch-121: mse-0.346365, rmse-0.588527, ci--1, r2-0.625076, pearson-0.796683, spearman-0.75174
Traing Log at fold-4 epoch-122: mse-0.059692, rmse-0.244319, r2-0.929549
Valid at fold-4: mse-0.352096
Traing Log at fold-4 epoch-123: mse-0.057733, rmse-0.240277, r2-0.931963
Valid at fold-4: mse-0.346428
Traing Log at fold-4 epoch-124: mse-0.05799, rmse-0.240812, r2-0.931448
Valid at fold-4: mse-0.355089
Traing Log at fold-4 epoch-125: mse-0.056687, rmse-0.238089, r2-0.933312
Valid at fold-4: mse-0.348559
Traing Log at fold-4 epoch-126: mse-0.057626, rmse-0.240054, r2-0.932194
Valid at fold-4: mse-0.348594
Traing Log at fold-4 epoch-127: mse-0.056675, rmse-0.238064, r2-0.933048
Valid at fold-4: mse-0.350543
Traing Log at fold-4 epoch-128: mse-0.057209, rmse-0.239183, r2-0.932692
Valid at fold-4: mse-0.354166
Traing Log at fold-4 epoch-129: mse-0.055062, rmse-0.234654, r2-0.935281
Valid at fold-4: mse-0.341103
Update best_mse, Valid at fold-4 epoch-129: mse-0.341103, rmse-0.58404, ci--1, r2-0.630771, pearson-0.799022, spearman-0.753175
Traing Log at fold-4 epoch-130: mse-0.054691, rmse-0.233862, r2-0.935798
Valid at fold-4: mse-0.346966
Traing Log at fold-4 epoch-131: mse-0.055567, rmse-0.235726, r2-0.934649
Valid at fold-4: mse-0.352153
Traing Log at fold-4 epoch-132: mse-0.055067, rmse-0.234664, r2-0.935364
Valid at fold-4: mse-0.360763
Traing Log at fold-4 epoch-133: mse-0.05269, rmse-0.229543, r2-0.938087
Valid at fold-4: mse-0.358996
Traing Log at fold-4 epoch-134: mse-0.054583, rmse-0.233631, r2-0.935988
Valid at fold-4: mse-0.344848
Traing Log at fold-4 epoch-135: mse-0.053296, rmse-0.230859, r2-0.937457
Valid at fold-4: mse-0.353952
Traing Log at fold-4 epoch-136: mse-0.053258, rmse-0.230778, r2-0.937497
Valid at fold-4: mse-0.347714
Traing Log at fold-4 epoch-137: mse-0.052635, rmse-0.229423, r2-0.938347
Valid at fold-4: mse-0.362638
Traing Log at fold-4 epoch-138: mse-0.051072, rmse-0.225991, r2-0.940176
Valid at fold-4: mse-0.350483
Traing Log at fold-4 epoch-139: mse-0.051649, rmse-0.227264, r2-0.939614
Valid at fold-4: mse-0.353478
Traing Log at fold-4 epoch-140: mse-0.050934, rmse-0.225685, r2-0.940478
Valid at fold-4: mse-0.344489
Traing Log at fold-4 epoch-141: mse-0.051893, rmse-0.227801, r2-0.939257
Valid at fold-4: mse-0.357235
Traing Log at fold-4 epoch-142: mse-0.053272, rmse-0.230807, r2-0.937519
Valid at fold-4: mse-0.349673
Traing Log at fold-4 epoch-143: mse-0.051194, rmse-0.226262, r2-0.940105
Valid at fold-4: mse-0.345992
Traing Log at fold-4 epoch-144: mse-0.04978, rmse-0.223115, r2-0.941909
Valid at fold-4: mse-0.353868
Traing Log at fold-4 epoch-145: mse-0.048855, rmse-0.221033, r2-0.94298
Valid at fold-4: mse-0.341814
Traing Log at fold-4 epoch-146: mse-0.051665, rmse-0.2273, r2-0.939562
Valid at fold-4: mse-0.344438
Traing Log at fold-4 epoch-147: mse-0.050121, rmse-0.223877, r2-0.941301
Valid at fold-4: mse-0.355284
Traing Log at fold-4 epoch-148: mse-0.049136, rmse-0.221667, r2-0.942666
Valid at fold-4: mse-0.348386
Traing Log at fold-4 epoch-149: mse-0.049843, rmse-0.223256, r2-0.941814
Valid at fold-4: mse-0.35654
Traing Log at fold-4 epoch-150: mse-0.04856, rmse-0.220362, r2-0.943349
Valid at fold-4: mse-0.35089
Traing stop at epoch-150, model save at-./savemodel/metz-novel-pair-fold4-Nov13_11-39-17.pth
Save log over at ./log/Nov13_11-39-17-metz-novel-pair-fold4.csv

============================================================
Testing fold 4 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-4, mse: 0.646541, rmse: 0.804077, ci: 0.677017, r2: 0.313348, pearson: 0.572558, spearman: 0.489526

Fold 4 results saved to: ./log/Test-metz-novel-pair-fold4-Nov13_11-39-17.csv
============================================================
Training fold 4 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 333-333, summary, console lines 349-354
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–ƒâ–‚â–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–ƒâ–‚â–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.3411
wandb:  best_valid/pearson 0.79902
wandb:       best_valid/r2 0.63077
wandb:     best_valid/rmse 0.58404
wandb: best_valid/spearman 0.75318
wandb:               epoch 150
wandb:       final_test_ci 0.67702
wandb:      final_test_mse 0.64654
wandb:  final_test_pearson 0.57256
wandb:       final_test_r2 0.31335
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run metz-novel-pair-fold4 at: https://wandb.ai/tringuyen/LLMDTA/runs/l8muknou
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_113917-l8muknou/logs
Weights & Biases run finished

Training for fold 4 completed successfully.
Python script exit code: 0
==========================================
End Time: Thu Nov 13 08:14:30 PM AEDT 2025
==========================================
