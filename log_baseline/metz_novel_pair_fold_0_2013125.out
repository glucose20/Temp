==========================================
Job ID: 2013125
Array Task ID: 0
Node: v100l-f-03
Start Time: Thu Nov 13 10:59:15 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 10:59:16 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:07:00.0 Off |                    0 |
| N/A   39C    P0             49W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 0...


============================================================
Starting training for Fold 0
Dataset: metz, Running Set: novel-pair
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 0 --cuda 0 --dataset metz --running_set novel-pair --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 0/4
Dataset: metz-novel-pair
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/metz/metz_drug_pretrain.pkl
Pretrain-./data/metz/metz_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run q8iinlup
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_105924-q8iinlup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run metz-novel-pair-fold0
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/q8iinlup
Weights & Biases initialized: LLMDTA
Loading fold 0 data...
  Train: ./data/dta-5fold-dataset/metz/novel-pair/fold_0_train.csv
  Valid: ./data/dta-5fold-dataset/metz/novel-pair/fold_0_valid.csv
  Test:  ./data/dta-5fold-dataset/metz/novel-pair/fold_0_test.csv
Dataset loaded: 13055 train, 16747 valid, 5457 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-0 epoch-1: mse-2.720763, rmse-1.649474, r2--0.177761
Valid at fold-0: mse-1.909769
Update best_mse, Valid at fold-0 epoch-1: mse-1.909769, rmse-1.381944, ci--1, r2--1.069721, pearson-0.156572, spearman-0.144998
Traing Log at fold-0 epoch-2: mse-0.984183, rmse-0.99206, r2--0.209641
Valid at fold-0: mse-1.443001
Update best_mse, Valid at fold-0 epoch-2: mse-1.443001, rmse-1.20125, ci--1, r2--0.563859, pearson-0.440054, spearman-0.413555
Traing Log at fold-0 epoch-3: mse-0.710163, rmse-0.842711, r2--0.096383
Valid at fold-0: mse-1.188611
Update best_mse, Valid at fold-0 epoch-3: mse-1.188611, rmse-1.090234, ci--1, r2--0.288163, pearson-0.439963, spearman-0.422794
Traing Log at fold-0 epoch-4: mse-0.628158, rmse-0.792564, r2--0.026751
Valid at fold-0: mse-1.078241
Update best_mse, Valid at fold-0 epoch-4: mse-1.078241, rmse-1.038384, ci--1, r2--0.168549, pearson-0.502659, spearman-0.471332
Traing Log at fold-0 epoch-5: mse-0.570451, rmse-0.755282, r2--0.003429
Valid at fold-0: mse-0.699198
Update best_mse, Valid at fold-0 epoch-5: mse-0.699198, rmse-0.836181, ci--1, r2-0.242241, pearson-0.568072, spearman-0.516842
Traing Log at fold-0 epoch-6: mse-0.531442, rmse-0.729001, r2-0.062037
Valid at fold-0: mse-0.636215
Update best_mse, Valid at fold-0 epoch-6: mse-0.636215, rmse-0.797631, ci--1, r2-0.310499, pearson-0.566054, spearman-0.535688
Traing Log at fold-0 epoch-7: mse-0.490571, rmse-0.700408, r2-0.107205
Valid at fold-0: mse-0.608977
Update best_mse, Valid at fold-0 epoch-7: mse-0.608977, rmse-0.78037, ci--1, r2-0.340019, pearson-0.615048, spearman-0.576956
Traing Log at fold-0 epoch-8: mse-0.462488, rmse-0.680065, r2-0.144863
Valid at fold-0: mse-0.633858
Traing Log at fold-0 epoch-9: mse-0.432971, rmse-0.658005, r2-0.198906
Valid at fold-0: mse-0.607434
Update best_mse, Valid at fold-0 epoch-9: mse-0.607434, rmse-0.77938, ci--1, r2-0.341691, pearson-0.614309, spearman-0.563145
Traing Log at fold-0 epoch-10: mse-0.412512, rmse-0.642271, r2-0.233196
Valid at fold-0: mse-0.579385
Update best_mse, Valid at fold-0 epoch-10: mse-0.579385, rmse-0.761174, ci--1, r2-0.372089, pearson-0.629717, spearman-0.580686
Traing Log at fold-0 epoch-11: mse-0.388825, rmse-0.623558, r2-0.287332
Valid at fold-0: mse-0.531435
Update best_mse, Valid at fold-0 epoch-11: mse-0.531435, rmse-0.728996, ci--1, r2-0.424054, pearson-0.654553, spearman-0.602888
Traing Log at fold-0 epoch-12: mse-0.374725, rmse-0.612147, r2-0.315334
Valid at fold-0: mse-0.540382
Traing Log at fold-0 epoch-13: mse-0.354519, rmse-0.595415, r2-0.362351
Valid at fold-0: mse-0.538355
Traing Log at fold-0 epoch-14: mse-0.344623, rmse-0.587046, r2-0.382778
Valid at fold-0: mse-0.48717
Update best_mse, Valid at fold-0 epoch-14: mse-0.48717, rmse-0.697976, ci--1, r2-0.472027, pearson-0.68802, spearman-0.639824
Traing Log at fold-0 epoch-15: mse-0.3308, rmse-0.575153, r2-0.421628
Valid at fold-0: mse-0.515099
Traing Log at fold-0 epoch-16: mse-0.319025, rmse-0.564823, r2-0.444975
Valid at fold-0: mse-0.503584
Traing Log at fold-0 epoch-17: mse-0.307331, rmse-0.554374, r2-0.481161
Valid at fold-0: mse-0.523838
Traing Log at fold-0 epoch-18: mse-0.300134, rmse-0.547845, r2-0.48982
Valid at fold-0: mse-0.52014
Traing Log at fold-0 epoch-19: mse-0.288733, rmse-0.537339, r2-0.520326
Valid at fold-0: mse-0.478597
Update best_mse, Valid at fold-0 epoch-19: mse-0.478597, rmse-0.691807, ci--1, r2-0.481318, pearson-0.696284, spearman-0.650147
Traing Log at fold-0 epoch-20: mse-0.274071, rmse-0.523518, r2-0.552355
Valid at fold-0: mse-0.482015
Traing Log at fold-0 epoch-21: mse-0.273494, rmse-0.522967, r2-0.554224
Valid at fold-0: mse-0.471514
Update best_mse, Valid at fold-0 epoch-21: mse-0.471514, rmse-0.686669, ci--1, r2-0.488995, pearson-0.703083, spearman-0.65736
Traing Log at fold-0 epoch-22: mse-0.263772, rmse-0.513587, r2-0.574955
Valid at fold-0: mse-0.465681
Update best_mse, Valid at fold-0 epoch-22: mse-0.465681, rmse-0.682408, ci--1, r2-0.495317, pearson-0.714382, spearman-0.666824
Traing Log at fold-0 epoch-23: mse-0.254771, rmse-0.504749, r2-0.595321
Valid at fold-0: mse-0.476335
Traing Log at fold-0 epoch-24: mse-0.250328, rmse-0.500328, r2-0.604958
Valid at fold-0: mse-0.449568
Update best_mse, Valid at fold-0 epoch-24: mse-0.449568, rmse-0.670498, ci--1, r2-0.512779, pearson-0.719972, spearman-0.675833
Traing Log at fold-0 epoch-25: mse-0.239923, rmse-0.48982, r2-0.627472
Valid at fold-0: mse-0.464782
Traing Log at fold-0 epoch-26: mse-0.232958, rmse-0.482657, r2-0.641777
Valid at fold-0: mse-0.465905
Traing Log at fold-0 epoch-27: mse-0.227053, rmse-0.476501, r2-0.654625
Valid at fold-0: mse-0.447925
Update best_mse, Valid at fold-0 epoch-27: mse-0.447925, rmse-0.669272, ci--1, r2-0.51456, pearson-0.723, spearman-0.674865
Traing Log at fold-0 epoch-28: mse-0.224411, rmse-0.47372, r2-0.660012
Valid at fold-0: mse-0.44251
Update best_mse, Valid at fold-0 epoch-28: mse-0.44251, rmse-0.665214, ci--1, r2-0.520428, pearson-0.72891, spearman-0.683694
Traing Log at fold-0 epoch-29: mse-0.217887, rmse-0.466784, r2-0.672657
Valid at fold-0: mse-0.456103
Traing Log at fold-0 epoch-30: mse-0.208491, rmse-0.456608, r2-0.690648
Valid at fold-0: mse-0.450515
Traing Log at fold-0 epoch-31: mse-0.20353, rmse-0.451143, r2-0.699812
Valid at fold-0: mse-0.446934
Traing Log at fold-0 epoch-32: mse-0.202783, rmse-0.450314, r2-0.702397
Valid at fold-0: mse-0.45007
Traing Log at fold-0 epoch-33: mse-0.190122, rmse-0.43603, r2-0.723957
Valid at fold-0: mse-0.446686
Traing Log at fold-0 epoch-34: mse-0.189086, rmse-0.43484, r2-0.726437
Valid at fold-0: mse-0.437625
Update best_mse, Valid at fold-0 epoch-34: mse-0.437625, rmse-0.661532, ci--1, r2-0.525722, pearson-0.731076, spearman-0.688637
Traing Log at fold-0 epoch-35: mse-0.189789, rmse-0.435648, r2-0.726703
Valid at fold-0: mse-0.431045
Update best_mse, Valid at fold-0 epoch-35: mse-0.431045, rmse-0.65654, ci--1, r2-0.532854, pearson-0.737555, spearman-0.695645
Traing Log at fold-0 epoch-36: mse-0.180022, rmse-0.42429, r2-0.743199
Valid at fold-0: mse-0.442639
Traing Log at fold-0 epoch-37: mse-0.176023, rmse-0.419551, r2-0.749308
Valid at fold-0: mse-0.445588
Traing Log at fold-0 epoch-38: mse-0.173188, rmse-0.416159, r2-0.755532
Valid at fold-0: mse-0.443403
Traing Log at fold-0 epoch-39: mse-0.169698, rmse-0.411944, r2-0.763127
Valid at fold-0: mse-0.445372
Traing Log at fold-0 epoch-40: mse-0.164564, rmse-0.405665, r2-0.770046
Valid at fold-0: mse-0.432902
Traing Log at fold-0 epoch-41: mse-0.162992, rmse-0.403722, r2-0.772591
Valid at fold-0: mse-0.437853
Traing Log at fold-0 epoch-42: mse-0.155717, rmse-0.394609, r2-0.785312
Valid at fold-0: mse-0.444932
Traing Log at fold-0 epoch-43: mse-0.155393, rmse-0.394199, r2-0.785898
Valid at fold-0: mse-0.428291
Update best_mse, Valid at fold-0 epoch-43: mse-0.428291, rmse-0.65444, ci--1, r2-0.535838, pearson-0.738879, spearman-0.697898
Traing Log at fold-0 epoch-44: mse-0.150847, rmse-0.388391, r2-0.793159
Valid at fold-0: mse-0.439687
Traing Log at fold-0 epoch-45: mse-0.146779, rmse-0.383117, r2-0.800113
Valid at fold-0: mse-0.428031
Update best_mse, Valid at fold-0 epoch-45: mse-0.428031, rmse-0.654241, ci--1, r2-0.536119, pearson-0.735712, spearman-0.692702
Traing Log at fold-0 epoch-46: mse-0.14519, rmse-0.381038, r2-0.802711
Valid at fold-0: mse-0.427453
Update best_mse, Valid at fold-0 epoch-46: mse-0.427453, rmse-0.653799, ci--1, r2-0.536746, pearson-0.740147, spearman-0.697585
Traing Log at fold-0 epoch-47: mse-0.140689, rmse-0.375086, r2-0.809957
Valid at fold-0: mse-0.422907
Update best_mse, Valid at fold-0 epoch-47: mse-0.422907, rmse-0.650313, ci--1, r2-0.541672, pearson-0.743707, spearman-0.703705
Traing Log at fold-0 epoch-48: mse-0.140997, rmse-0.375496, r2-0.809249
Valid at fold-0: mse-0.428667
Traing Log at fold-0 epoch-49: mse-0.135576, rmse-0.368207, r2-0.818894
Valid at fold-0: mse-0.422904
Update best_mse, Valid at fold-0 epoch-49: mse-0.422904, rmse-0.650311, ci--1, r2-0.541676, pearson-0.745785, spearman-0.705531
Traing Log at fold-0 epoch-50: mse-0.135936, rmse-0.368695, r2-0.817628
Valid at fold-0: mse-0.429932
Traing Log at fold-0 epoch-51: mse-0.131971, rmse-0.363278, r2-0.82415
Valid at fold-0: mse-0.414706
Update best_mse, Valid at fold-0 epoch-51: mse-0.414706, rmse-0.643977, ci--1, r2-0.55056, pearson-0.750455, spearman-0.705754
Traing Log at fold-0 epoch-52: mse-0.127687, rmse-0.357333, r2-0.829853
Valid at fold-0: mse-0.421043
Traing Log at fold-0 epoch-53: mse-0.122852, rmse-0.350502, r2-0.838044
Valid at fold-0: mse-0.42074
Traing Log at fold-0 epoch-54: mse-0.123128, rmse-0.350896, r2-0.838044
Valid at fold-0: mse-0.414777
Traing Log at fold-0 epoch-55: mse-0.119314, rmse-0.345419, r2-0.843466
Valid at fold-0: mse-0.420051
Traing Log at fold-0 epoch-56: mse-0.122364, rmse-0.349805, r2-0.839067
Valid at fold-0: mse-0.41171
Update best_mse, Valid at fold-0 epoch-56: mse-0.41171, rmse-0.641647, ci--1, r2-0.553807, pearson-0.751167, spearman-0.712277
Traing Log at fold-0 epoch-57: mse-0.117116, rmse-0.342223, r2-0.846692
Valid at fold-0: mse-0.418327
Traing Log at fold-0 epoch-58: mse-0.115301, rmse-0.33956, r2-0.849008
Valid at fold-0: mse-0.420613
Traing Log at fold-0 epoch-59: mse-0.113106, rmse-0.336313, r2-0.853295
Valid at fold-0: mse-0.408801
Update best_mse, Valid at fold-0 epoch-59: mse-0.408801, rmse-0.639375, ci--1, r2-0.55696, pearson-0.750968, spearman-0.712759
Traing Log at fold-0 epoch-60: mse-0.108299, rmse-0.329087, r2-0.859834
Valid at fold-0: mse-0.438516
Traing Log at fold-0 epoch-61: mse-0.10693, rmse-0.327002, r2-0.861794
Valid at fold-0: mse-0.417543
Traing Log at fold-0 epoch-62: mse-0.107657, rmse-0.328112, r2-0.861096
Valid at fold-0: mse-0.426002
Traing Log at fold-0 epoch-63: mse-0.10762, rmse-0.328055, r2-0.861239
Valid at fold-0: mse-0.426901
Traing Log at fold-0 epoch-64: mse-0.104749, rmse-0.323649, r2-0.865031
Valid at fold-0: mse-0.418674
Traing Log at fold-0 epoch-65: mse-0.103401, rmse-0.32156, r2-0.867478
Valid at fold-0: mse-0.427126
Traing Log at fold-0 epoch-66: mse-0.100103, rmse-0.31639, r2-0.872174
Valid at fold-0: mse-0.422165
Traing Log at fold-0 epoch-67: mse-0.100029, rmse-0.316273, r2-0.872449
Valid at fold-0: mse-0.407603
Update best_mse, Valid at fold-0 epoch-67: mse-0.407603, rmse-0.638438, ci--1, r2-0.558258, pearson-0.753602, spearman-0.715505
Traing Log at fold-0 epoch-68: mse-0.098083, rmse-0.313181, r2-0.874649
Valid at fold-0: mse-0.411508
Traing Log at fold-0 epoch-69: mse-0.096307, rmse-0.310333, r2-0.87747
Valid at fold-0: mse-0.400767
Update best_mse, Valid at fold-0 epoch-69: mse-0.400767, rmse-0.633061, ci--1, r2-0.565667, pearson-0.757284, spearman-0.721213
Traing Log at fold-0 epoch-70: mse-0.096739, rmse-0.311028, r2-0.876803
Valid at fold-0: mse-0.405459
Traing Log at fold-0 epoch-71: mse-0.09278, rmse-0.304599, r2-0.882925
Valid at fold-0: mse-0.406923
Traing Log at fold-0 epoch-72: mse-0.094168, rmse-0.306868, r2-0.880585
Valid at fold-0: mse-0.412865
Traing Log at fold-0 epoch-73: mse-0.092336, rmse-0.303868, r2-0.883208
Valid at fold-0: mse-0.401809
Traing Log at fold-0 epoch-74: mse-0.089024, rmse-0.29837, r2-0.887723
Valid at fold-0: mse-0.402141
Traing Log at fold-0 epoch-75: mse-0.08873, rmse-0.297875, r2-0.88826
Valid at fold-0: mse-0.409099
Traing Log at fold-0 epoch-76: mse-0.08895, rmse-0.298244, r2-0.887946
Valid at fold-0: mse-0.417428
Traing Log at fold-0 epoch-77: mse-0.087215, rmse-0.295323, r2-0.890266
Valid at fold-0: mse-0.407978
Traing Log at fold-0 epoch-78: mse-0.085056, rmse-0.291644, r2-0.89333
Valid at fold-0: mse-0.410252
Traing Log at fold-0 epoch-79: mse-0.082955, rmse-0.288019, r2-0.896229
Valid at fold-0: mse-0.422867
Traing Log at fold-0 epoch-80: mse-0.084517, rmse-0.290718, r2-0.894416
Valid at fold-0: mse-0.403692
Traing Log at fold-0 epoch-81: mse-0.082429, rmse-0.287104, r2-0.897076
Valid at fold-0: mse-0.399469
Update best_mse, Valid at fold-0 epoch-81: mse-0.399469, rmse-0.632036, ci--1, r2-0.567074, pearson-0.761727, spearman-0.726892
Traing Log at fold-0 epoch-82: mse-0.082899, rmse-0.287922, r2-0.896296
Valid at fold-0: mse-0.409789
Traing Log at fold-0 epoch-83: mse-0.081689, rmse-0.285813, r2-0.898284
Valid at fold-0: mse-0.405663
Traing Log at fold-0 epoch-84: mse-0.081377, rmse-0.285266, r2-0.898325
Valid at fold-0: mse-0.410461
Traing Log at fold-0 epoch-85: mse-0.07871, rmse-0.280553, r2-0.902098
Valid at fold-0: mse-0.403528
Traing Log at fold-0 epoch-86: mse-0.077458, rmse-0.278313, r2-0.90375
Valid at fold-0: mse-0.414099
Traing Log at fold-0 epoch-87: mse-0.076624, rmse-0.27681, r2-0.905318
Valid at fold-0: mse-0.416503
Traing Log at fold-0 epoch-88: mse-0.075114, rmse-0.274069, r2-0.906764
Valid at fold-0: mse-0.409719
Traing Log at fold-0 epoch-89: mse-0.075669, rmse-0.275081, r2-0.906319
Valid at fold-0: mse-0.39987
Traing Log at fold-0 epoch-90: mse-0.074214, rmse-0.272422, r2-0.908276
Valid at fold-0: mse-0.410429
Traing Log at fold-0 epoch-91: mse-0.073283, rmse-0.270708, r2-0.909282
Valid at fold-0: mse-0.402102
Traing Log at fold-0 epoch-92: mse-0.074278, rmse-0.272541, r2-0.908276
Valid at fold-0: mse-0.407453
Traing Log at fold-0 epoch-93: mse-0.071656, rmse-0.267687, r2-0.911729
Valid at fold-0: mse-0.397282
Update best_mse, Valid at fold-0 epoch-93: mse-0.397282, rmse-0.630303, ci--1, r2-0.569444, pearson-0.757577, spearman-0.72283
Traing Log at fold-0 epoch-94: mse-0.072793, rmse-0.269802, r2-0.910168
Valid at fold-0: mse-0.401081
Traing Log at fold-0 epoch-95: mse-0.071272, rmse-0.266968, r2-0.912139
Valid at fold-0: mse-0.398988
Traing Log at fold-0 epoch-96: mse-0.06936, rmse-0.263363, r2-0.914565
Valid at fold-0: mse-0.404283
Traing Log at fold-0 epoch-97: mse-0.069005, rmse-0.262687, r2-0.915304
Valid at fold-0: mse-0.396533
Update best_mse, Valid at fold-0 epoch-97: mse-0.396533, rmse-0.629709, ci--1, r2-0.570256, pearson-0.760338, spearman-0.726953
Traing Log at fold-0 epoch-98: mse-0.069768, rmse-0.264136, r2-0.914632
Valid at fold-0: mse-0.400495
Traing Log at fold-0 epoch-99: mse-0.069933, rmse-0.264448, r2-0.914099
Valid at fold-0: mse-0.399616
Traing Log at fold-0 epoch-100: mse-0.068178, rmse-0.261109, r2-0.916269
Valid at fold-0: mse-0.400946
Traing Log at fold-0 epoch-101: mse-0.068402, rmse-0.261537, r2-0.916212
Valid at fold-0: mse-0.396182
Update best_mse, Valid at fold-0 epoch-101: mse-0.396182, rmse-0.62943, ci--1, r2-0.570636, pearson-0.758968, spearman-0.723624
Traing Log at fold-0 epoch-102: mse-0.067463, rmse-0.259737, r2-0.917231
Valid at fold-0: mse-0.403418
Traing Log at fold-0 epoch-103: mse-0.065048, rmse-0.255044, r2-0.920383
Valid at fold-0: mse-0.394226
Update best_mse, Valid at fold-0 epoch-103: mse-0.394226, rmse-0.627874, ci--1, r2-0.572756, pearson-0.764218, spearman-0.733692
Traing Log at fold-0 epoch-104: mse-0.066035, rmse-0.256973, r2-0.919132
Valid at fold-0: mse-0.398975
Traing Log at fold-0 epoch-105: mse-0.063357, rmse-0.251709, r2-0.922747
Valid at fold-0: mse-0.411108
Traing Log at fold-0 epoch-106: mse-0.063988, rmse-0.252958, r2-0.921888
Valid at fold-0: mse-0.404453
Traing Log at fold-0 epoch-107: mse-0.063101, rmse-0.251199, r2-0.923068
Valid at fold-0: mse-0.402022
Traing Log at fold-0 epoch-108: mse-0.062338, rmse-0.249676, r2-0.92394
Valid at fold-0: mse-0.406234
Traing Log at fold-0 epoch-109: mse-0.06256, rmse-0.25012, r2-0.923743
Valid at fold-0: mse-0.401844
Traing Log at fold-0 epoch-110: mse-0.061694, rmse-0.248384, r2-0.924939
Valid at fold-0: mse-0.401395
Traing Log at fold-0 epoch-111: mse-0.062045, rmse-0.249088, r2-0.924337
Valid at fold-0: mse-0.394872
Traing Log at fold-0 epoch-112: mse-0.059648, rmse-0.244229, r2-0.927418
Valid at fold-0: mse-0.400078
Traing Log at fold-0 epoch-113: mse-0.060529, rmse-0.246026, r2-0.926453
Valid at fold-0: mse-0.399465
Traing Log at fold-0 epoch-114: mse-0.059212, rmse-0.243335, r2-0.928087
Valid at fold-0: mse-0.392845
Update best_mse, Valid at fold-0 epoch-114: mse-0.392845, rmse-0.626773, ci--1, r2-0.574253, pearson-0.762741, spearman-0.730041
Traing Log at fold-0 epoch-115: mse-0.06114, rmse-0.247265, r2-0.925608
Valid at fold-0: mse-0.40273
Traing Log at fold-0 epoch-116: mse-0.059489, rmse-0.243904, r2-0.927879
Valid at fold-0: mse-0.403037
Traing Log at fold-0 epoch-117: mse-0.057815, rmse-0.240447, r2-0.92989
Valid at fold-0: mse-0.398981
Traing Log at fold-0 epoch-118: mse-0.057612, rmse-0.240026, r2-0.930084
Valid at fold-0: mse-0.401908
Traing Log at fold-0 epoch-119: mse-0.059372, rmse-0.243665, r2-0.928022
Valid at fold-0: mse-0.400486
Traing Log at fold-0 epoch-120: mse-0.05829, rmse-0.241432, r2-0.929348
Valid at fold-0: mse-0.404943
Traing Log at fold-0 epoch-121: mse-0.055246, rmse-0.235045, r2-0.933146
Valid at fold-0: mse-0.401367
Traing Log at fold-0 epoch-122: mse-0.056909, rmse-0.238557, r2-0.931161
Valid at fold-0: mse-0.394053
Traing Log at fold-0 epoch-123: mse-0.053626, rmse-0.231574, r2-0.935398
Valid at fold-0: mse-0.399618
Traing Log at fold-0 epoch-124: mse-0.056721, rmse-0.238162, r2-0.931291
Valid at fold-0: mse-0.40173
Traing Log at fold-0 epoch-125: mse-0.05536, rmse-0.235287, r2-0.933182
Valid at fold-0: mse-0.404336
Traing Log at fold-0 epoch-126: mse-0.055187, rmse-0.234919, r2-0.933407
Valid at fold-0: mse-0.391398
Update best_mse, Valid at fold-0 epoch-126: mse-0.391398, rmse-0.625618, ci--1, r2-0.57582, pearson-0.764726, spearman-0.732366
Traing Log at fold-0 epoch-127: mse-0.055211, rmse-0.23497, r2-0.933246
Valid at fold-0: mse-0.401695
Traing Log at fold-0 epoch-128: mse-0.055415, rmse-0.235404, r2-0.933051
Valid at fold-0: mse-0.399103
Traing Log at fold-0 epoch-129: mse-0.05353, rmse-0.231366, r2-0.935564
Valid at fold-0: mse-0.391579
Traing Log at fold-0 epoch-130: mse-0.053861, rmse-0.23208, r2-0.934842
Valid at fold-0: mse-0.408802
Traing Log at fold-0 epoch-131: mse-0.053608, rmse-0.231535, r2-0.935462
Valid at fold-0: mse-0.396662
Traing Log at fold-0 epoch-132: mse-0.052454, rmse-0.229028, r2-0.936795
Valid at fold-0: mse-0.391852
Traing Log at fold-0 epoch-133: mse-0.053154, rmse-0.230552, r2-0.935904
Valid at fold-0: mse-0.392371
Traing Log at fold-0 epoch-134: mse-0.051861, rmse-0.227731, r2-0.9376
Valid at fold-0: mse-0.40426
Traing Log at fold-0 epoch-135: mse-0.051494, rmse-0.226924, r2-0.937939
Valid at fold-0: mse-0.399141
Traing Log at fold-0 epoch-136: mse-0.053651, rmse-0.231626, r2-0.935442
Valid at fold-0: mse-0.386516
Update best_mse, Valid at fold-0 epoch-136: mse-0.386516, rmse-0.621705, ci--1, r2-0.581111, pearson-0.768262, spearman-0.733513
Traing Log at fold-0 epoch-137: mse-0.050919, rmse-0.225653, r2-0.938809
Valid at fold-0: mse-0.39339
Traing Log at fold-0 epoch-138: mse-0.049793, rmse-0.223143, r2-0.940168
Valid at fold-0: mse-0.39651
Traing Log at fold-0 epoch-139: mse-0.050219, rmse-0.224097, r2-0.939561
Valid at fold-0: mse-0.39087
Traing Log at fold-0 epoch-140: mse-0.050014, rmse-0.223638, r2-0.940025
Valid at fold-0: mse-0.392863
Traing Log at fold-0 epoch-141: mse-0.048639, rmse-0.220542, r2-0.941591
Valid at fold-0: mse-0.397192
Traing Log at fold-0 epoch-142: mse-0.049927, rmse-0.223443, r2-0.940072
Valid at fold-0: mse-0.396979
Traing Log at fold-0 epoch-143: mse-0.049229, rmse-0.221876, r2-0.940979
Valid at fold-0: mse-0.393666
Traing Log at fold-0 epoch-144: mse-0.049432, rmse-0.222333, r2-0.940706
Valid at fold-0: mse-0.392582
Traing Log at fold-0 epoch-145: mse-0.048208, rmse-0.219563, r2-0.94218
Valid at fold-0: mse-0.390852
Traing Log at fold-0 epoch-146: mse-0.048681, rmse-0.220637, r2-0.941642
Valid at fold-0: mse-0.391445
Traing Log at fold-0 epoch-147: mse-0.047579, rmse-0.218127, r2-0.943072
Valid at fold-0: mse-0.394047
Traing Log at fold-0 epoch-148: mse-0.048379, rmse-0.219953, r2-0.941997
Valid at fold-0: mse-0.39104
Traing Log at fold-0 epoch-149: mse-0.04781, rmse-0.218655, r2-0.94265
Valid at fold-0: mse-0.392875
Traing Log at fold-0 epoch-150: mse-0.047077, rmse-0.216973, r2-0.94372
Valid at fold-0: mse-0.389532
Traing Log at fold-0 epoch-151: mse-0.046716, rmse-0.216138, r2-0.944143
Valid at fold-0: mse-0.392523
Traing Log at fold-0 epoch-152: mse-0.046775, rmse-0.216274, r2-0.943971
Valid at fold-0: mse-0.393612
Traing Log at fold-0 epoch-153: mse-0.047324, rmse-0.217542, r2-0.943323
Valid at fold-0: mse-0.395597
Traing Log at fold-0 epoch-154: mse-0.046281, rmse-0.215129, r2-0.944783
Valid at fold-0: mse-0.391648
Traing Log at fold-0 epoch-155: mse-0.04684, rmse-0.216424, r2-0.943874
Valid at fold-0: mse-0.393042
Traing Log at fold-0 epoch-156: mse-0.045953, rmse-0.214367, r2-0.945063
Valid at fold-0: mse-0.392491
Traing Log at fold-0 epoch-157: mse-0.045538, rmse-0.213396, r2-0.945728
Valid at fold-0: mse-0.387283
Traing stop at epoch-157, model save at-./savemodel/metz-novel-pair-fold0-Nov13_10-59-23.pth
Save log over at ./log/Nov13_10-59-23-metz-novel-pair-fold0.csv

============================================================
Testing fold 0 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-0, mse: 0.732578, rmse: 0.855908, ci: 0.674143, r2: 0.256149, pearson: 0.526477, spearman: 0.477801

Fold 0 results saved to: ./log/Test-metz-novel-pair-fold0-Nov13_10-59-23.csv
============================================================
Training fold 0 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 351-351, summary, console lines 367-372
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–†â–…â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–ƒâ–„â–…â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–†â–…â–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.38652
wandb:  best_valid/pearson 0.76826
wandb:       best_valid/r2 0.58111
wandb:     best_valid/rmse 0.6217
wandb: best_valid/spearman 0.73351
wandb:               epoch 157
wandb:       final_test_ci 0.67414
wandb:      final_test_mse 0.73258
wandb:  final_test_pearson 0.52648
wandb:       final_test_r2 0.25615
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run metz-novel-pair-fold0 at: https://wandb.ai/tringuyen/LLMDTA/runs/q8iinlup
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_105924-q8iinlup/logs
Weights & Biases run finished

Training for fold 0 completed successfully.
Python script exit code: 0
==========================================
End Time: Thu Nov 13 07:59:08 PM AEDT 2025
==========================================
