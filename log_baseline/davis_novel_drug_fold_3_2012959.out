==========================================
Job ID: 2012959
Array Task ID: 3
Node: v100l-f-05
Start Time: Wed Nov 12 04:41:09 PM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Wed Nov 12 16:41:10 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:06:00.0 Off |                    0 |
| N/A   34C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 3...


============================================================
Starting training for Fold 3
Dataset: davis, Running Set: novel-drug
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 3 --cuda 0 --dataset davis --running_set novel-drug --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 3/4
Dataset: davis-novel-drug
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/davis/davis_drug_pretrain.pkl
Pretrain-./data/davis/davis_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run 1u548s8u
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251112_164118-1u548s8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run davis-novel-drug-fold3
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/1u548s8u
Weights & Biases initialized: LLMDTA
Loading fold 3 data...
  Train: ./data/dta-5fold-dataset/davis/novel-drug/fold_3_train.csv
  Valid: ./data/dta-5fold-dataset/davis/novel-drug/fold_3_valid.csv
  Test:  ./data/dta-5fold-dataset/davis/novel-drug/fold_3_test.csv
Dataset loaded: 19448 train, 4862 valid, 5746 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-3 epoch-1: mse-1.760351, rmse-1.326782, r2--0.193299
Valid at fold-3: mse-1.113503
Update best_mse, Valid at fold-3 epoch-1: mse-1.113503, rmse-1.055226, ci--1, r2--0.298842, pearson-0.448176, spearman-0.400595
Traing Log at fold-3 epoch-2: mse-0.7069, rmse-0.840774, r2--0.146167
Valid at fold-3: mse-0.803877
Update best_mse, Valid at fold-3 epoch-2: mse-0.803877, rmse-0.896592, ci--1, r2-0.06232, pearson-0.60447, spearman-0.522818
Traing Log at fold-3 epoch-3: mse-0.582624, rmse-0.763298, r2--0.030698
Valid at fold-3: mse-0.55301
Update best_mse, Valid at fold-3 epoch-3: mse-0.55301, rmse-0.743647, ci--1, r2-0.354943, pearson-0.631403, spearman-0.546065
Traing Log at fold-3 epoch-4: mse-0.48586, rmse-0.697037, r2-0.089436
Valid at fold-3: mse-0.607673
Traing Log at fold-3 epoch-5: mse-0.43587, rmse-0.660204, r2-0.151706
Valid at fold-3: mse-0.507041
Update best_mse, Valid at fold-3 epoch-5: mse-0.507041, rmse-0.712068, ci--1, r2-0.408564, pearson-0.72621, spearman-0.617226
Traing Log at fold-3 epoch-6: mse-0.380984, rmse-0.617239, r2-0.279816
Valid at fold-3: mse-0.570336
Traing Log at fold-3 epoch-7: mse-0.359773, rmse-0.599811, r2-0.314867
Valid at fold-3: mse-0.368337
Update best_mse, Valid at fold-3 epoch-7: mse-0.368337, rmse-0.606908, ci--1, r2-0.570355, pearson-0.767032, spearman-0.645017
Traing Log at fold-3 epoch-8: mse-0.332188, rmse-0.576357, r2-0.384044
Valid at fold-3: mse-0.36134
Update best_mse, Valid at fold-3 epoch-8: mse-0.36134, rmse-0.601116, ci--1, r2-0.578516, pearson-0.776791, spearman-0.639691
Traing Log at fold-3 epoch-9: mse-0.314929, rmse-0.561185, r2-0.422207
Valid at fold-3: mse-0.338085
Update best_mse, Valid at fold-3 epoch-9: mse-0.338085, rmse-0.581451, ci--1, r2-0.605642, pearson-0.77963, spearman-0.628956
Traing Log at fold-3 epoch-10: mse-0.296468, rmse-0.544488, r2-0.468257
Valid at fold-3: mse-0.323168
Update best_mse, Valid at fold-3 epoch-10: mse-0.323168, rmse-0.568479, ci--1, r2-0.623042, pearson-0.791069, spearman-0.658055
Traing Log at fold-3 epoch-11: mse-0.285934, rmse-0.534728, r2-0.496924
Valid at fold-3: mse-0.359326
Traing Log at fold-3 epoch-12: mse-0.273658, rmse-0.523123, r2-0.526145
Valid at fold-3: mse-0.31799
Update best_mse, Valid at fold-3 epoch-12: mse-0.31799, rmse-0.563906, ci--1, r2-0.629081, pearson-0.797099, spearman-0.669565
Traing Log at fold-3 epoch-13: mse-0.261491, rmse-0.511362, r2-0.551164
Valid at fold-3: mse-0.308482
Update best_mse, Valid at fold-3 epoch-13: mse-0.308482, rmse-0.555411, ci--1, r2-0.640172, pearson-0.810865, spearman-0.679977
Traing Log at fold-3 epoch-14: mse-0.254136, rmse-0.504119, r2-0.569458
Valid at fold-3: mse-0.315361
Traing Log at fold-3 epoch-15: mse-0.239441, rmse-0.489327, r2-0.60441
Valid at fold-3: mse-0.300542
Update best_mse, Valid at fold-3 epoch-15: mse-0.300542, rmse-0.548217, ci--1, r2-0.649434, pearson-0.807655, spearman-0.675377
Traing Log at fold-3 epoch-16: mse-0.232553, rmse-0.482237, r2-0.618815
Valid at fold-3: mse-0.27947
Update best_mse, Valid at fold-3 epoch-16: mse-0.27947, rmse-0.52865, ci--1, r2-0.674013, pearson-0.822372, spearman-0.6691
Traing Log at fold-3 epoch-17: mse-0.225713, rmse-0.475093, r2-0.632576
Valid at fold-3: mse-0.295879
Traing Log at fold-3 epoch-18: mse-0.214612, rmse-0.463263, r2-0.657396
Valid at fold-3: mse-0.291638
Traing Log at fold-3 epoch-19: mse-0.209112, rmse-0.457288, r2-0.669322
Valid at fold-3: mse-0.275756
Update best_mse, Valid at fold-3 epoch-19: mse-0.275756, rmse-0.525125, ci--1, r2-0.678345, pearson-0.828857, spearman-0.686843
Traing Log at fold-3 epoch-20: mse-0.206363, rmse-0.454272, r2-0.673511
Valid at fold-3: mse-0.274937
Update best_mse, Valid at fold-3 epoch-20: mse-0.274937, rmse-0.524344, ci--1, r2-0.679301, pearson-0.826297, spearman-0.675379
Traing Log at fold-3 epoch-21: mse-0.196136, rmse-0.442873, r2-0.69654
Valid at fold-3: mse-0.25386
Update best_mse, Valid at fold-3 epoch-21: mse-0.25386, rmse-0.503845, ci--1, r2-0.703886, pearson-0.840053, spearman-0.687089
Traing Log at fold-3 epoch-22: mse-0.193901, rmse-0.440342, r2-0.699517
Valid at fold-3: mse-0.279722
Traing Log at fold-3 epoch-23: mse-0.191191, rmse-0.437254, r2-0.706291
Valid at fold-3: mse-0.26543
Traing Log at fold-3 epoch-24: mse-0.18362, rmse-0.428509, r2-0.719821
Valid at fold-3: mse-0.256688
Traing Log at fold-3 epoch-25: mse-0.17972, rmse-0.423934, r2-0.727136
Valid at fold-3: mse-0.250144
Update best_mse, Valid at fold-3 epoch-25: mse-0.250144, rmse-0.500144, ci--1, r2-0.70822, pearson-0.844864, spearman-0.693996
Traing Log at fold-3 epoch-26: mse-0.174926, rmse-0.418241, r2-0.736745
Valid at fold-3: mse-0.250467
Traing Log at fold-3 epoch-27: mse-0.170722, rmse-0.413185, r2-0.745147
Valid at fold-3: mse-0.270899
Traing Log at fold-3 epoch-28: mse-0.16734, rmse-0.409072, r2-0.750568
Valid at fold-3: mse-0.249379
Update best_mse, Valid at fold-3 epoch-28: mse-0.249379, rmse-0.499378, ci--1, r2-0.709113, pearson-0.849892, spearman-0.705344
Traing Log at fold-3 epoch-29: mse-0.160256, rmse-0.40032, r2-0.763636
Valid at fold-3: mse-0.257286
Traing Log at fold-3 epoch-30: mse-0.162758, rmse-0.403432, r2-0.760142
Valid at fold-3: mse-0.24709
Update best_mse, Valid at fold-3 epoch-30: mse-0.24709, rmse-0.497082, ci--1, r2-0.711783, pearson-0.84638, spearman-0.69669
Traing Log at fold-3 epoch-31: mse-0.156417, rmse-0.395495, r2-0.769717
Valid at fold-3: mse-0.257364
Traing Log at fold-3 epoch-32: mse-0.153885, rmse-0.392282, r2-0.775482
Valid at fold-3: mse-0.24835
Traing Log at fold-3 epoch-33: mse-0.148154, rmse-0.384907, r2-0.785383
Valid at fold-3: mse-0.247715
Traing Log at fold-3 epoch-34: mse-0.148109, rmse-0.38485, r2-0.786642
Valid at fold-3: mse-0.240787
Update best_mse, Valid at fold-3 epoch-34: mse-0.240787, rmse-0.4907, ci--1, r2-0.719135, pearson-0.848494, spearman-0.691672
Traing Log at fold-3 epoch-35: mse-0.143222, rmse-0.378446, r2-0.793204
Valid at fold-3: mse-0.250512
Traing Log at fold-3 epoch-36: mse-0.14073, rmse-0.37514, r2-0.798493
Valid at fold-3: mse-0.239022
Update best_mse, Valid at fold-3 epoch-36: mse-0.239022, rmse-0.488899, ci--1, r2-0.721194, pearson-0.852442, spearman-0.69871
Traing Log at fold-3 epoch-37: mse-0.141086, rmse-0.375614, r2-0.798627
Valid at fold-3: mse-0.243907
Traing Log at fold-3 epoch-38: mse-0.137715, rmse-0.3711, r2-0.803714
Valid at fold-3: mse-0.25497
Traing Log at fold-3 epoch-39: mse-0.136792, rmse-0.369854, r2-0.806035
Valid at fold-3: mse-0.244411
Traing Log at fold-3 epoch-40: mse-0.135441, rmse-0.368023, r2-0.807469
Valid at fold-3: mse-0.240468
Traing Log at fold-3 epoch-41: mse-0.128914, rmse-0.359046, r2-0.818183
Valid at fold-3: mse-0.236349
Update best_mse, Valid at fold-3 epoch-41: mse-0.236349, rmse-0.486157, ci--1, r2-0.724312, pearson-0.85326, spearman-0.697353
Traing Log at fold-3 epoch-42: mse-0.129885, rmse-0.360396, r2-0.816888
Valid at fold-3: mse-0.238542
Traing Log at fold-3 epoch-43: mse-0.126313, rmse-0.355405, r2-0.822871
Valid at fold-3: mse-0.226545
Update best_mse, Valid at fold-3 epoch-43: mse-0.226545, rmse-0.475968, ci--1, r2-0.735747, pearson-0.858754, spearman-0.705534
Traing Log at fold-3 epoch-44: mse-0.122952, rmse-0.350645, r2-0.827525
Valid at fold-3: mse-0.233216
Traing Log at fold-3 epoch-45: mse-0.125007, rmse-0.353564, r2-0.825633
Valid at fold-3: mse-0.247288
Traing Log at fold-3 epoch-46: mse-0.120322, rmse-0.346874, r2-0.832153
Valid at fold-3: mse-0.231389
Traing Log at fold-3 epoch-47: mse-0.120868, rmse-0.347661, r2-0.831306
Valid at fold-3: mse-0.239437
Traing Log at fold-3 epoch-48: mse-0.116427, rmse-0.341213, r2-0.83933
Valid at fold-3: mse-0.227487
Traing Log at fold-3 epoch-49: mse-0.116841, rmse-0.34182, r2-0.837958
Valid at fold-3: mse-0.240759
Traing Log at fold-3 epoch-50: mse-0.117411, rmse-0.342653, r2-0.838046
Valid at fold-3: mse-0.228217
Traing Log at fold-3 epoch-51: mse-0.113534, rmse-0.336948, r2-0.843786
Valid at fold-3: mse-0.237349
Traing Log at fold-3 epoch-52: mse-0.112613, rmse-0.335578, r2-0.844498
Valid at fold-3: mse-0.238709
Traing Log at fold-3 epoch-53: mse-0.110562, rmse-0.332509, r2-0.847538
Valid at fold-3: mse-0.239568
Traing Log at fold-3 epoch-54: mse-0.109438, rmse-0.330814, r2-0.850298
Valid at fold-3: mse-0.23656
Traing Log at fold-3 epoch-55: mse-0.109084, rmse-0.330279, r2-0.850838
Valid at fold-3: mse-0.221116
Update best_mse, Valid at fold-3 epoch-55: mse-0.221116, rmse-0.470229, ci--1, r2-0.742081, pearson-0.862166, spearman-0.695386
Traing Log at fold-3 epoch-56: mse-0.106002, rmse-0.325579, r2-0.85494
Valid at fold-3: mse-0.223582
Traing Log at fold-3 epoch-57: mse-0.106396, rmse-0.326185, r2-0.855249
Valid at fold-3: mse-0.230337
Traing Log at fold-3 epoch-58: mse-0.105126, rmse-0.324231, r2-0.856961
Valid at fold-3: mse-0.233312
Traing Log at fold-3 epoch-59: mse-0.105007, rmse-0.324048, r2-0.856479
Valid at fold-3: mse-0.224753
Traing Log at fold-3 epoch-60: mse-0.10033, rmse-0.316749, r2-0.864259
Valid at fold-3: mse-0.232244
Traing Log at fold-3 epoch-61: mse-0.100807, rmse-0.317501, r2-0.8631
Valid at fold-3: mse-0.22445
Traing Log at fold-3 epoch-62: mse-0.098417, rmse-0.313715, r2-0.867158
Valid at fold-3: mse-0.226596
Traing Log at fold-3 epoch-63: mse-0.09759, rmse-0.312394, r2-0.868296
Valid at fold-3: mse-0.223217
Traing Log at fold-3 epoch-64: mse-0.100097, rmse-0.316381, r2-0.86452
Valid at fold-3: mse-0.222375
Traing Log at fold-3 epoch-65: mse-0.09605, rmse-0.30992, r2-0.870519
Valid at fold-3: mse-0.223366
Traing Log at fold-3 epoch-66: mse-0.098367, rmse-0.313636, r2-0.867879
Valid at fold-3: mse-0.237589
Traing Log at fold-3 epoch-67: mse-0.094818, rmse-0.307925, r2-0.872488
Valid at fold-3: mse-0.222638
Traing Log at fold-3 epoch-68: mse-0.095034, rmse-0.308276, r2-0.872664
Valid at fold-3: mse-0.233143
Traing Log at fold-3 epoch-69: mse-0.092877, rmse-0.304758, r2-0.874891
Valid at fold-3: mse-0.230778
Traing Log at fold-3 epoch-70: mse-0.092329, rmse-0.303858, r2-0.875898
Valid at fold-3: mse-0.22376
Traing Log at fold-3 epoch-71: mse-0.091175, rmse-0.301951, r2-0.87772
Valid at fold-3: mse-0.228763
Traing Log at fold-3 epoch-72: mse-0.090124, rmse-0.300206, r2-0.879876
Valid at fold-3: mse-0.22106
Update best_mse, Valid at fold-3 epoch-72: mse-0.22106, rmse-0.47017, ci--1, r2-0.742146, pearson-0.862918, spearman-0.684743
Traing Log at fold-3 epoch-73: mse-0.088779, rmse-0.297958, r2-0.881599
Valid at fold-3: mse-0.219281
Update best_mse, Valid at fold-3 epoch-73: mse-0.219281, rmse-0.468274, ci--1, r2-0.744221, pearson-0.863343, spearman-0.691259
Traing Log at fold-3 epoch-74: mse-0.090492, rmse-0.300819, r2-0.879572
Valid at fold-3: mse-0.233169
Traing Log at fold-3 epoch-75: mse-0.087955, rmse-0.296572, r2-0.88288
Valid at fold-3: mse-0.221312
Traing Log at fold-3 epoch-76: mse-0.088284, rmse-0.297126, r2-0.882066
Valid at fold-3: mse-0.217093
Update best_mse, Valid at fold-3 epoch-76: mse-0.217093, rmse-0.465933, ci--1, r2-0.746772, pearson-0.864472, spearman-0.695413
Traing Log at fold-3 epoch-77: mse-0.087051, rmse-0.295044, r2-0.884275
Valid at fold-3: mse-0.218914
Traing Log at fold-3 epoch-78: mse-0.086443, rmse-0.294012, r2-0.885326
Valid at fold-3: mse-0.217075
Update best_mse, Valid at fold-3 epoch-78: mse-0.217075, rmse-0.465913, ci--1, r2-0.746793, pearson-0.866649, spearman-0.701822
Traing Log at fold-3 epoch-79: mse-0.08572, rmse-0.29278, r2-0.885996
Valid at fold-3: mse-0.221923
Traing Log at fold-3 epoch-80: mse-0.085005, rmse-0.291557, r2-0.887081
Valid at fold-3: mse-0.218634
Traing Log at fold-3 epoch-81: mse-0.0841, rmse-0.290001, r2-0.88827
Valid at fold-3: mse-0.224688
Traing Log at fold-3 epoch-82: mse-0.082678, rmse-0.287537, r2-0.890779
Valid at fold-3: mse-0.228386
Traing Log at fold-3 epoch-83: mse-0.085306, rmse-0.292073, r2-0.886754
Valid at fold-3: mse-0.213696
Update best_mse, Valid at fold-3 epoch-83: mse-0.213696, rmse-0.462273, ci--1, r2-0.750735, pearson-0.867128, spearman-0.702422
Traing Log at fold-3 epoch-84: mse-0.083294, rmse-0.288607, r2-0.889771
Valid at fold-3: mse-0.213357
Update best_mse, Valid at fold-3 epoch-84: mse-0.213357, rmse-0.461906, ci--1, r2-0.75113, pearson-0.866697, spearman-0.702118
Traing Log at fold-3 epoch-85: mse-0.083056, rmse-0.288195, r2-0.890173
Valid at fold-3: mse-0.216869
Traing Log at fold-3 epoch-86: mse-0.080951, rmse-0.284519, r2-0.893014
Valid at fold-3: mse-0.228241
Traing Log at fold-3 epoch-87: mse-0.080481, rmse-0.283692, r2-0.893956
Valid at fold-3: mse-0.226105
Traing Log at fold-3 epoch-88: mse-0.081476, rmse-0.28544, r2-0.892143
Valid at fold-3: mse-0.218682
Traing Log at fold-3 epoch-89: mse-0.080765, rmse-0.284191, r2-0.893704
Valid at fold-3: mse-0.221613
Traing Log at fold-3 epoch-90: mse-0.079283, rmse-0.281573, r2-0.895326
Valid at fold-3: mse-0.227858
Traing Log at fold-3 epoch-91: mse-0.078501, rmse-0.28018, r2-0.896771
Valid at fold-3: mse-0.22435
Traing Log at fold-3 epoch-92: mse-0.078938, rmse-0.280958, r2-0.895946
Valid at fold-3: mse-0.226155
Traing Log at fold-3 epoch-93: mse-0.077768, rmse-0.278869, r2-0.897759
Valid at fold-3: mse-0.218445
Traing Log at fold-3 epoch-94: mse-0.077548, rmse-0.278475, r2-0.898409
Valid at fold-3: mse-0.219205
Traing Log at fold-3 epoch-95: mse-0.0767, rmse-0.276948, r2-0.899459
Valid at fold-3: mse-0.219662
Traing Log at fold-3 epoch-96: mse-0.076384, rmse-0.276377, r2-0.899613
Valid at fold-3: mse-0.221251
Traing Log at fold-3 epoch-97: mse-0.075386, rmse-0.274564, r2-0.901039
Valid at fold-3: mse-0.219056
Traing Log at fold-3 epoch-98: mse-0.076089, rmse-0.275842, r2-0.900391
Valid at fold-3: mse-0.216031
Traing Log at fold-3 epoch-99: mse-0.076131, rmse-0.275919, r2-0.899814
Valid at fold-3: mse-0.224626
Traing Log at fold-3 epoch-100: mse-0.074064, rmse-0.272148, r2-0.902997
Valid at fold-3: mse-0.229647
Traing Log at fold-3 epoch-101: mse-0.075375, rmse-0.274545, r2-0.901053
Valid at fold-3: mse-0.219799
Traing Log at fold-3 epoch-102: mse-0.074927, rmse-0.273727, r2-0.902052
Valid at fold-3: mse-0.214687
Traing Log at fold-3 epoch-103: mse-0.074493, rmse-0.272934, r2-0.902274
Valid at fold-3: mse-0.218381
Traing Log at fold-3 epoch-104: mse-0.075253, rmse-0.274323, r2-0.901477
Valid at fold-3: mse-0.215866
Traing Log at fold-3 epoch-105: mse-0.072453, rmse-0.269171, r2-0.905264
Valid at fold-3: mse-0.217238
Traing stop at epoch-105, model save at-./savemodel/davis-novel-drug-fold3-Nov12_16-41-17.pth
Save log over at ./log/Nov12_16-41-17-davis-novel-drug-fold3.csv

============================================================
Testing fold 3 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-3, mse: 0.634821, rmse: 0.796757, ci: 0.675549, r2: 0.003868, pearson: 0.275975, spearman: 0.326585

Fold 3 results saved to: ./log/Test-davis-novel-drug-fold3-Nov12_16-41-17.csv
============================================================
Training fold 3 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 239-239, summary, console lines 255-260
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–„â–„â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–ƒâ–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–†â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–„â–„â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.21336
wandb:  best_valid/pearson 0.8667
wandb:       best_valid/r2 0.75113
wandb:     best_valid/rmse 0.46191
wandb: best_valid/spearman 0.70212
wandb:               epoch 105
wandb:       final_test_ci 0.67555
wandb:      final_test_mse 0.63482
wandb:  final_test_pearson 0.27598
wandb:       final_test_r2 0.00387
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run davis-novel-drug-fold3 at: https://wandb.ai/tringuyen/LLMDTA/runs/1u548s8u
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251112_164118-1u548s8u/logs
Weights & Biases run finished

Training for fold 3 completed successfully.
Python script exit code: 0
==========================================
End Time: Wed Nov 12 08:56:58 PM AEDT 2025
==========================================
