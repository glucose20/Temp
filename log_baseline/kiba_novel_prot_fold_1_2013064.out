==========================================
Job ID: 2013064
Array Task ID: 1
Node: v100-f-10
Start Time: Thu Nov 13 07:13:43 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 07:13:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:18:00.0 Off |                    0 |
| N/A   33C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   1  Tesla V100-SXM2-32GB           On  |   00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   2  Tesla V100-SXM2-32GB           On  |   00000000:86:00.0 Off |                    0 |
| N/A   29C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
|   3  Tesla V100-SXM2-32GB           On  |   00000000:AF:00.0 Off |                    0 |
| N/A   33C    P0             42W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 1...


============================================================
Starting training for Fold 1
Dataset: kiba, Running Set: novel-prot
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 1 --cuda 0 --dataset kiba --running_set novel-prot --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 1/4
Dataset: kiba-novel-prot
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/kiba/kiba_drug_pretrain.pkl
Pretrain-./data/kiba/kiba_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run t2p0yrtm
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_071405-t2p0yrtm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kiba-novel-prot-fold1
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/t2p0yrtm
Weights & Biases initialized: LLMDTA
Loading fold 1 data...
  Train: ./data/dta-5fold-dataset/kiba/novel-prot/fold_1_train.csv
  Valid: ./data/dta-5fold-dataset/kiba/novel-prot/fold_1_valid.csv
  Test:  ./data/dta-5fold-dataset/kiba/novel-prot/fold_1_test.csv
Dataset loaded: 75228 train, 18807 valid, 24219 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-1 epoch-1: mse-2.323658, rmse-1.524355, r2--0.161438
Valid at fold-1: mse-0.50927
Update best_mse, Valid at fold-1 epoch-1: mse-0.50927, rmse-0.713632, ci--1, r2-0.290476, pearson-0.566482, spearman-0.556903
Traing Log at fold-1 epoch-2: mse-0.453004, rmse-0.673056, r2--0.296999
Valid at fold-1: mse-0.443133
Update best_mse, Valid at fold-1 epoch-2: mse-0.443133, rmse-0.665682, ci--1, r2-0.382619, pearson-0.654537, spearman-0.618887
Traing Log at fold-1 epoch-3: mse-0.372387, rmse-0.610235, r2--0.024268
Valid at fold-1: mse-0.353217
Update best_mse, Valid at fold-1 epoch-3: mse-0.353217, rmse-0.594321, ci--1, r2-0.507891, pearson-0.721693, spearman-0.700615
Traing Log at fold-1 epoch-4: mse-0.327865, rmse-0.572595, r2-0.163639
Valid at fold-1: mse-0.331144
Update best_mse, Valid at fold-1 epoch-4: mse-0.331144, rmse-0.575451, ci--1, r2-0.538644, pearson-0.738693, spearman-0.735444
Traing Log at fold-1 epoch-5: mse-0.296382, rmse-0.54441, r2-0.293648
Valid at fold-1: mse-0.294953
Update best_mse, Valid at fold-1 epoch-5: mse-0.294953, rmse-0.543096, ci--1, r2-0.589066, pearson-0.768792, spearman-0.758869
Traing Log at fold-1 epoch-6: mse-0.278217, rmse-0.527463, r2-0.361888
Valid at fold-1: mse-0.278913
Update best_mse, Valid at fold-1 epoch-6: mse-0.278913, rmse-0.528122, ci--1, r2-0.611414, pearson-0.782328, spearman-0.766919
Traing Log at fold-1 epoch-7: mse-0.262062, rmse-0.51192, r2-0.419751
Valid at fold-1: mse-0.26754
Update best_mse, Valid at fold-1 epoch-7: mse-0.26754, rmse-0.517242, ci--1, r2-0.627259, pearson-0.794207, spearman-0.774419
Traing Log at fold-1 epoch-8: mse-0.249594, rmse-0.499594, r2-0.460758
Valid at fold-1: mse-0.262817
Update best_mse, Valid at fold-1 epoch-8: mse-0.262817, rmse-0.512657, ci--1, r2-0.633838, pearson-0.801182, spearman-0.78388
Traing Log at fold-1 epoch-9: mse-0.237173, rmse-0.487004, r2-0.502941
Valid at fold-1: mse-0.252523
Update best_mse, Valid at fold-1 epoch-9: mse-0.252523, rmse-0.502517, ci--1, r2-0.64818, pearson-0.808238, spearman-0.793037
Traing Log at fold-1 epoch-10: mse-0.229166, rmse-0.478713, r2-0.52711
Valid at fold-1: mse-0.249475
Update best_mse, Valid at fold-1 epoch-10: mse-0.249475, rmse-0.499475, ci--1, r2-0.652427, pearson-0.808638, spearman-0.789957
Traing Log at fold-1 epoch-11: mse-0.222394, rmse-0.471587, r2-0.547913
Valid at fold-1: mse-0.240269
Update best_mse, Valid at fold-1 epoch-11: mse-0.240269, rmse-0.490173, ci--1, r2-0.665252, pearson-0.818069, spearman-0.798459
Traing Log at fold-1 epoch-12: mse-0.213965, rmse-0.462563, r2-0.571688
Valid at fold-1: mse-0.238459
Update best_mse, Valid at fold-1 epoch-12: mse-0.238459, rmse-0.488322, ci--1, r2-0.667775, pearson-0.820099, spearman-0.794208
Traing Log at fold-1 epoch-13: mse-0.207301, rmse-0.455303, r2-0.591042
Valid at fold-1: mse-0.23111
Update best_mse, Valid at fold-1 epoch-13: mse-0.23111, rmse-0.480739, ci--1, r2-0.678013, pearson-0.82599, spearman-0.808129
Traing Log at fold-1 epoch-14: mse-0.201949, rmse-0.449388, r2-0.604065
Valid at fold-1: mse-0.235109
Traing Log at fold-1 epoch-15: mse-0.194003, rmse-0.440458, r2-0.626652
Valid at fold-1: mse-0.223393
Update best_mse, Valid at fold-1 epoch-15: mse-0.223393, rmse-0.472645, ci--1, r2-0.688765, pearson-0.831437, spearman-0.808625
Traing Log at fold-1 epoch-16: mse-0.188383, rmse-0.434031, r2-0.640895
Valid at fold-1: mse-0.222125
Update best_mse, Valid at fold-1 epoch-16: mse-0.222125, rmse-0.471301, ci--1, r2-0.690532, pearson-0.832515, spearman-0.812197
Traing Log at fold-1 epoch-17: mse-0.184932, rmse-0.430037, r2-0.649789
Valid at fold-1: mse-0.222753
Traing Log at fold-1 epoch-18: mse-0.178995, rmse-0.423078, r2-0.664562
Valid at fold-1: mse-0.216597
Update best_mse, Valid at fold-1 epoch-18: mse-0.216597, rmse-0.465399, ci--1, r2-0.698234, pearson-0.841317, spearman-0.815465
Traing Log at fold-1 epoch-19: mse-0.175242, rmse-0.41862, r2-0.674521
Valid at fold-1: mse-0.216395
Update best_mse, Valid at fold-1 epoch-19: mse-0.216395, rmse-0.465183, ci--1, r2-0.698515, pearson-0.838497, spearman-0.818994
Traing Log at fold-1 epoch-20: mse-0.171184, rmse-0.413744, r2-0.684493
Valid at fold-1: mse-0.204571
Update best_mse, Valid at fold-1 epoch-20: mse-0.204571, rmse-0.452295, ci--1, r2-0.714988, pearson-0.848882, spearman-0.823856
Traing Log at fold-1 epoch-21: mse-0.166605, rmse-0.408172, r2-0.695124
Valid at fold-1: mse-0.214214
Traing Log at fold-1 epoch-22: mse-0.160912, rmse-0.401138, r2-0.708567
Valid at fold-1: mse-0.20699
Traing Log at fold-1 epoch-23: mse-0.157778, rmse-0.397213, r2-0.716068
Valid at fold-1: mse-0.206648
Traing Log at fold-1 epoch-24: mse-0.155301, rmse-0.394083, r2-0.721097
Valid at fold-1: mse-0.21049
Traing Log at fold-1 epoch-25: mse-0.152158, rmse-0.390075, r2-0.7291
Valid at fold-1: mse-0.210251
Traing Log at fold-1 epoch-26: mse-0.14799, rmse-0.384695, r2-0.738307
Valid at fold-1: mse-0.200409
Update best_mse, Valid at fold-1 epoch-26: mse-0.200409, rmse-0.447671, ci--1, r2-0.720786, pearson-0.850489, spearman-0.826514
Traing Log at fold-1 epoch-27: mse-0.145789, rmse-0.381824, r2-0.743074
Valid at fold-1: mse-0.200556
Traing Log at fold-1 epoch-28: mse-0.142197, rmse-0.37709, r2-0.750649
Valid at fold-1: mse-0.198763
Update best_mse, Valid at fold-1 epoch-28: mse-0.198763, rmse-0.445828, ci--1, r2-0.72308, pearson-0.857962, spearman-0.834719
Traing Log at fold-1 epoch-29: mse-0.138669, rmse-0.372383, r2-0.758536
Valid at fold-1: mse-0.199608
Traing Log at fold-1 epoch-30: mse-0.137015, rmse-0.370155, r2-0.76193
Valid at fold-1: mse-0.196496
Update best_mse, Valid at fold-1 epoch-30: mse-0.196496, rmse-0.443279, ci--1, r2-0.726238, pearson-0.855717, spearman-0.833993
Traing Log at fold-1 epoch-31: mse-0.133378, rmse-0.365209, r2-0.770342
Valid at fold-1: mse-0.198086
Traing Log at fold-1 epoch-32: mse-0.131408, rmse-0.362502, r2-0.774145
Valid at fold-1: mse-0.189132
Update best_mse, Valid at fold-1 epoch-32: mse-0.189132, rmse-0.434894, ci--1, r2-0.736497, pearson-0.860612, spearman-0.840104
Traing Log at fold-1 epoch-33: mse-0.129539, rmse-0.359915, r2-0.777995
Valid at fold-1: mse-0.195097
Traing Log at fold-1 epoch-34: mse-0.126248, rmse-0.355314, r2-0.784808
Valid at fold-1: mse-0.189127
Update best_mse, Valid at fold-1 epoch-34: mse-0.189127, rmse-0.434887, ci--1, r2-0.736506, pearson-0.859709, spearman-0.838883
Traing Log at fold-1 epoch-35: mse-0.125152, rmse-0.353768, r2-0.787206
Valid at fold-1: mse-0.191417
Traing Log at fold-1 epoch-36: mse-0.121698, rmse-0.348852, r2-0.794118
Valid at fold-1: mse-0.205747
Traing Log at fold-1 epoch-37: mse-0.120405, rmse-0.346994, r2-0.796867
Valid at fold-1: mse-0.193018
Traing Log at fold-1 epoch-38: mse-0.119279, rmse-0.345368, r2-0.799451
Valid at fold-1: mse-0.187567
Update best_mse, Valid at fold-1 epoch-38: mse-0.187567, rmse-0.43309, ci--1, r2-0.738678, pearson-0.862266, spearman-0.843684
Traing Log at fold-1 epoch-39: mse-0.115626, rmse-0.340039, r2-0.806161
Valid at fold-1: mse-0.18842
Traing Log at fold-1 epoch-40: mse-0.113109, rmse-0.336316, r2-0.811671
Valid at fold-1: mse-0.183453
Update best_mse, Valid at fold-1 epoch-40: mse-0.183453, rmse-0.428314, ci--1, r2-0.74441, pearson-0.864826, spearman-0.840687
Traing Log at fold-1 epoch-41: mse-0.11278, rmse-0.335828, r2-0.811982
Valid at fold-1: mse-0.186498
Traing Log at fold-1 epoch-42: mse-0.109777, rmse-0.331326, r2-0.818062
Valid at fold-1: mse-0.190777
Traing Log at fold-1 epoch-43: mse-0.109364, rmse-0.330703, r2-0.818816
Valid at fold-1: mse-0.184521
Traing Log at fold-1 epoch-44: mse-0.10723, rmse-0.32746, r2-0.822874
Valid at fold-1: mse-0.179948
Update best_mse, Valid at fold-1 epoch-44: mse-0.179948, rmse-0.424203, ci--1, r2-0.749293, pearson-0.86749, spearman-0.843145
Traing Log at fold-1 epoch-45: mse-0.10405, rmse-0.322568, r2-0.829081
Valid at fold-1: mse-0.185279
Traing Log at fold-1 epoch-46: mse-0.102985, rmse-0.320913, r2-0.831256
Valid at fold-1: mse-0.18203
Traing Log at fold-1 epoch-47: mse-0.103024, rmse-0.320973, r2-0.831144
Valid at fold-1: mse-0.181244
Traing Log at fold-1 epoch-48: mse-0.099618, rmse-0.315624, r2-0.837396
Valid at fold-1: mse-0.182122
Traing Log at fold-1 epoch-49: mse-0.09969, rmse-0.315738, r2-0.837521
Valid at fold-1: mse-0.185336
Traing Log at fold-1 epoch-50: mse-0.097493, rmse-0.312239, r2-0.84203
Valid at fold-1: mse-0.177842
Update best_mse, Valid at fold-1 epoch-50: mse-0.177842, rmse-0.421714, ci--1, r2-0.752227, pearson-0.868998, spearman-0.851637
Traing Log at fold-1 epoch-51: mse-0.095575, rmse-0.309152, r2-0.844968
Valid at fold-1: mse-0.181199
Traing Log at fold-1 epoch-52: mse-0.094163, rmse-0.306859, r2-0.847797
Valid at fold-1: mse-0.182346
Traing Log at fold-1 epoch-53: mse-0.092335, rmse-0.303867, r2-0.851063
Valid at fold-1: mse-0.175573
Update best_mse, Valid at fold-1 epoch-53: mse-0.175573, rmse-0.419014, ci--1, r2-0.755389, pearson-0.87298, spearman-0.852727
Traing Log at fold-1 epoch-54: mse-0.092976, rmse-0.304919, r2-0.850189
Valid at fold-1: mse-0.182779
Traing Log at fold-1 epoch-55: mse-0.089628, rmse-0.29938, r2-0.856142
Valid at fold-1: mse-0.179434
Traing Log at fold-1 epoch-56: mse-0.088983, rmse-0.2983, r2-0.85718
Valid at fold-1: mse-0.190533
Traing Log at fold-1 epoch-57: mse-0.087518, rmse-0.295835, r2-0.859968
Valid at fold-1: mse-0.184995
Traing Log at fold-1 epoch-58: mse-0.086332, rmse-0.293822, r2-0.862166
Valid at fold-1: mse-0.17404
Update best_mse, Valid at fold-1 epoch-58: mse-0.17404, rmse-0.417181, ci--1, r2-0.757524, pearson-0.873067, spearman-0.856789
Traing Log at fold-1 epoch-59: mse-0.085365, rmse-0.292172, r2-0.864048
Valid at fold-1: mse-0.176575
Traing Log at fold-1 epoch-60: mse-0.084527, rmse-0.290735, r2-0.865241
Valid at fold-1: mse-0.179563
Traing Log at fold-1 epoch-61: mse-0.082509, rmse-0.287244, r2-0.869325
Valid at fold-1: mse-0.175485
Traing Log at fold-1 epoch-62: mse-0.081819, rmse-0.286041, r2-0.870463
Valid at fold-1: mse-0.180568
Traing Log at fold-1 epoch-63: mse-0.081962, rmse-0.28629, r2-0.869795
Valid at fold-1: mse-0.180701
Traing Log at fold-1 epoch-64: mse-0.079558, rmse-0.28206, r2-0.874355
Valid at fold-1: mse-0.176041
Traing Log at fold-1 epoch-65: mse-0.078647, rmse-0.280441, r2-0.875957
Valid at fold-1: mse-0.180277
Traing Log at fold-1 epoch-66: mse-0.077419, rmse-0.278244, r2-0.87814
Valid at fold-1: mse-0.176353
Traing Log at fold-1 epoch-67: mse-0.076505, rmse-0.276595, r2-0.879775
Valid at fold-1: mse-0.174971
Traing Log at fold-1 epoch-68: mse-0.075719, rmse-0.27517, r2-0.881023
Valid at fold-1: mse-0.173551
Update best_mse, Valid at fold-1 epoch-68: mse-0.173551, rmse-0.416594, ci--1, r2-0.758206, pearson-0.875014, spearman-0.856445
Traing Log at fold-1 epoch-69: mse-0.07354, rmse-0.271183, r2-0.884914
Valid at fold-1: mse-0.174651
Traing Log at fold-1 epoch-70: mse-0.073231, rmse-0.270613, r2-0.885363
Valid at fold-1: mse-0.171047
Update best_mse, Valid at fold-1 epoch-70: mse-0.171047, rmse-0.413578, ci--1, r2-0.761694, pearson-0.875112, spearman-0.857163
Traing Log at fold-1 epoch-71: mse-0.072228, rmse-0.268753, r2-0.887183
Valid at fold-1: mse-0.175585
Traing Log at fold-1 epoch-72: mse-0.071243, rmse-0.266914, r2-0.888862
Valid at fold-1: mse-0.178244
Traing Log at fold-1 epoch-73: mse-0.069947, rmse-0.264475, r2-0.891155
Valid at fold-1: mse-0.170824
Update best_mse, Valid at fold-1 epoch-73: mse-0.170824, rmse-0.413309, ci--1, r2-0.762004, pearson-0.875159, spearman-0.85737
Traing Log at fold-1 epoch-74: mse-0.069072, rmse-0.262815, r2-0.892581
Valid at fold-1: mse-0.172901
Traing Log at fold-1 epoch-75: mse-0.068655, rmse-0.262022, r2-0.89325
Valid at fold-1: mse-0.177596
Traing Log at fold-1 epoch-76: mse-0.06703, rmse-0.258901, r2-0.896176
Valid at fold-1: mse-0.176363
Traing Log at fold-1 epoch-77: mse-0.066565, rmse-0.258001, r2-0.896859
Valid at fold-1: mse-0.170608
Update best_mse, Valid at fold-1 epoch-77: mse-0.170608, rmse-0.413047, ci--1, r2-0.762306, pearson-0.878124, spearman-0.857383
Traing Log at fold-1 epoch-78: mse-0.065772, rmse-0.25646, r2-0.898258
Valid at fold-1: mse-0.169598
Update best_mse, Valid at fold-1 epoch-78: mse-0.169598, rmse-0.411823, ci--1, r2-0.763712, pearson-0.877626, spearman-0.86162
Traing Log at fold-1 epoch-79: mse-0.065085, rmse-0.255118, r2-0.899421
Valid at fold-1: mse-0.170621
Traing Log at fold-1 epoch-80: mse-0.063991, rmse-0.252965, r2-0.901291
Valid at fold-1: mse-0.173909
Traing Log at fold-1 epoch-81: mse-0.063631, rmse-0.252253, r2-0.901951
Valid at fold-1: mse-0.172757
Traing Log at fold-1 epoch-82: mse-0.06126, rmse-0.247508, r2-0.90587
Valid at fold-1: mse-0.172413
Traing Log at fold-1 epoch-83: mse-0.061171, rmse-0.247327, r2-0.905923
Valid at fold-1: mse-0.17069
Traing Log at fold-1 epoch-84: mse-0.059999, rmse-0.244947, r2-0.907888
Valid at fold-1: mse-0.168189
Update best_mse, Valid at fold-1 epoch-84: mse-0.168189, rmse-0.410108, ci--1, r2-0.765676, pearson-0.881146, spearman-0.862131
Traing Log at fold-1 epoch-85: mse-0.059942, rmse-0.24483, r2-0.908136
Valid at fold-1: mse-0.168325
Traing Log at fold-1 epoch-86: mse-0.05898, rmse-0.242858, r2-0.909651
Valid at fold-1: mse-0.169319
Traing Log at fold-1 epoch-87: mse-0.058423, rmse-0.241709, r2-0.910598
Valid at fold-1: mse-0.165292
Update best_mse, Valid at fold-1 epoch-87: mse-0.165292, rmse-0.406561, ci--1, r2-0.769712, pearson-0.880496, spearman-0.860348
Traing Log at fold-1 epoch-88: mse-0.056825, rmse-0.23838, r2-0.913262
Valid at fold-1: mse-0.166908
Traing Log at fold-1 epoch-89: mse-0.056796, rmse-0.23832, r2-0.913276
Valid at fold-1: mse-0.167406
Traing Log at fold-1 epoch-90: mse-0.055716, rmse-0.236043, r2-0.915083
Valid at fold-1: mse-0.16909
Traing Log at fold-1 epoch-91: mse-0.055337, rmse-0.235239, r2-0.915666
Valid at fold-1: mse-0.16516
Update best_mse, Valid at fold-1 epoch-91: mse-0.16516, rmse-0.406399, ci--1, r2-0.769896, pearson-0.880953, spearman-0.86322
Traing Log at fold-1 epoch-92: mse-0.055136, rmse-0.23481, r2-0.915987
Valid at fold-1: mse-0.165674
Traing Log at fold-1 epoch-93: mse-0.053583, rmse-0.231479, r2-0.918623
Valid at fold-1: mse-0.169826
Traing Log at fold-1 epoch-94: mse-0.053464, rmse-0.231223, r2-0.91883
Valid at fold-1: mse-0.167223
Traing Log at fold-1 epoch-95: mse-0.052531, rmse-0.229196, r2-0.920281
Valid at fold-1: mse-0.169791
Traing Log at fold-1 epoch-96: mse-0.051889, rmse-0.227792, r2-0.921338
Valid at fold-1: mse-0.181141
Traing Log at fold-1 epoch-97: mse-0.051608, rmse-0.227173, r2-0.92182
Valid at fold-1: mse-0.168293
Traing Log at fold-1 epoch-98: mse-0.050308, rmse-0.224293, r2-0.924029
Valid at fold-1: mse-0.16728
Traing Log at fold-1 epoch-99: mse-0.050032, rmse-0.223678, r2-0.92433
Valid at fold-1: mse-0.165965
Traing Log at fold-1 epoch-100: mse-0.049795, rmse-0.223147, r2-0.924828
Valid at fold-1: mse-0.169333
Traing Log at fold-1 epoch-101: mse-0.049128, rmse-0.221649, r2-0.925777
Valid at fold-1: mse-0.167439
Traing Log at fold-1 epoch-102: mse-0.047844, rmse-0.218732, r2-0.927911
Valid at fold-1: mse-0.16668
Traing Log at fold-1 epoch-103: mse-0.048139, rmse-0.219406, r2-0.927554
Valid at fold-1: mse-0.162028
Update best_mse, Valid at fold-1 epoch-103: mse-0.162028, rmse-0.402528, ci--1, r2-0.774259, pearson-0.881593, spearman-0.865785
Traing Log at fold-1 epoch-104: mse-0.04771, rmse-0.218427, r2-0.92805
Valid at fold-1: mse-0.164293
Traing Log at fold-1 epoch-105: mse-0.046701, rmse-0.216104, r2-0.92973
Valid at fold-1: mse-0.164429
Traing Log at fold-1 epoch-106: mse-0.045843, rmse-0.214111, r2-0.931223
Valid at fold-1: mse-0.167241
Traing Log at fold-1 epoch-107: mse-0.045361, rmse-0.212982, r2-0.931807
Valid at fold-1: mse-0.167189
Traing Log at fold-1 epoch-108: mse-0.045289, rmse-0.212811, r2-0.932065
Valid at fold-1: mse-0.165355
Traing Log at fold-1 epoch-109: mse-0.044671, rmse-0.211355, r2-0.93301
Valid at fold-1: mse-0.165782
Traing Log at fold-1 epoch-110: mse-0.043852, rmse-0.209408, r2-0.934274
Valid at fold-1: mse-0.168503
Traing Log at fold-1 epoch-111: mse-0.043356, rmse-0.208222, r2-0.935117
Valid at fold-1: mse-0.167778
Traing Log at fold-1 epoch-112: mse-0.042719, rmse-0.206686, r2-0.936129
Valid at fold-1: mse-0.163844
Traing Log at fold-1 epoch-113: mse-0.042448, rmse-0.206028, r2-0.936518
Valid at fold-1: mse-0.16124
Update best_mse, Valid at fold-1 epoch-113: mse-0.16124, rmse-0.401547, ci--1, r2-0.775358, pearson-0.883127, spearman-0.866983
Traing Log at fold-1 epoch-114: mse-0.041905, rmse-0.204707, r2-0.937499
Valid at fold-1: mse-0.162089
Traing Log at fold-1 epoch-115: mse-0.041643, rmse-0.204065, r2-0.937784
Valid at fold-1: mse-0.16506
Traing Log at fold-1 epoch-116: mse-0.041091, rmse-0.202709, r2-0.93869
Valid at fold-1: mse-0.164279
Traing Log at fold-1 epoch-117: mse-0.040791, rmse-0.201967, r2-0.939171
Valid at fold-1: mse-0.16345
Traing Log at fold-1 epoch-118: mse-0.04027, rmse-0.200674, r2-0.939957
Valid at fold-1: mse-0.162966
Traing Log at fold-1 epoch-119: mse-0.039474, rmse-0.198681, r2-0.941238
Valid at fold-1: mse-0.162029
Traing Log at fold-1 epoch-120: mse-0.039257, rmse-0.198134, r2-0.941555
Valid at fold-1: mse-0.167641
Traing Log at fold-1 epoch-121: mse-0.039139, rmse-0.197836, r2-0.94181
Valid at fold-1: mse-0.163078
Traing Log at fold-1 epoch-122: mse-0.03896, rmse-0.197384, r2-0.94206
Valid at fold-1: mse-0.161458
Traing Log at fold-1 epoch-123: mse-0.038247, rmse-0.19557, r2-0.943179
Valid at fold-1: mse-0.162164
Traing Log at fold-1 epoch-124: mse-0.037817, rmse-0.194467, r2-0.943885
Valid at fold-1: mse-0.164169
Traing Log at fold-1 epoch-125: mse-0.037299, rmse-0.193129, r2-0.94458
Valid at fold-1: mse-0.161216
Update best_mse, Valid at fold-1 epoch-125: mse-0.161216, rmse-0.401517, ci--1, r2-0.775391, pearson-0.883792, spearman-0.866709
Traing Log at fold-1 epoch-126: mse-0.037236, rmse-0.192968, r2-0.944762
Valid at fold-1: mse-0.162585
Traing Log at fold-1 epoch-127: mse-0.036332, rmse-0.190609, r2-0.946187
Valid at fold-1: mse-0.1596
Update best_mse, Valid at fold-1 epoch-127: mse-0.1596, rmse-0.3995, ci--1, r2-0.777642, pearson-0.882528, spearman-0.870329
Traing Log at fold-1 epoch-128: mse-0.036554, rmse-0.191192, r2-0.945848
Valid at fold-1: mse-0.162515
Traing Log at fold-1 epoch-129: mse-0.035704, rmse-0.188956, r2-0.94709
Valid at fold-1: mse-0.161715
Traing Log at fold-1 epoch-130: mse-0.036014, rmse-0.189774, r2-0.946708
Valid at fold-1: mse-0.159455
Update best_mse, Valid at fold-1 epoch-130: mse-0.159455, rmse-0.399318, ci--1, r2-0.777845, pearson-0.883023, spearman-0.867104
Traing Log at fold-1 epoch-131: mse-0.035706, rmse-0.188961, r2-0.947158
Valid at fold-1: mse-0.167464
Traing Log at fold-1 epoch-132: mse-0.035548, rmse-0.188541, r2-0.94741
Valid at fold-1: mse-0.164287
Traing Log at fold-1 epoch-133: mse-0.034747, rmse-0.186405, r2-0.948584
Valid at fold-1: mse-0.160633
Traing Log at fold-1 epoch-134: mse-0.034332, rmse-0.185289, r2-0.949291
Valid at fold-1: mse-0.161453
Traing Log at fold-1 epoch-135: mse-0.03404, rmse-0.184498, r2-0.949689
Valid at fold-1: mse-0.162072
Traing Log at fold-1 epoch-136: mse-0.033862, rmse-0.184017, r2-0.949993
Valid at fold-1: mse-0.159684
Traing Log at fold-1 epoch-137: mse-0.033685, rmse-0.183535, r2-0.950318
Valid at fold-1: mse-0.159931
Traing Log at fold-1 epoch-138: mse-0.033269, rmse-0.182399, r2-0.950938
Valid at fold-1: mse-0.166258
Traing Log at fold-1 epoch-139: mse-0.033083, rmse-0.181887, r2-0.95119
Valid at fold-1: mse-0.161311
Traing Log at fold-1 epoch-140: mse-0.032903, rmse-0.181393, r2-0.951508
Valid at fold-1: mse-0.161416
Traing Log at fold-1 epoch-141: mse-0.032702, rmse-0.180838, r2-0.951772
Valid at fold-1: mse-0.159002
Update best_mse, Valid at fold-1 epoch-141: mse-0.159002, rmse-0.398751, ci--1, r2-0.778475, pearson-0.885052, spearman-0.868726
Traing Log at fold-1 epoch-142: mse-0.032114, rmse-0.179204, r2-0.952708
Valid at fold-1: mse-0.159343
Traing Log at fold-1 epoch-143: mse-0.031742, rmse-0.178162, r2-0.953275
Valid at fold-1: mse-0.160741
Traing Log at fold-1 epoch-144: mse-0.031702, rmse-0.178052, r2-0.953282
Valid at fold-1: mse-0.159232
Traing Log at fold-1 epoch-145: mse-0.032022, rmse-0.178948, r2-0.952853
Valid at fold-1: mse-0.160696
Traing Log at fold-1 epoch-146: mse-0.03118, rmse-0.176578, r2-0.95415
Valid at fold-1: mse-0.158748
Update best_mse, Valid at fold-1 epoch-146: mse-0.158748, rmse-0.398432, ci--1, r2-0.778829, pearson-0.883637, spearman-0.871044
Traing Log at fold-1 epoch-147: mse-0.030789, rmse-0.175468, r2-0.954717
Valid at fold-1: mse-0.158932
Traing Log at fold-1 epoch-148: mse-0.030535, rmse-0.174742, r2-0.955136
Valid at fold-1: mse-0.158133
Update best_mse, Valid at fold-1 epoch-148: mse-0.158133, rmse-0.39766, ci--1, r2-0.779686, pearson-0.884108, spearman-0.872019
Traing Log at fold-1 epoch-149: mse-0.030617, rmse-0.174978, r2-0.954945
Valid at fold-1: mse-0.159856
Traing Log at fold-1 epoch-150: mse-0.029996, rmse-0.173193, r2-0.955961
Valid at fold-1: mse-0.162098
Traing Log at fold-1 epoch-151: mse-0.030088, rmse-0.173458, r2-0.955796
Valid at fold-1: mse-0.158685
Traing Log at fold-1 epoch-152: mse-0.02931, rmse-0.171203, r2-0.956967
Valid at fold-1: mse-0.162951
Traing Log at fold-1 epoch-153: mse-0.029479, rmse-0.171696, r2-0.956773
Valid at fold-1: mse-0.161818
Traing Log at fold-1 epoch-154: mse-0.029627, rmse-0.172125, r2-0.956477
Valid at fold-1: mse-0.160941
Traing Log at fold-1 epoch-155: mse-0.029262, rmse-0.171063, r2-0.95706
Valid at fold-1: mse-0.160862
Traing Log at fold-1 epoch-156: mse-0.028461, rmse-0.168703, r2-0.958312
Valid at fold-1: mse-0.162059
Traing Log at fold-1 epoch-157: mse-0.028463, rmse-0.16871, r2-0.958267
Valid at fold-1: mse-0.160031
Traing Log at fold-1 epoch-158: mse-0.028425, rmse-0.168598, r2-0.95833
Valid at fold-1: mse-0.162056
Traing Log at fold-1 epoch-159: mse-0.028462, rmse-0.168707, r2-0.958291
Valid at fold-1: mse-0.158447
Traing Log at fold-1 epoch-160: mse-0.028005, rmse-0.167347, r2-0.958943
Valid at fold-1: mse-0.158671
Traing Log at fold-1 epoch-161: mse-0.027849, rmse-0.166881, r2-0.959218
Valid at fold-1: mse-0.157808
Update best_mse, Valid at fold-1 epoch-161: mse-0.157808, rmse-0.397251, ci--1, r2-0.780139, pearson-0.884889, spearman-0.871522
Traing Log at fold-1 epoch-162: mse-0.027742, rmse-0.166561, r2-0.95938
Valid at fold-1: mse-0.159657
Traing Log at fold-1 epoch-163: mse-0.027445, rmse-0.165666, r2-0.95987
Valid at fold-1: mse-0.15943
Traing Log at fold-1 epoch-164: mse-0.027151, rmse-0.164777, r2-0.960238
Valid at fold-1: mse-0.158885
Traing Log at fold-1 epoch-165: mse-0.026829, rmse-0.163796, r2-0.960762
Valid at fold-1: mse-0.160131
Traing Log at fold-1 epoch-166: mse-0.026498, rmse-0.162782, r2-0.961269
Valid at fold-1: mse-0.156993
Update best_mse, Valid at fold-1 epoch-166: mse-0.156993, rmse-0.396223, ci--1, r2-0.781275, pearson-0.885643, spearman-0.870886
Traing Log at fold-1 epoch-167: mse-0.02681, rmse-0.163737, r2-0.96079
Valid at fold-1: mse-0.158337
Traing Log at fold-1 epoch-168: mse-0.026651, rmse-0.163251, r2-0.96103
Valid at fold-1: mse-0.157455
Traing Log at fold-1 epoch-169: mse-0.026653, rmse-0.163257, r2-0.96102
Valid at fold-1: mse-0.156883
Update best_mse, Valid at fold-1 epoch-169: mse-0.156883, rmse-0.396084, ci--1, r2-0.781428, pearson-0.884569, spearman-0.871858
Traing Log at fold-1 epoch-170: mse-0.026037, rmse-0.16136, r2-0.961966
Valid at fold-1: mse-0.158179
Traing Log at fold-1 epoch-171: mse-0.026057, rmse-0.16142, r2-0.961925
Valid at fold-1: mse-0.157565
Traing Log at fold-1 epoch-172: mse-0.025861, rmse-0.160813, r2-0.962251
Valid at fold-1: mse-0.156986
Traing Log at fold-1 epoch-173: mse-0.025671, rmse-0.160221, r2-0.962523
Valid at fold-1: mse-0.159939
Traing Log at fold-1 epoch-174: mse-0.025681, rmse-0.160254, r2-0.962486
Valid at fold-1: mse-0.15669
Update best_mse, Valid at fold-1 epoch-174: mse-0.15669, rmse-0.395841, ci--1, r2-0.781697, pearson-0.884841, spearman-0.872687
Traing Log at fold-1 epoch-175: mse-0.025262, rmse-0.158941, r2-0.963132
Valid at fold-1: mse-0.156755
Traing Log at fold-1 epoch-176: mse-0.025167, rmse-0.158642, r2-0.963307
Valid at fold-1: mse-0.157393
Traing Log at fold-1 epoch-177: mse-0.025377, rmse-0.159302, r2-0.96297
Valid at fold-1: mse-0.156823
Traing Log at fold-1 epoch-178: mse-0.024686, rmse-0.157119, r2-0.963993
Valid at fold-1: mse-0.157489
Traing Log at fold-1 epoch-179: mse-0.024651, rmse-0.157007, r2-0.964097
Valid at fold-1: mse-0.162201
Traing Log at fold-1 epoch-180: mse-0.024835, rmse-0.157591, r2-0.963763
Valid at fold-1: mse-0.166188
Traing Log at fold-1 epoch-181: mse-0.024524, rmse-0.156602, r2-0.964241
Valid at fold-1: mse-0.156154
Update best_mse, Valid at fold-1 epoch-181: mse-0.156154, rmse-0.395163, ci--1, r2-0.782443, pearson-0.886399, spearman-0.873449
Traing Log at fold-1 epoch-182: mse-0.024434, rmse-0.156312, r2-0.964395
Valid at fold-1: mse-0.158174
Traing Log at fold-1 epoch-183: mse-0.024182, rmse-0.155505, r2-0.964762
Valid at fold-1: mse-0.157121
Traing Log at fold-1 epoch-184: mse-0.024285, rmse-0.155835, r2-0.964609
Valid at fold-1: mse-0.158178
Traing Log at fold-1 epoch-185: mse-0.023955, rmse-0.154774, r2-0.965097
Valid at fold-1: mse-0.1596
Traing Log at fold-1 epoch-186: mse-0.023995, rmse-0.154903, r2-0.965061
Valid at fold-1: mse-0.15599
Update best_mse, Valid at fold-1 epoch-186: mse-0.15599, rmse-0.394955, ci--1, r2-0.782672, pearson-0.886314, spearman-0.874187
Traing Log at fold-1 epoch-187: mse-0.023806, rmse-0.154291, r2-0.965326
Valid at fold-1: mse-0.15534
Update best_mse, Valid at fold-1 epoch-187: mse-0.15534, rmse-0.394131, ci--1, r2-0.783578, pearson-0.886204, spearman-0.875061
Traing Log at fold-1 epoch-188: mse-0.023612, rmse-0.153662, r2-0.965615
Valid at fold-1: mse-0.152251
Update best_mse, Valid at fold-1 epoch-188: mse-0.152251, rmse-0.390194, ci--1, r2-0.787881, pearson-0.888801, spearman-0.876808
Traing Log at fold-1 epoch-189: mse-0.023355, rmse-0.152823, r2-0.965999
Valid at fold-1: mse-0.157045
Traing Log at fold-1 epoch-190: mse-0.023789, rmse-0.154236, r2-0.965341
Valid at fold-1: mse-0.154795
Traing Log at fold-1 epoch-191: mse-0.023119, rmse-0.152048, r2-0.966398
Valid at fold-1: mse-0.155173
Traing Log at fold-1 epoch-192: mse-0.022937, rmse-0.151451, r2-0.966635
Valid at fold-1: mse-0.157435
Traing Log at fold-1 epoch-193: mse-0.023163, rmse-0.152193, r2-0.966295
Valid at fold-1: mse-0.157475
Traing Log at fold-1 epoch-194: mse-0.023027, rmse-0.151747, r2-0.966502
Valid at fold-1: mse-0.158479
Traing Log at fold-1 epoch-195: mse-0.022801, rmse-0.151001, r2-0.966803
Valid at fold-1: mse-0.153499
Traing Log at fold-1 epoch-196: mse-0.022463, rmse-0.149876, r2-0.967344
Valid at fold-1: mse-0.154951
Traing Log at fold-1 epoch-197: mse-0.022442, rmse-0.149807, r2-0.967382
Valid at fold-1: mse-0.155565
Traing Log at fold-1 epoch-198: mse-0.022093, rmse-0.148637, r2-0.967874
Valid at fold-1: mse-0.15544
Traing Log at fold-1 epoch-199: mse-0.022137, rmse-0.148786, r2-0.967832
Valid at fold-1: mse-0.157641
Traing Log at fold-1 epoch-200: mse-0.022431, rmse-0.14977, r2-0.967369
Valid at fold-1: mse-0.15724
Save log over at ./log/Nov13_07-14-05-kiba-novel-prot-fold1.csv

============================================================
Testing fold 1 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-1, mse: 0.336454, rmse: 0.580047, ci: 0.741638, r2: 0.493695, pearson: 0.740611, spearman: 0.607227

Fold 1 results saved to: ./log/Test-kiba-novel-prot-fold1-Nov13_07-14-05.csv
============================================================
Training fold 1 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading wandb-summary.json; uploading output.log
wandb: uploading output.log
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–‡â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–ƒâ–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–‚â–„â–„â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–‡â–…â–…â–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.15225
wandb:  best_valid/pearson 0.8888
wandb:       best_valid/r2 0.78788
wandb:     best_valid/rmse 0.39019
wandb: best_valid/spearman 0.87681
wandb:               epoch 200
wandb:       final_test_ci 0.74164
wandb:      final_test_mse 0.33645
wandb:  final_test_pearson 0.74061
wandb:       final_test_r2 0.49369
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run kiba-novel-prot-fold1 at: https://wandb.ai/tringuyen/LLMDTA/runs/t2p0yrtm
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_071405-t2p0yrtm/logs
Weights & Biases run finished

Training for fold 1 completed successfully.
Python script exit code: 0
==========================================
End Time: Fri Nov 14 06:58:12 PM AEDT 2025
==========================================
