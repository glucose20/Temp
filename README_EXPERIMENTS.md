# ğŸ“¦ Files Created for Server Experiments

## Shell Scripts (executable)

### 1. **scripts/run_all_experiments.sh** â­ MAIN
- Cháº¡y Táº¤T Cáº¢ 60 experiments tuáº§n tá»± (sequential)
- PhÃ¹ há»£p: 1 GPU, cháº¡y an toÃ n
- Thá»i gian: ~30-60 giá»
- Tá»± Ä‘á»™ng: log tracking, error handling, aggregation

**Cháº¡y:**
```bash
bash scripts/run_all_experiments.sh
```

### 2. **scripts/run_all_experiments_parallel.sh** âš¡ FAST
- Cháº¡y song song vá»›i nhiá»u GPU
- PhÃ¹ há»£p: 2-4 GPUs
- Thá»i gian: ~8-30 giá» (tÃ¹y sá»‘ GPU)
- Tá»± Ä‘á»™ng phÃ¢n bá»• jobs lÃªn GPUs

**Cháº¡y:**
```bash
# Edit NUM_GPUS vÃ  GPU_DEVICES trÆ°á»›c
bash scripts/run_all_experiments_parallel.sh
```

### 3. **scripts/run_single_dataset.sh** ğŸ¯ FOCUSED
- Cháº¡y 1 dataset (20 runs: 4 settings Ã— 5 folds)
- PhÃ¹ há»£p: test hoáº·c chia nhá» workload
- Thá»i gian: ~10-20 giá»/dataset

**Cháº¡y:**
```bash
bash scripts/run_single_dataset.sh davis
bash scripts/run_single_dataset.sh kiba
bash scripts/run_single_dataset.sh metz
```

### 4. **scripts/setup_server.sh** ğŸ› ï¸ SETUP
- Setup tá»± Ä‘á»™ng: dependencies, data download, extract
- Chá»‰ cháº¡y 1 láº§n khi setup server má»›i

**Cháº¡y:**
```bash
bash scripts/setup_server.sh
```

---

## Python Scripts

### 5. **code/aggregate_results.py** ğŸ“Š (ÄÃƒ CÃ“ Sáº´N)
- Tá»•ng há»£p káº¿t quáº£ tá»« 5 folds
- Tá»± Ä‘á»™ng gá»i trong shell scripts
- CÃ³ thá»ƒ cháº¡y thá»§ cÃ´ng

**Cháº¡y:**
```bash
python code/aggregate_results.py --dataset davis --running_set warm
```

### 6. **code/generate_final_report.py** ğŸ“ˆ NEW
- Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p cuá»‘i cÃ¹ng cho Táº¤T Cáº¢ 60 runs
- So sÃ¡nh giá»¯a datasets vÃ  settings
- Xuáº¥t CSV vÃ  console output Ä‘áº¹p

**Cháº¡y:**
```bash
python code/generate_final_report.py
```

---

## Documentation

### 7. **EXPERIMENT_GUIDE.md** ğŸ“– DETAILED
- HÆ°á»›ng dáº«n CHI TIáº¾T Ä‘áº§y Ä‘á»§
- Setup, cÃ¡ch cháº¡y, theo dÃµi, troubleshooting
- VÃ­ dá»¥ vÃ  tips

### 8. **QUICK_START_SERVER.md** âš¡ QUICK
- Quick start ngáº¯n gá»n
- Copy-paste commands
- Troubleshooting nhanh

### 9. **README_EXPERIMENTS.md** ğŸ“‹ THIS FILE
- Tá»•ng quan táº¥t cáº£ files
- CÃ¡i nÃ o dÃ¹ng khi nÃ o

---

## Decision Tree - Chá»n script nÃ o?

```
Báº¡n cÃ³ bao nhiÃªu GPU?
â”‚
â”œâ”€ 1 GPU
â”‚  â”‚
â”‚  â”œâ”€ Muá»‘n cháº¡y táº¥t cáº£ 60 runs?
â”‚  â”‚  â””â”€ YES â†’ run_all_experiments.sh (sequential)
â”‚  â”‚
â”‚  â””â”€ Chá»‰ muá»‘n test 1 dataset?
â”‚     â””â”€ run_single_dataset.sh davis
â”‚
â””â”€ 2+ GPUs
   â”‚
   â”œâ”€ Muá»‘n nhanh nháº¥t?
   â”‚  â””â”€ run_all_experiments_parallel.sh (parallel)
   â”‚
   â””â”€ Muá»‘n chia thá»§ cÃ´ng?
      â””â”€ Má»Ÿ 3 terminals, má»—i cÃ¡i cháº¡y 1 dataset:
         - Terminal 1: run_single_dataset.sh davis  (GPU 0)
         - Terminal 2: run_single_dataset.sh kiba   (GPU 1)
         - Terminal 3: run_single_dataset.sh metz   (GPU 2)
```

---

## Workflow hoÃ n chá»‰nh

```bash
# 1. Setup (1 láº§n duy nháº¥t)
bash scripts/setup_server.sh

# 2. Test nhanh
python code/train.py --fold 0 --cuda "0" --dataset davis --running_set warm --epochs 2

# 3. Cháº¡y Táº¤T Cáº¢ experiments
tmux new -s llmdta
bash scripts/run_all_experiments.sh  # hoáº·c _parallel.sh

# Detach: Ctrl+B, D
# Check: tmux attach -t llmdta

# 4. Theo dÃµi
tail -f ./results/experiment_master_log_*.txt
watch -n 1 nvidia-smi

# 5. Tá»•ng há»£p káº¿t quáº£ (sau khi xong)
python code/generate_final_report.py

# 6. Download káº¿t quáº£ vá» local
scp -r user@server:/path/to/Temp/log ./
scp -r user@server:/path/to/Temp/savemodel ./
```

---

## File Structure sau khi cháº¡y xong

```
Temp/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_all_experiments.sh          â† MAIN: Sequential
â”‚   â”œâ”€â”€ run_all_experiments_parallel.sh â† FAST: Parallel
â”‚   â”œâ”€â”€ run_single_dataset.sh           â† FOCUSED: 1 dataset
â”‚   â””â”€â”€ setup_server.sh                 â† SETUP: Initialize
â”‚
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ train.py                        â† Core training (modified)
â”‚   â”œâ”€â”€ aggregate_results.py            â† Aggregate 5 folds
â”‚   â””â”€â”€ generate_final_report.py        â† Final report (NEW)
â”‚
â”œâ”€â”€ log/
â”‚   â”œâ”€â”€ experiment_master_log_*.txt     â† Master tracking
â”‚   â”œâ”€â”€ *-fold*.csv                     â† Individual runs (60 files)
â”‚   â”œâ”€â”€ Test-*-AGGREGATED.csv           â† Per setting (12 files)
â”‚   â”œâ”€â”€ Test-*-SUMMARY.csv              â† Statistics (12 files)
â”‚   â””â”€â”€ FINAL_SUMMARY_REPORT_*.csv      â† Final comparison
â”‚
â”œâ”€â”€ savemodel/
â”‚   â””â”€â”€ *.pth                           â† 60 model checkpoints
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ experiment_master_log_*.txt
â”‚   â””â”€â”€ run_*.log                       â† Per-run logs (60 files)
â”‚
â”œâ”€â”€ EXPERIMENT_GUIDE.md                 â† Detailed guide
â”œâ”€â”€ QUICK_START_SERVER.md               â† Quick start
â””â”€â”€ README_EXPERIMENTS.md               â† This file
```

---

## Checklist hoÃ n chá»‰nh

- [ ] Setup server: `bash scripts/setup_server.sh`
- [ ] Test run: `python code/train.py --fold 0 --cuda "0" --dataset davis --running_set warm --epochs 2`
- [ ] Chá»n strategy (sequential/parallel/single)
- [ ] Start tmux session
- [ ] Run experiments script
- [ ] Monitor progress (tail -f log)
- [ ] Wait for completion (~8-60 hours)
- [ ] Generate final report: `python code/generate_final_report.py`
- [ ] Download results to local
- [ ] Celebrate! ğŸ‰

---

## Support & Troubleshooting

**Common issues:**

1. **Out of memory**: Edit script, change `BATCH_SIZE=8`
2. **CUDA not available**: Check PyTorch installation
3. **File not found**: Run `setup_server.sh` again
4. **Script stops**: Use `tmux` or `nohup`
5. **Wrong GPU**: Edit `CUDA_DEVICE` in script

**Get help:**
- Read `EXPERIMENT_GUIDE.md` section "ğŸš¨ Xá»­ lÃ½ lá»—i"
- Check individual run logs in `./results/`
- Verify GPU: `nvidia-smi`
- Test single run first before batch

---

**Good luck with your experiments! ğŸš€**
