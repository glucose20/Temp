==========================================
Job ID: 2013072
Array Task ID: 4
Node: v100l-f-02
Start Time: Thu Nov 13 07:15:42 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 07:15:43 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:06:00.0 Off |                    0 |
| N/A   30C    P0             43W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 4...


============================================================
Starting training for Fold 4
Dataset: kiba, Running Set: novel-pair
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 4 --cuda 0 --dataset kiba --running_set novel-pair --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 4/4
Dataset: kiba-novel-pair
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/kiba/kiba_drug_pretrain.pkl
Pretrain-./data/kiba/kiba_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run 4m93mh3i
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_071549-4m93mh3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kiba-novel-pair-fold4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/tringuyen/LLMDTA
wandb: üöÄ View run at https://wandb.ai/tringuyen/LLMDTA/runs/4m93mh3i
Weights & Biases initialized: LLMDTA
Loading fold 4 data...
  Train: ./data/dta-5fold-dataset/kiba/novel-pair/fold_4_train.csv
  Valid: ./data/dta-5fold-dataset/kiba/novel-pair/fold_4_valid.csv
  Test:  ./data/dta-5fold-dataset/kiba/novel-pair/fold_4_test.csv
Dataset loaded: 41210 train, 57116 valid, 19928 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-4 epoch-1: mse-3.679127, rmse-1.918105, r2--0.138574
Valid at fold-4: mse-1.313318
Update best_mse, Valid at fold-4 epoch-1: mse-1.313318, rmse-1.146001, ci--1, r2--0.866597, pearson-0.325712, spearman-0.261068
Traing Log at fold-4 epoch-2: mse-0.567748, rmse-0.753491, r2--0.353872
Valid at fold-4: mse-0.511256
Update best_mse, Valid at fold-4 epoch-2: mse-0.511256, rmse-0.715022, ci--1, r2-0.27336, pearson-0.542504, spearman-0.479388
Traing Log at fold-4 epoch-3: mse-0.444793, rmse-0.666928, r2--0.154932
Valid at fold-4: mse-0.576259
Traing Log at fold-4 epoch-4: mse-0.395136, rmse-0.628598, r2--0.027537
Valid at fold-4: mse-0.479872
Update best_mse, Valid at fold-4 epoch-4: mse-0.479872, rmse-0.692728, ci--1, r2-0.317966, pearson-0.600034, spearman-0.588909
Traing Log at fold-4 epoch-5: mse-0.353639, rmse-0.594675, r2-0.133204
Valid at fold-4: mse-0.436816
Update best_mse, Valid at fold-4 epoch-5: mse-0.436816, rmse-0.660921, ci--1, r2-0.37916, pearson-0.641245, spearman-0.57252
Traing Log at fold-4 epoch-6: mse-0.323262, rmse-0.568562, r2-0.233145
Valid at fold-4: mse-0.495366
Traing Log at fold-4 epoch-7: mse-0.300948, rmse-0.548587, r2-0.312588
Valid at fold-4: mse-0.636356
Traing Log at fold-4 epoch-8: mse-0.281898, rmse-0.53094, r2-0.378218
Valid at fold-4: mse-0.662406
Traing Log at fold-4 epoch-9: mse-0.292521, rmse-0.540852, r2-0.398639
Valid at fold-4: mse-0.5182
Traing Log at fold-4 epoch-10: mse-0.242297, rmse-0.492236, r2-0.502729
Valid at fold-4: mse-0.66754
Traing Log at fold-4 epoch-11: mse-0.236307, rmse-0.486114, r2-0.525954
Valid at fold-4: mse-0.476445
Traing Log at fold-4 epoch-12: mse-0.239735, rmse-0.489627, r2-0.514411
Valid at fold-4: mse-0.678452
Traing Log at fold-4 epoch-13: mse-0.231874, rmse-0.481533, r2-0.538668
Valid at fold-4: mse-0.713465
Traing Log at fold-4 epoch-14: mse-0.224949, rmse-0.474288, r2-0.557954
Valid at fold-4: mse-0.688909
Traing Log at fold-4 epoch-15: mse-0.216953, rmse-0.465782, r2-0.579797
Valid at fold-4: mse-0.473171
Traing Log at fold-4 epoch-16: mse-0.208552, rmse-0.456675, r2-0.601304
Valid at fold-4: mse-0.718001
Traing Log at fold-4 epoch-17: mse-0.201734, rmse-0.449148, r2-0.620294
Valid at fold-4: mse-0.664236
Traing Log at fold-4 epoch-18: mse-0.199199, rmse-0.446317, r2-0.627502
Valid at fold-4: mse-0.550874
Traing Log at fold-4 epoch-19: mse-0.191877, rmse-0.438037, r2-0.643681
Valid at fold-4: mse-0.618279
Traing Log at fold-4 epoch-20: mse-0.185368, rmse-0.430543, r2-0.661152
Valid at fold-4: mse-0.766953
Traing Log at fold-4 epoch-21: mse-0.180332, rmse-0.424655, r2-0.673666
Valid at fold-4: mse-0.70323
Traing Log at fold-4 epoch-22: mse-0.176817, rmse-0.420496, r2-0.681761
Valid at fold-4: mse-0.573255
Traing Log at fold-4 epoch-23: mse-0.169718, rmse-0.411968, r2-0.697436
Valid at fold-4: mse-0.489817
Traing Log at fold-4 epoch-24: mse-0.166202, rmse-0.407678, r2-0.705589
Valid at fold-4: mse-0.494574
Traing Log at fold-4 epoch-25: mse-0.16218, rmse-0.402716, r2-0.716001
Valid at fold-4: mse-0.53146
Traing Log at fold-4 epoch-26: mse-0.158876, rmse-0.398593, r2-0.722237
Valid at fold-4: mse-0.708126
Traing stop at epoch-26, model save at-./savemodel/kiba-novel-pair-fold4-Nov13_07-15-49.pth
Save log over at ./log/Nov13_07-15-49-kiba-novel-pair-fold4.csv

============================================================
Testing fold 4 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-4, mse: 0.575015, rmse: 0.758297, ci: 0.62732, r2: 0.095882, pearson: 0.450664, spearman: 0.351948

Fold 4 results saved to: ./log/Test-kiba-novel-pair-fold4-Nov13_07-15-49.csv
============================================================
Training fold 4 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 56-56, summary, console lines 72-77
wandb: 
wandb: Run history:
wandb:      best_valid/mse ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb:  best_valid/pearson ‚ñÅ‚ñÜ‚ñá‚ñà
wandb:       best_valid/r2 ‚ñÅ‚ñá‚ñà‚ñà
wandb:     best_valid/rmse ‚ñà‚ñÇ‚ñÅ‚ñÅ
wandb: best_valid/spearman ‚ñÅ‚ñÜ‚ñà‚ñà
wandb:               epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:             test/ci ‚ñÅ
wandb:            test/mse ‚ñÅ
wandb:        test/pearson ‚ñÅ
wandb:             test/r2 ‚ñÅ
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.43682
wandb:  best_valid/pearson 0.64124
wandb:       best_valid/r2 0.37916
wandb:     best_valid/rmse 0.66092
wandb: best_valid/spearman 0.57252
wandb:               epoch 26
wandb:       final_test_ci 0.62732
wandb:      final_test_mse 0.57502
wandb:  final_test_pearson 0.45066
wandb:       final_test_r2 0.09588
wandb:                 +19 ...
wandb: 
wandb: üöÄ View run kiba-novel-pair-fold4 at: https://wandb.ai/tringuyen/LLMDTA/runs/4m93mh3i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_071549-4m93mh3i/logs
Weights & Biases run finished

Training for fold 4 completed successfully.
Python script exit code: 0
==========================================
End Time: Thu Nov 13 12:04:33 PM AEDT 2025
==========================================
