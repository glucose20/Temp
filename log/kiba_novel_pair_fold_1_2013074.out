==========================================
Job ID: 2013074
Array Task ID: 1
Node: v100l-f-06
Start Time: Thu Nov 13 07:15:43 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 07:15:43 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:86:00.0 Off |                    0 |
| N/A   35C    P0             43W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 1...


============================================================
Starting training for Fold 1
Dataset: kiba, Running Set: novel-pair
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 1 --cuda 0 --dataset kiba --running_set novel-pair --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 1/4
Dataset: kiba-novel-pair
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/kiba/kiba_drug_pretrain.pkl
Pretrain-./data/kiba/kiba_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run ypqqxa3r
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_071549-ypqqxa3r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kiba-novel-pair-fold1
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/ypqqxa3r
Weights & Biases initialized: LLMDTA
Loading fold 1 data...
  Train: ./data/dta-5fold-dataset/kiba/novel-pair/fold_1_train.csv
  Valid: ./data/dta-5fold-dataset/kiba/novel-pair/fold_1_valid.csv
  Test:  ./data/dta-5fold-dataset/kiba/novel-pair/fold_1_test.csv
Dataset loaded: 41484 train, 57195 valid, 19575 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-1 epoch-1: mse-3.75656, rmse-1.938185, r2--0.113088
Valid at fold-1: mse-1.781191
Update best_mse, Valid at fold-1 epoch-1: mse-1.781191, rmse-1.334613, ci--1, r2--1.531647, pearson-0.411104, spearman-0.435511
Traing Log at fold-1 epoch-2: mse-0.55202, rmse-0.742981, r2--0.313708
Valid at fold-1: mse-0.532946
Update best_mse, Valid at fold-1 epoch-2: mse-0.532946, rmse-0.730032, ci--1, r2-0.242512, pearson-0.554994, spearman-0.534415
Traing Log at fold-1 epoch-3: mse-0.43969, rmse-0.663091, r2--0.157677
Valid at fold-1: mse-0.489745
Update best_mse, Valid at fold-1 epoch-3: mse-0.489745, rmse-0.699818, ci--1, r2-0.303915, pearson-0.583154, spearman-0.550906
Traing Log at fold-1 epoch-4: mse-0.372291, rmse-0.610156, r2--0.011866
Valid at fold-1: mse-0.459563
Update best_mse, Valid at fold-1 epoch-4: mse-0.459563, rmse-0.677911, ci--1, r2-0.346813, pearson-0.625461, spearman-0.585082
Traing Log at fold-1 epoch-5: mse-0.328016, rmse-0.572727, r2-0.13721
Valid at fold-1: mse-0.405745
Update best_mse, Valid at fold-1 epoch-5: mse-0.405745, rmse-0.636981, ci--1, r2-0.423306, pearson-0.657438, spearman-0.617956
Traing Log at fold-1 epoch-6: mse-0.299666, rmse-0.547417, r2-0.248116
Valid at fold-1: mse-0.388899
Update best_mse, Valid at fold-1 epoch-6: mse-0.388899, rmse-0.623618, ci--1, r2-0.447249, pearson-0.671587, spearman-0.630893
Traing Log at fold-1 epoch-7: mse-0.27777, rmse-0.527039, r2-0.327502
Valid at fold-1: mse-0.388993
Traing Log at fold-1 epoch-8: mse-0.262467, rmse-0.512316, r2-0.388042
Valid at fold-1: mse-0.381093
Update best_mse, Valid at fold-1 epoch-8: mse-0.381093, rmse-0.617327, ci--1, r2-0.458344, pearson-0.685738, spearman-0.636325
Traing Log at fold-1 epoch-9: mse-0.248118, rmse-0.498115, r2-0.434687
Valid at fold-1: mse-0.381884
Traing Log at fold-1 epoch-10: mse-0.23595, rmse-0.485747, r2-0.479147
Valid at fold-1: mse-0.384675
Traing Log at fold-1 epoch-11: mse-0.228005, rmse-0.477498, r2-0.505029
Valid at fold-1: mse-0.370963
Update best_mse, Valid at fold-1 epoch-11: mse-0.370963, rmse-0.609067, ci--1, r2-0.472742, pearson-0.705827, spearman-0.658674
Traing Log at fold-1 epoch-12: mse-0.217665, rmse-0.466545, r2-0.5375
Valid at fold-1: mse-0.358013
Update best_mse, Valid at fold-1 epoch-12: mse-0.358013, rmse-0.598342, ci--1, r2-0.491148, pearson-0.713739, spearman-0.673249
Traing Log at fold-1 epoch-13: mse-0.210031, rmse-0.458292, r2-0.560304
Valid at fold-1: mse-0.370505
Traing Log at fold-1 epoch-14: mse-0.204362, rmse-0.452064, r2-0.577313
Valid at fold-1: mse-0.360016
Traing Log at fold-1 epoch-15: mse-0.198255, rmse-0.445259, r2-0.594359
Valid at fold-1: mse-0.337641
Update best_mse, Valid at fold-1 epoch-15: mse-0.337641, rmse-0.581069, ci--1, r2-0.520103, pearson-0.725583, spearman-0.688824
Traing Log at fold-1 epoch-16: mse-0.190952, rmse-0.436981, r2-0.615689
Valid at fold-1: mse-0.343529
Traing Log at fold-1 epoch-17: mse-0.186161, rmse-0.431463, r2-0.628073
Valid at fold-1: mse-0.340742
Traing Log at fold-1 epoch-18: mse-0.180005, rmse-0.42427, r2-0.645086
Valid at fold-1: mse-0.345087
Traing Log at fold-1 epoch-19: mse-0.17515, rmse-0.41851, r2-0.65797
Valid at fold-1: mse-0.346044
Traing Log at fold-1 epoch-20: mse-0.170395, rmse-0.412789, r2-0.670637
Valid at fold-1: mse-0.345552
Traing Log at fold-1 epoch-21: mse-0.1671, rmse-0.408779, r2-0.677749
Valid at fold-1: mse-0.342878
Traing Log at fold-1 epoch-22: mse-0.161737, rmse-0.402166, r2-0.693171
Valid at fold-1: mse-0.322874
Update best_mse, Valid at fold-1 epoch-22: mse-0.322874, rmse-0.56822, ci--1, r2-0.541092, pearson-0.738294, spearman-0.693798
Traing Log at fold-1 epoch-23: mse-0.158364, rmse-0.397949, r2-0.69969
Valid at fold-1: mse-0.328533
Traing Log at fold-1 epoch-24: mse-0.1543, rmse-0.39281, r2-0.71039
Valid at fold-1: mse-0.327603
Traing Log at fold-1 epoch-25: mse-0.153243, rmse-0.391462, r2-0.713255
Valid at fold-1: mse-0.326998
Traing Log at fold-1 epoch-26: mse-0.148129, rmse-0.384875, r2-0.724762
Valid at fold-1: mse-0.317196
Update best_mse, Valid at fold-1 epoch-26: mse-0.317196, rmse-0.563201, ci--1, r2-0.549163, pearson-0.749726, spearman-0.700063
Traing Log at fold-1 epoch-27: mse-0.143781, rmse-0.379184, r2-0.735537
Valid at fold-1: mse-0.319804
Traing Log at fold-1 epoch-28: mse-0.141018, rmse-0.375523, r2-0.741116
Valid at fold-1: mse-0.317264
Traing Log at fold-1 epoch-29: mse-0.138762, rmse-0.372508, r2-0.746753
Valid at fold-1: mse-0.320053
Traing Log at fold-1 epoch-30: mse-0.134551, rmse-0.366812, r2-0.756213
Valid at fold-1: mse-0.319849
Traing Log at fold-1 epoch-31: mse-0.132874, rmse-0.364518, r2-0.760567
Valid at fold-1: mse-0.321564
Traing Log at fold-1 epoch-32: mse-0.132172, rmse-0.363555, r2-0.762036
Valid at fold-1: mse-0.323485
Traing Log at fold-1 epoch-33: mse-0.128071, rmse-0.357871, r2-0.770583
Valid at fold-1: mse-0.318347
Traing Log at fold-1 epoch-34: mse-0.125227, rmse-0.353874, r2-0.776878
Valid at fold-1: mse-0.31774
Traing Log at fold-1 epoch-35: mse-0.123566, rmse-0.35152, r2-0.781102
Valid at fold-1: mse-0.306433
Update best_mse, Valid at fold-1 epoch-35: mse-0.306433, rmse-0.553564, ci--1, r2-0.56446, pearson-0.75363, spearman-0.707377
Traing Log at fold-1 epoch-36: mse-0.122367, rmse-0.34981, r2-0.78298
Valid at fold-1: mse-0.3322
Traing Log at fold-1 epoch-37: mse-0.118955, rmse-0.344898, r2-0.790779
Valid at fold-1: mse-0.313863
Traing Log at fold-1 epoch-38: mse-0.11564, rmse-0.340059, r2-0.797124
Valid at fold-1: mse-0.317034
Traing Log at fold-1 epoch-39: mse-0.115448, rmse-0.339777, r2-0.797738
Valid at fold-1: mse-0.319058
Traing Log at fold-1 epoch-40: mse-0.112283, rmse-0.335086, r2-0.80461
Valid at fold-1: mse-0.316858
Traing Log at fold-1 epoch-41: mse-0.110972, rmse-0.333124, r2-0.807949
Valid at fold-1: mse-0.313162
Traing Log at fold-1 epoch-42: mse-0.109308, rmse-0.330618, r2-0.810714
Valid at fold-1: mse-0.320245
Traing Log at fold-1 epoch-43: mse-0.106215, rmse-0.325906, r2-0.817233
Valid at fold-1: mse-0.307049
Traing Log at fold-1 epoch-44: mse-0.106612, rmse-0.326514, r2-0.816395
Valid at fold-1: mse-0.304075
Update best_mse, Valid at fold-1 epoch-44: mse-0.304075, rmse-0.55143, ci--1, r2-0.567811, pearson-0.758941, spearman-0.711598
Traing Log at fold-1 epoch-45: mse-0.104059, rmse-0.322581, r2-0.821558
Valid at fold-1: mse-0.313576
Traing Log at fold-1 epoch-46: mse-0.103162, rmse-0.321188, r2-0.823059
Valid at fold-1: mse-0.306239
Traing Log at fold-1 epoch-47: mse-0.10022, rmse-0.316575, r2-0.828954
Valid at fold-1: mse-0.305554
Traing Log at fold-1 epoch-48: mse-0.09866, rmse-0.314102, r2-0.832329
Valid at fold-1: mse-0.311011
Traing Log at fold-1 epoch-49: mse-0.097532, rmse-0.3123, r2-0.834637
Valid at fold-1: mse-0.31174
Traing Log at fold-1 epoch-50: mse-0.0955, rmse-0.309031, r2-0.838466
Valid at fold-1: mse-0.314341
Traing Log at fold-1 epoch-51: mse-0.095392, rmse-0.308857, r2-0.838758
Valid at fold-1: mse-0.300684
Update best_mse, Valid at fold-1 epoch-51: mse-0.300684, rmse-0.548347, ci--1, r2-0.572631, pearson-0.761242, spearman-0.713487
Traing Log at fold-1 epoch-52: mse-0.093227, rmse-0.305331, r2-0.842818
Valid at fold-1: mse-0.300515
Update best_mse, Valid at fold-1 epoch-52: mse-0.300515, rmse-0.548192, ci--1, r2-0.572872, pearson-0.764395, spearman-0.720832
Traing Log at fold-1 epoch-53: mse-0.091501, rmse-0.302492, r2-0.846354
Valid at fold-1: mse-0.302111
Traing Log at fold-1 epoch-54: mse-0.09006, rmse-0.300101, r2-0.849167
Valid at fold-1: mse-0.301607
Traing Log at fold-1 epoch-55: mse-0.089665, rmse-0.29944, r2-0.84954
Valid at fold-1: mse-0.298439
Update best_mse, Valid at fold-1 epoch-55: mse-0.298439, rmse-0.546296, ci--1, r2-0.575822, pearson-0.766156, spearman-0.713768
Traing Log at fold-1 epoch-56: mse-0.087284, rmse-0.295438, r2-0.854345
Valid at fold-1: mse-0.308766
Traing Log at fold-1 epoch-57: mse-0.086134, rmse-0.293486, r2-0.856799
Valid at fold-1: mse-0.304976
Traing Log at fold-1 epoch-58: mse-0.084438, rmse-0.290582, r2-0.859608
Valid at fold-1: mse-0.314295
Traing Log at fold-1 epoch-59: mse-0.08404, rmse-0.289897, r2-0.860606
Valid at fold-1: mse-0.30456
Traing Log at fold-1 epoch-60: mse-0.083119, rmse-0.288303, r2-0.862371
Valid at fold-1: mse-0.301682
Traing Log at fold-1 epoch-61: mse-0.080737, rmse-0.284143, r2-0.86682
Valid at fold-1: mse-0.297451
Update best_mse, Valid at fold-1 epoch-61: mse-0.297451, rmse-0.545391, ci--1, r2-0.577226, pearson-0.76662, spearman-0.720797
Traing Log at fold-1 epoch-62: mse-0.080444, rmse-0.283627, r2-0.867322
Valid at fold-1: mse-0.305844
Traing Log at fold-1 epoch-63: mse-0.078907, rmse-0.280904, r2-0.870244
Valid at fold-1: mse-0.301239
Traing Log at fold-1 epoch-64: mse-0.078847, rmse-0.280798, r2-0.870273
Valid at fold-1: mse-0.303197
Traing Log at fold-1 epoch-65: mse-0.077241, rmse-0.277923, r2-0.873248
Valid at fold-1: mse-0.296645
Update best_mse, Valid at fold-1 epoch-65: mse-0.296645, rmse-0.544651, ci--1, r2-0.578372, pearson-0.766222, spearman-0.714698
Traing Log at fold-1 epoch-66: mse-0.075722, rmse-0.275176, r2-0.875912
Valid at fold-1: mse-0.302069
Traing Log at fold-1 epoch-67: mse-0.075469, rmse-0.274717, r2-0.876571
Valid at fold-1: mse-0.291424
Update best_mse, Valid at fold-1 epoch-67: mse-0.291424, rmse-0.539837, ci--1, r2-0.585792, pearson-0.77098, spearman-0.714991
Traing Log at fold-1 epoch-68: mse-0.073935, rmse-0.271911, r2-0.879393
Valid at fold-1: mse-0.300803
Traing Log at fold-1 epoch-69: mse-0.073179, rmse-0.270517, r2-0.880798
Valid at fold-1: mse-0.300083
Traing Log at fold-1 epoch-70: mse-0.072257, rmse-0.268807, r2-0.882516
Valid at fold-1: mse-0.296669
Traing Log at fold-1 epoch-71: mse-0.070969, rmse-0.266401, r2-0.884493
Valid at fold-1: mse-0.295198
Traing Log at fold-1 epoch-72: mse-0.070343, rmse-0.265223, r2-0.885939
Valid at fold-1: mse-0.295134
Traing Log at fold-1 epoch-73: mse-0.068939, rmse-0.262562, r2-0.888497
Valid at fold-1: mse-0.297929
Traing Log at fold-1 epoch-74: mse-0.0684, rmse-0.261534, r2-0.88927
Valid at fold-1: mse-0.292158
Traing Log at fold-1 epoch-75: mse-0.067265, rmse-0.259355, r2-0.891348
Valid at fold-1: mse-0.293338
Traing Log at fold-1 epoch-76: mse-0.067028, rmse-0.258898, r2-0.891832
Valid at fold-1: mse-0.287789
Update best_mse, Valid at fold-1 epoch-76: mse-0.287789, rmse-0.53646, ci--1, r2-0.590959, pearson-0.774308, spearman-0.723228
Traing Log at fold-1 epoch-77: mse-0.066179, rmse-0.257253, r2-0.893337
Valid at fold-1: mse-0.307099
Traing Log at fold-1 epoch-78: mse-0.065761, rmse-0.256439, r2-0.894201
Valid at fold-1: mse-0.296088
Traing Log at fold-1 epoch-79: mse-0.063685, rmse-0.252358, r2-0.897828
Valid at fold-1: mse-0.291891
Traing Log at fold-1 epoch-80: mse-0.063575, rmse-0.252141, r2-0.897925
Valid at fold-1: mse-0.294159
Traing Log at fold-1 epoch-81: mse-0.062722, rmse-0.250443, r2-0.899418
Valid at fold-1: mse-0.290883
Traing Log at fold-1 epoch-82: mse-0.06197, rmse-0.248937, r2-0.900745
Valid at fold-1: mse-0.302214
Traing Log at fold-1 epoch-83: mse-0.061008, rmse-0.246997, r2-0.902551
Valid at fold-1: mse-0.293976
Traing Log at fold-1 epoch-84: mse-0.061919, rmse-0.248835, r2-0.901044
Valid at fold-1: mse-0.29059
Traing Log at fold-1 epoch-85: mse-0.059719, rmse-0.244376, r2-0.904535
Valid at fold-1: mse-0.290797
Traing Log at fold-1 epoch-86: mse-0.059838, rmse-0.244618, r2-0.904559
Valid at fold-1: mse-0.295258
Traing Log at fold-1 epoch-87: mse-0.059109, rmse-0.243123, r2-0.905801
Valid at fold-1: mse-0.294827
Traing Log at fold-1 epoch-88: mse-0.058007, rmse-0.240847, r2-0.907556
Valid at fold-1: mse-0.293846
Traing Log at fold-1 epoch-89: mse-0.056585, rmse-0.237876, r2-0.910204
Valid at fold-1: mse-0.294192
Traing Log at fold-1 epoch-90: mse-0.056687, rmse-0.23809, r2-0.910001
Valid at fold-1: mse-0.286089
Update best_mse, Valid at fold-1 epoch-90: mse-0.286089, rmse-0.534873, ci--1, r2-0.593375, pearson-0.775101, spearman-0.730518
Traing Log at fold-1 epoch-91: mse-0.056126, rmse-0.236909, r2-0.910986
Valid at fold-1: mse-0.294309
Traing Log at fold-1 epoch-92: mse-0.054892, rmse-0.23429, r2-0.913135
Valid at fold-1: mse-0.285211
Update best_mse, Valid at fold-1 epoch-92: mse-0.285211, rmse-0.534052, ci--1, r2-0.594623, pearson-0.775453, spearman-0.729494
Traing Log at fold-1 epoch-93: mse-0.055353, rmse-0.235273, r2-0.912313
Valid at fold-1: mse-0.285898
Traing Log at fold-1 epoch-94: mse-0.05482, rmse-0.234137, r2-0.913109
Valid at fold-1: mse-0.294755
Traing Log at fold-1 epoch-95: mse-0.053763, rmse-0.23187, r2-0.91508
Valid at fold-1: mse-0.291037
Traing Log at fold-1 epoch-96: mse-0.053109, rmse-0.230455, r2-0.916122
Valid at fold-1: mse-0.291237
Traing Log at fold-1 epoch-97: mse-0.051989, rmse-0.228011, r2-0.918101
Valid at fold-1: mse-0.291707
Traing Log at fold-1 epoch-98: mse-0.052786, rmse-0.229753, r2-0.916752
Valid at fold-1: mse-0.298772
Traing Log at fold-1 epoch-99: mse-0.051062, rmse-0.225969, r2-0.91968
Valid at fold-1: mse-0.298189
Traing Log at fold-1 epoch-100: mse-0.050936, rmse-0.225691, r2-0.919966
Valid at fold-1: mse-0.287873
Traing Log at fold-1 epoch-101: mse-0.049793, rmse-0.223143, r2-0.921676
Valid at fold-1: mse-0.283159
Update best_mse, Valid at fold-1 epoch-101: mse-0.283159, rmse-0.532127, ci--1, r2-0.59754, pearson-0.779007, spearman-0.732773
Traing Log at fold-1 epoch-102: mse-0.049315, rmse-0.22207, r2-0.92257
Valid at fold-1: mse-0.291588
Traing Log at fold-1 epoch-103: mse-0.049617, rmse-0.22275, r2-0.922019
Valid at fold-1: mse-0.286986
Traing Log at fold-1 epoch-104: mse-0.048504, rmse-0.220237, r2-0.924044
Valid at fold-1: mse-0.290289
Traing Log at fold-1 epoch-105: mse-0.04835, rmse-0.219886, r2-0.924215
Valid at fold-1: mse-0.289011
Traing Log at fold-1 epoch-106: mse-0.047446, rmse-0.217821, r2-0.925736
Valid at fold-1: mse-0.289094
Traing Log at fold-1 epoch-107: mse-0.046803, rmse-0.216341, r2-0.926843
Valid at fold-1: mse-0.286788
Traing Log at fold-1 epoch-108: mse-0.04687, rmse-0.216495, r2-0.926589
Valid at fold-1: mse-0.286052
Traing Log at fold-1 epoch-109: mse-0.046632, rmse-0.215945, r2-0.927118
Valid at fold-1: mse-0.287181
Traing Log at fold-1 epoch-110: mse-0.045647, rmse-0.213652, r2-0.928758
Valid at fold-1: mse-0.284586
Traing Log at fold-1 epoch-111: mse-0.045794, rmse-0.213996, r2-0.92838
Valid at fold-1: mse-0.289209
Traing Log at fold-1 epoch-112: mse-0.045575, rmse-0.213483, r2-0.928959
Valid at fold-1: mse-0.283802
Traing Log at fold-1 epoch-113: mse-0.044141, rmse-0.210099, r2-0.931225
Valid at fold-1: mse-0.291939
Traing Log at fold-1 epoch-114: mse-0.043921, rmse-0.209573, r2-0.931646
Valid at fold-1: mse-0.286125
Traing Log at fold-1 epoch-115: mse-0.044287, rmse-0.210445, r2-0.931028
Valid at fold-1: mse-0.284682
Traing Log at fold-1 epoch-116: mse-0.043378, rmse-0.208274, r2-0.932535
Valid at fold-1: mse-0.281195
Update best_mse, Valid at fold-1 epoch-116: mse-0.281195, rmse-0.530278, ci--1, r2-0.600332, pearson-0.778417, spearman-0.734818
Traing Log at fold-1 epoch-117: mse-0.042703, rmse-0.206648, r2-0.933536
Valid at fold-1: mse-0.288684
Traing Log at fold-1 epoch-118: mse-0.04299, rmse-0.207341, r2-0.933119
Valid at fold-1: mse-0.285906
Traing Log at fold-1 epoch-119: mse-0.04206, rmse-0.205084, r2-0.934764
Valid at fold-1: mse-0.284376
Traing Log at fold-1 epoch-120: mse-0.041335, rmse-0.203311, r2-0.93597
Valid at fold-1: mse-0.284795
Traing Log at fold-1 epoch-121: mse-0.040902, rmse-0.202243, r2-0.93659
Valid at fold-1: mse-0.282635
Traing Log at fold-1 epoch-122: mse-0.040681, rmse-0.201695, r2-0.93691
Valid at fold-1: mse-0.281494
Traing Log at fold-1 epoch-123: mse-0.040229, rmse-0.200572, r2-0.937574
Valid at fold-1: mse-0.290134
Traing Log at fold-1 epoch-124: mse-0.039819, rmse-0.199548, r2-0.9385
Valid at fold-1: mse-0.284438
Traing Log at fold-1 epoch-125: mse-0.03932, rmse-0.198292, r2-0.939196
Valid at fold-1: mse-0.283226
Traing Log at fold-1 epoch-126: mse-0.038948, rmse-0.197352, r2-0.939713
Valid at fold-1: mse-0.286949
Traing Log at fold-1 epoch-127: mse-0.039074, rmse-0.19767, r2-0.939639
Valid at fold-1: mse-0.288586
Traing Log at fold-1 epoch-128: mse-0.038429, rmse-0.196033, r2-0.940652
Valid at fold-1: mse-0.286158
Traing Log at fold-1 epoch-129: mse-0.038315, rmse-0.195741, r2-0.940784
Valid at fold-1: mse-0.285322
Traing Log at fold-1 epoch-130: mse-0.03813, rmse-0.195268, r2-0.941196
Valid at fold-1: mse-0.281791
Traing Log at fold-1 epoch-131: mse-0.03748, rmse-0.193597, r2-0.942125
Valid at fold-1: mse-0.293891
Traing Log at fold-1 epoch-132: mse-0.036733, rmse-0.191659, r2-0.943427
Valid at fold-1: mse-0.286425
Traing Log at fold-1 epoch-133: mse-0.037304, rmse-0.193143, r2-0.9425
Valid at fold-1: mse-0.288971
Traing Log at fold-1 epoch-134: mse-0.036679, rmse-0.191517, r2-0.943499
Valid at fold-1: mse-0.287342
Traing Log at fold-1 epoch-135: mse-0.035733, rmse-0.189033, r2-0.944989
Valid at fold-1: mse-0.286202
Traing Log at fold-1 epoch-136: mse-0.036396, rmse-0.190778, r2-0.943966
Valid at fold-1: mse-0.285951
Traing Log at fold-1 epoch-137: mse-0.035384, rmse-0.188108, r2-0.945592
Valid at fold-1: mse-0.286233
Traing stop at epoch-137, model save at-./savemodel/kiba-novel-pair-fold1-Nov13_07-15-48.pth
Save log over at ./log/Nov13_07-15-48-kiba-novel-pair-fold1.csv

============================================================
Testing fold 1 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-1, mse: 0.539649, rmse: 0.734608, ci: 0.663278, r2: 0.252545, pearson: 0.518616, spearman: 0.437219

Fold 1 results saved to: ./log/Test-kiba-novel-pair-fold1-Nov13_07-15-48.csv
============================================================
Training fold 1 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 299-299, summary, console lines 315-320
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–„â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–ƒâ–„â–„â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.28119
wandb:  best_valid/pearson 0.77842
wandb:       best_valid/r2 0.60033
wandb:     best_valid/rmse 0.53028
wandb: best_valid/spearman 0.73482
wandb:               epoch 137
wandb:       final_test_ci 0.66328
wandb:      final_test_mse 0.53965
wandb:  final_test_pearson 0.51862
wandb:       final_test_r2 0.25255
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run kiba-novel-pair-fold1 at: https://wandb.ai/tringuyen/LLMDTA/runs/ypqqxa3r
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_071549-ypqqxa3r/logs
Weights & Biases run finished

Training for fold 1 completed successfully.
Python script exit code: 0
==========================================
End Time: Fri Nov 14 07:06:15 AM AEDT 2025
==========================================
