==========================================
Job ID: 2013089
Array Task ID: 1
Node: v100l-f-01
Start Time: Thu Nov 13 07:19:43 AM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Thu Nov 13 07:19:43 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:07:00.0 Off |                    0 |
| N/A   33C    P0             41W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 1...


============================================================
Starting training for Fold 1
Dataset: metz, Running Set: novel-drug
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 1 --cuda 0 --dataset metz --running_set novel-drug --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 1/4
Dataset: metz-novel-drug
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/metz/metz_drug_pretrain.pkl
Pretrain-./data/metz/metz_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run jktqtruy
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251113_071950-jktqtruy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run metz-novel-drug-fold1
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/jktqtruy
Weights & Biases initialized: LLMDTA
Loading fold 1 data...
  Train: ./data/dta-5fold-dataset/metz/novel-drug/fold_1_train.csv
  Valid: ./data/dta-5fold-dataset/metz/novel-drug/fold_1_valid.csv
  Test:  ./data/dta-5fold-dataset/metz/novel-drug/fold_1_test.csv
Dataset loaded: 22609 train, 5653 valid, 6997 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-1 epoch-1: mse-2.134616, rmse-1.461032, r2--0.208944
Valid at fold-1: mse-2.100648
Update best_mse, Valid at fold-1 epoch-1: mse-2.100648, rmse-1.449361, ci--1, r2--1.326776, pearson-0.420547, spearman-0.392191
Traing Log at fold-1 epoch-2: mse-0.772275, rmse-0.878792, r2--0.167431
Valid at fold-1: mse-0.707469
Update best_mse, Valid at fold-1 epoch-2: mse-0.707469, rmse-0.841112, ci--1, r2-0.216374, pearson-0.592803, spearman-0.544483
Traing Log at fold-1 epoch-3: mse-0.635851, rmse-0.797403, r2--0.065634
Valid at fold-1: mse-0.754965
Traing Log at fold-1 epoch-4: mse-0.55191, rmse-0.742907, r2--0.00017
Valid at fold-1: mse-0.570526
Update best_mse, Valid at fold-1 epoch-4: mse-0.570526, rmse-0.755332, ci--1, r2-0.368059, pearson-0.662574, spearman-0.615166
Traing Log at fold-1 epoch-5: mse-0.495081, rmse-0.70362, r2-0.090076
Valid at fold-1: mse-0.498119
Update best_mse, Valid at fold-1 epoch-5: mse-0.498119, rmse-0.705775, ci--1, r2-0.44826, pearson-0.687212, spearman-0.63532
Traing Log at fold-1 epoch-6: mse-0.456342, rmse-0.675531, r2-0.144051
Valid at fold-1: mse-0.434828
Update best_mse, Valid at fold-1 epoch-6: mse-0.434828, rmse-0.659415, ci--1, r2-0.518364, pearson-0.726151, spearman-0.68042
Traing Log at fold-1 epoch-7: mse-0.424685, rmse-0.651678, r2-0.217332
Valid at fold-1: mse-0.423379
Update best_mse, Valid at fold-1 epoch-7: mse-0.423379, rmse-0.650676, ci--1, r2-0.531046, pearson-0.739345, spearman-0.700902
Traing Log at fold-1 epoch-8: mse-0.406186, rmse-0.637327, r2-0.260893
Valid at fold-1: mse-0.434291
Traing Log at fold-1 epoch-9: mse-0.387321, rmse-0.622351, r2-0.30981
Valid at fold-1: mse-0.460312
Traing Log at fold-1 epoch-10: mse-0.370658, rmse-0.608817, r2-0.352637
Valid at fold-1: mse-0.395924
Update best_mse, Valid at fold-1 epoch-10: mse-0.395924, rmse-0.629225, ci--1, r2-0.561456, pearson-0.754477, spearman-0.711456
Traing Log at fold-1 epoch-11: mse-0.357105, rmse-0.597583, r2-0.387324
Valid at fold-1: mse-0.394706
Update best_mse, Valid at fold-1 epoch-11: mse-0.394706, rmse-0.628256, ci--1, r2-0.562805, pearson-0.758515, spearman-0.714818
Traing Log at fold-1 epoch-12: mse-0.338782, rmse-0.58205, r2-0.43182
Valid at fold-1: mse-0.381653
Update best_mse, Valid at fold-1 epoch-12: mse-0.381653, rmse-0.617781, ci--1, r2-0.577263, pearson-0.763565, spearman-0.724113
Traing Log at fold-1 epoch-13: mse-0.329276, rmse-0.573826, r2-0.457279
Valid at fold-1: mse-0.384434
Traing Log at fold-1 epoch-14: mse-0.316976, rmse-0.563007, r2-0.48569
Valid at fold-1: mse-0.370978
Update best_mse, Valid at fold-1 epoch-14: mse-0.370978, rmse-0.60908, ci--1, r2-0.589087, pearson-0.772978, spearman-0.730025
Traing Log at fold-1 epoch-15: mse-0.305124, rmse-0.552381, r2-0.515853
Valid at fold-1: mse-0.399138
Traing Log at fold-1 epoch-16: mse-0.299675, rmse-0.547426, r2-0.528075
Valid at fold-1: mse-0.369558
Update best_mse, Valid at fold-1 epoch-16: mse-0.369558, rmse-0.607913, ci--1, r2-0.59066, pearson-0.773633, spearman-0.735605
Traing Log at fold-1 epoch-17: mse-0.288584, rmse-0.5372, r2-0.551992
Valid at fold-1: mse-0.360487
Update best_mse, Valid at fold-1 epoch-17: mse-0.360487, rmse-0.600406, ci--1, r2-0.600707, pearson-0.781851, spearman-0.743769
Traing Log at fold-1 epoch-18: mse-0.279246, rmse-0.528438, r2-0.570531
Valid at fold-1: mse-0.360979
Traing Log at fold-1 epoch-19: mse-0.271304, rmse-0.520869, r2-0.5875
Valid at fold-1: mse-0.367327
Traing Log at fold-1 epoch-20: mse-0.265637, rmse-0.5154, r2-0.603394
Valid at fold-1: mse-0.35477
Update best_mse, Valid at fold-1 epoch-20: mse-0.35477, rmse-0.595626, ci--1, r2-0.60704, pearson-0.78127, spearman-0.740669
Traing Log at fold-1 epoch-21: mse-0.256828, rmse-0.506782, r2-0.618274
Valid at fold-1: mse-0.348987
Update best_mse, Valid at fold-1 epoch-21: mse-0.348987, rmse-0.590751, ci--1, r2-0.613445, pearson-0.79019, spearman-0.746522
Traing Log at fold-1 epoch-22: mse-0.253804, rmse-0.50379, r2-0.626129
Valid at fold-1: mse-0.362511
Traing Log at fold-1 epoch-23: mse-0.242898, rmse-0.492847, r2-0.646327
Valid at fold-1: mse-0.359511
Traing Log at fold-1 epoch-24: mse-0.239552, rmse-0.489441, r2-0.654421
Valid at fold-1: mse-0.350059
Traing Log at fold-1 epoch-25: mse-0.232963, rmse-0.482662, r2-0.665438
Valid at fold-1: mse-0.355808
Traing Log at fold-1 epoch-26: mse-0.230067, rmse-0.479653, r2-0.671154
Valid at fold-1: mse-0.364394
Traing Log at fold-1 epoch-27: mse-0.224484, rmse-0.473797, r2-0.683193
Valid at fold-1: mse-0.35754
Traing Log at fold-1 epoch-28: mse-0.215273, rmse-0.463975, r2-0.698156
Valid at fold-1: mse-0.346269
Update best_mse, Valid at fold-1 epoch-28: mse-0.346269, rmse-0.588446, ci--1, r2-0.616456, pearson-0.792488, spearman-0.754449
Traing Log at fold-1 epoch-29: mse-0.211755, rmse-0.460168, r2-0.70592
Valid at fold-1: mse-0.346531
Traing Log at fold-1 epoch-30: mse-0.209581, rmse-0.457801, r2-0.709598
Valid at fold-1: mse-0.339405
Update best_mse, Valid at fold-1 epoch-30: mse-0.339405, rmse-0.582584, ci--1, r2-0.62406, pearson-0.79847, spearman-0.757861
Traing Log at fold-1 epoch-31: mse-0.203268, rmse-0.450853, r2-0.720482
Valid at fold-1: mse-0.339346
Update best_mse, Valid at fold-1 epoch-31: mse-0.339346, rmse-0.582534, ci--1, r2-0.624124, pearson-0.798268, spearman-0.756349
Traing Log at fold-1 epoch-32: mse-0.198624, rmse-0.445672, r2-0.728629
Valid at fold-1: mse-0.341272
Traing Log at fold-1 epoch-33: mse-0.194066, rmse-0.440529, r2-0.736463
Valid at fold-1: mse-0.33885
Update best_mse, Valid at fold-1 epoch-33: mse-0.33885, rmse-0.582108, ci--1, r2-0.624674, pearson-0.798575, spearman-0.755091
Traing Log at fold-1 epoch-34: mse-0.191747, rmse-0.437889, r2-0.740705
Valid at fold-1: mse-0.339805
Traing Log at fold-1 epoch-35: mse-0.186092, rmse-0.431383, r2-0.7501
Valid at fold-1: mse-0.331531
Update best_mse, Valid at fold-1 epoch-35: mse-0.331531, rmse-0.575787, ci--1, r2-0.632781, pearson-0.801396, spearman-0.760989
Traing Log at fold-1 epoch-36: mse-0.18311, rmse-0.427914, r2-0.75528
Valid at fold-1: mse-0.35236
Traing Log at fold-1 epoch-37: mse-0.180082, rmse-0.42436, r2-0.760525
Valid at fold-1: mse-0.352192
Traing Log at fold-1 epoch-38: mse-0.175012, rmse-0.418344, r2-0.768035
Valid at fold-1: mse-0.330772
Update best_mse, Valid at fold-1 epoch-38: mse-0.330772, rmse-0.575128, ci--1, r2-0.633621, pearson-0.806403, spearman-0.767358
Traing Log at fold-1 epoch-39: mse-0.173438, rmse-0.416459, r2-0.770362
Valid at fold-1: mse-0.336475
Traing Log at fold-1 epoch-40: mse-0.167237, rmse-0.408947, r2-0.781501
Valid at fold-1: mse-0.334891
Traing Log at fold-1 epoch-41: mse-0.164393, rmse-0.405455, r2-0.784635
Valid at fold-1: mse-0.342303
Traing Log at fold-1 epoch-42: mse-0.16471, rmse-0.405845, r2-0.785861
Valid at fold-1: mse-0.335191
Traing Log at fold-1 epoch-43: mse-0.159849, rmse-0.399811, r2-0.791797
Valid at fold-1: mse-0.346783
Traing Log at fold-1 epoch-44: mse-0.157406, rmse-0.396745, r2-0.796688
Valid at fold-1: mse-0.329538
Update best_mse, Valid at fold-1 epoch-44: mse-0.329538, rmse-0.574054, ci--1, r2-0.634988, pearson-0.80561, spearman-0.763283
Traing Log at fold-1 epoch-45: mse-0.153878, rmse-0.392272, r2-0.801174
Valid at fold-1: mse-0.335767
Traing Log at fold-1 epoch-46: mse-0.152988, rmse-0.391137, r2-0.803939
Valid at fold-1: mse-0.336417
Traing Log at fold-1 epoch-47: mse-0.149923, rmse-0.387199, r2-0.807781
Valid at fold-1: mse-0.325402
Update best_mse, Valid at fold-1 epoch-47: mse-0.325402, rmse-0.570441, ci--1, r2-0.639569, pearson-0.808952, spearman-0.768956
Traing Log at fold-1 epoch-48: mse-0.147779, rmse-0.38442, r2-0.811167
Valid at fold-1: mse-0.337293
Traing Log at fold-1 epoch-49: mse-0.144308, rmse-0.379879, r2-0.816065
Valid at fold-1: mse-0.332674
Traing Log at fold-1 epoch-50: mse-0.140398, rmse-0.374697, r2-0.822822
Valid at fold-1: mse-0.336991
Traing Log at fold-1 epoch-51: mse-0.137579, rmse-0.370916, r2-0.826283
Valid at fold-1: mse-0.329837
Traing Log at fold-1 epoch-52: mse-0.134197, rmse-0.36633, r2-0.831361
Valid at fold-1: mse-0.336766
Traing Log at fold-1 epoch-53: mse-0.137428, rmse-0.370713, r2-0.82717
Valid at fold-1: mse-0.324669
Update best_mse, Valid at fold-1 epoch-53: mse-0.324669, rmse-0.569797, ci--1, r2-0.640382, pearson-0.810079, spearman-0.772803
Traing Log at fold-1 epoch-54: mse-0.133452, rmse-0.365311, r2-0.832408
Valid at fold-1: mse-0.338505
Traing Log at fold-1 epoch-55: mse-0.131139, rmse-0.362131, r2-0.835871
Valid at fold-1: mse-0.3334
Traing Log at fold-1 epoch-56: mse-0.128067, rmse-0.357865, r2-0.840829
Valid at fold-1: mse-0.32661
Traing Log at fold-1 epoch-57: mse-0.126697, rmse-0.355946, r2-0.842339
Valid at fold-1: mse-0.344305
Traing Log at fold-1 epoch-58: mse-0.125063, rmse-0.353643, r2-0.844641
Valid at fold-1: mse-0.337929
Traing Log at fold-1 epoch-59: mse-0.121525, rmse-0.348604, r2-0.849659
Valid at fold-1: mse-0.327895
Traing Log at fold-1 epoch-60: mse-0.122126, rmse-0.349465, r2-0.849242
Valid at fold-1: mse-0.332379
Traing Log at fold-1 epoch-61: mse-0.119952, rmse-0.346341, r2-0.85182
Valid at fold-1: mse-0.34657
Traing Log at fold-1 epoch-62: mse-0.121036, rmse-0.347903, r2-0.850973
Valid at fold-1: mse-0.335627
Traing Log at fold-1 epoch-63: mse-0.117567, rmse-0.34288, r2-0.855488
Valid at fold-1: mse-0.330847
Traing Log at fold-1 epoch-64: mse-0.113102, rmse-0.336306, r2-0.861977
Valid at fold-1: mse-0.334092
Traing Log at fold-1 epoch-65: mse-0.114973, rmse-0.339077, r2-0.859118
Valid at fold-1: mse-0.330355
Traing Log at fold-1 epoch-66: mse-0.112419, rmse-0.335289, r2-0.862485
Valid at fold-1: mse-0.3312
Traing Log at fold-1 epoch-67: mse-0.110618, rmse-0.332593, r2-0.865052
Valid at fold-1: mse-0.334397
Traing Log at fold-1 epoch-68: mse-0.109609, rmse-0.331072, r2-0.866879
Valid at fold-1: mse-0.333407
Traing Log at fold-1 epoch-69: mse-0.107165, rmse-0.327361, r2-0.869907
Valid at fold-1: mse-0.33069
Traing Log at fold-1 epoch-70: mse-0.107349, rmse-0.327641, r2-0.869862
Valid at fold-1: mse-0.327088
Traing Log at fold-1 epoch-71: mse-0.105665, rmse-0.325061, r2-0.872082
Valid at fold-1: mse-0.329539
Traing Log at fold-1 epoch-72: mse-0.102967, rmse-0.320885, r2-0.875682
Valid at fold-1: mse-0.332019
Traing Log at fold-1 epoch-73: mse-0.100483, rmse-0.316991, r2-0.879031
Valid at fold-1: mse-0.328713
Traing Log at fold-1 epoch-74: mse-0.101205, rmse-0.318127, r2-0.877954
Valid at fold-1: mse-0.328829
Traing stop at epoch-74, model save at-./savemodel/metz-novel-drug-fold1-Nov13_07-19-49.pth
Save log over at ./log/Nov13_07-19-49-metz-novel-drug-fold1.csv

============================================================
Testing fold 1 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-1, mse: 0.511508, rmse: 0.715198, ci: 0.732793, r2: 0.436539, pearson: 0.683569, spearman: 0.624808

Fold 1 results saved to: ./log/Test-metz-novel-drug-fold1-Nov13_07-19-49.csv
============================================================
Training fold 1 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json; uploading history steps 171-171, summary, console lines 187-192
wandb: uploading data
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–„â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–„â–…â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.32467
wandb:  best_valid/pearson 0.81008
wandb:       best_valid/r2 0.64038
wandb:     best_valid/rmse 0.5698
wandb: best_valid/spearman 0.7728
wandb:               epoch 74
wandb:       final_test_ci 0.73279
wandb:      final_test_mse 0.51151
wandb:  final_test_pearson 0.68357
wandb:       final_test_r2 0.43654
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run metz-novel-drug-fold1 at: https://wandb.ai/tringuyen/LLMDTA/runs/jktqtruy
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251113_071950-jktqtruy/logs
Weights & Biases run finished

Training for fold 1 completed successfully.
Python script exit code: 0
==========================================
End Time: Thu Nov 13 11:39:09 AM AEDT 2025
==========================================
