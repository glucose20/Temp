==========================================
Job ID: 2012966
Array Task ID: 4
Node: v100l-f-02
Start Time: Wed Nov 12 04:42:39 PM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Wed Nov 12 16:42:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:07:00.0 Off |                    0 |
| N/A   38C    P0             43W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 4...


============================================================
Starting training for Fold 4
Dataset: davis, Running Set: novel-prot
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 4 --cuda 0 --dataset davis --running_set novel-prot --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 4/4
Dataset: davis-novel-prot
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/davis/davis_drug_pretrain.pkl
Pretrain-./data/davis/davis_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run b35aeo2i
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251112_164248-b35aeo2i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run davis-novel-prot-fold4
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/b35aeo2i
Weights & Biases initialized: LLMDTA
Loading fold 4 data...
  Train: ./data/dta-5fold-dataset/davis/novel-prot/fold_4_train.csv
  Valid: ./data/dta-5fold-dataset/davis/novel-prot/fold_4_valid.csv
  Test:  ./data/dta-5fold-dataset/davis/novel-prot/fold_4_test.csv
Dataset loaded: 19148 train, 4788 valid, 6120 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-4 epoch-1: mse-1.891245, rmse-1.375225, r2--0.226851
Valid at fold-4: mse-1.155479
Update best_mse, Valid at fold-4 epoch-1: mse-1.155479, rmse-1.074932, ci--1, r2--0.443908, pearson-0.498531, spearman-0.452336
Traing Log at fold-4 epoch-2: mse-0.726404, rmse-0.852294, r2--0.191574
Valid at fold-4: mse-1.075053
Update best_mse, Valid at fold-4 epoch-2: mse-1.075053, rmse-1.036848, ci--1, r2--0.343407, pearson-0.599691, spearman-0.521912
Traing Log at fold-4 epoch-3: mse-0.58744, rmse-0.766446, r2--0.066593
Valid at fold-4: mse-0.643051
Update best_mse, Valid at fold-4 epoch-3: mse-0.643051, rmse-0.801905, ci--1, r2-0.196431, pearson-0.644699, spearman-0.549097
Traing Log at fold-4 epoch-4: mse-0.511957, rmse-0.715512, r2-0.018152
Valid at fold-4: mse-0.41635
Update best_mse, Valid at fold-4 epoch-4: mse-0.41635, rmse-0.645252, ci--1, r2-0.479721, pearson-0.702211, spearman-0.588203
Traing Log at fold-4 epoch-5: mse-0.439173, rmse-0.662701, r2-0.142548
Valid at fold-4: mse-0.350087
Update best_mse, Valid at fold-4 epoch-5: mse-0.350087, rmse-0.591682, ci--1, r2-0.562524, pearson-0.752668, spearman-0.629242
Traing Log at fold-4 epoch-6: mse-0.400263, rmse-0.632664, r2-0.209981
Valid at fold-4: mse-0.429234
Traing Log at fold-4 epoch-7: mse-0.36992, rmse-0.608211, r2-0.283485
Valid at fold-4: mse-0.364518
Traing Log at fold-4 epoch-8: mse-0.343068, rmse-0.58572, r2-0.347145
Valid at fold-4: mse-0.31361
Update best_mse, Valid at fold-4 epoch-8: mse-0.31361, rmse-0.560009, ci--1, r2-0.608107, pearson-0.795205, spearman-0.657059
Traing Log at fold-4 epoch-9: mse-0.325579, rmse-0.570596, r2-0.38817
Valid at fold-4: mse-0.329211
Traing Log at fold-4 epoch-10: mse-0.306767, rmse-0.553865, r2-0.445844
Valid at fold-4: mse-0.295421
Update best_mse, Valid at fold-4 epoch-10: mse-0.295421, rmse-0.543527, ci--1, r2-0.630836, pearson-0.795078, spearman-0.658568
Traing Log at fold-4 epoch-11: mse-0.294918, rmse-0.543063, r2-0.468054
Valid at fold-4: mse-0.281994
Update best_mse, Valid at fold-4 epoch-11: mse-0.281994, rmse-0.531031, ci--1, r2-0.647615, pearson-0.807142, spearman-0.660677
Traing Log at fold-4 epoch-12: mse-0.288887, rmse-0.537483, r2-0.48855
Valid at fold-4: mse-0.274151
Update best_mse, Valid at fold-4 epoch-12: mse-0.274151, rmse-0.523595, ci--1, r2-0.657415, pearson-0.812543, spearman-0.654853
Traing Log at fold-4 epoch-13: mse-0.272957, rmse-0.522452, r2-0.521527
Valid at fold-4: mse-0.264995
Update best_mse, Valid at fold-4 epoch-13: mse-0.264995, rmse-0.514777, ci--1, r2-0.668857, pearson-0.818503, spearman-0.67169
Traing Log at fold-4 epoch-14: mse-0.265474, rmse-0.515242, r2-0.543752
Valid at fold-4: mse-0.291925
Traing Log at fold-4 epoch-15: mse-0.257111, rmse-0.507061, r2-0.56142
Valid at fold-4: mse-0.261736
Update best_mse, Valid at fold-4 epoch-15: mse-0.261736, rmse-0.511601, ci--1, r2-0.67293, pearson-0.821847, spearman-0.674742
Traing Log at fold-4 epoch-16: mse-0.24364, rmse-0.493599, r2-0.59354
Valid at fold-4: mse-0.267116
Traing Log at fold-4 epoch-17: mse-0.240651, rmse-0.490562, r2-0.596586
Valid at fold-4: mse-0.264715
Traing Log at fold-4 epoch-18: mse-0.231168, rmse-0.4808, r2-0.619881
Valid at fold-4: mse-0.244466
Update best_mse, Valid at fold-4 epoch-18: mse-0.244466, rmse-0.494435, ci--1, r2-0.694511, pearson-0.836132, spearman-0.681311
Traing Log at fold-4 epoch-19: mse-0.227455, rmse-0.476922, r2-0.629805
Valid at fold-4: mse-0.247473
Traing Log at fold-4 epoch-20: mse-0.215926, rmse-0.464678, r2-0.650872
Valid at fold-4: mse-0.233804
Update best_mse, Valid at fold-4 epoch-20: mse-0.233804, rmse-0.483533, ci--1, r2-0.707834, pearson-0.843035, spearman-0.685443
Traing Log at fold-4 epoch-21: mse-0.208741, rmse-0.456882, r2-0.669109
Valid at fold-4: mse-0.230832
Update best_mse, Valid at fold-4 epoch-21: mse-0.230832, rmse-0.48045, ci--1, r2-0.711548, pearson-0.846469, spearman-0.682921
Traing Log at fold-4 epoch-22: mse-0.203465, rmse-0.451071, r2-0.681155
Valid at fold-4: mse-0.246462
Traing Log at fold-4 epoch-23: mse-0.199147, rmse-0.446259, r2-0.688089
Valid at fold-4: mse-0.245806
Traing Log at fold-4 epoch-24: mse-0.195089, rmse-0.441689, r2-0.69581
Valid at fold-4: mse-0.229948
Update best_mse, Valid at fold-4 epoch-24: mse-0.229948, rmse-0.479529, ci--1, r2-0.712653, pearson-0.848498, spearman-0.680173
Traing Log at fold-4 epoch-25: mse-0.189271, rmse-0.435053, r2-0.70578
Valid at fold-4: mse-0.244116
Traing Log at fold-4 epoch-26: mse-0.186911, rmse-0.432332, r2-0.715814
Valid at fold-4: mse-0.23643
Traing Log at fold-4 epoch-27: mse-0.182072, rmse-0.426699, r2-0.722374
Valid at fold-4: mse-0.22883
Update best_mse, Valid at fold-4 epoch-27: mse-0.22883, rmse-0.478362, ci--1, r2-0.714049, pearson-0.848835, spearman-0.690565
Traing Log at fold-4 epoch-28: mse-0.176001, rmse-0.419524, r2-0.734198
Valid at fold-4: mse-0.2309
Traing Log at fold-4 epoch-29: mse-0.172821, rmse-0.415717, r2-0.740657
Valid at fold-4: mse-0.230428
Traing Log at fold-4 epoch-30: mse-0.169375, rmse-0.411552, r2-0.746837
Valid at fold-4: mse-0.231245
Traing Log at fold-4 epoch-31: mse-0.165528, rmse-0.406851, r2-0.753385
Valid at fold-4: mse-0.235999
Traing Log at fold-4 epoch-32: mse-0.161994, rmse-0.402485, r2-0.760712
Valid at fold-4: mse-0.224296
Update best_mse, Valid at fold-4 epoch-32: mse-0.224296, rmse-0.473599, ci--1, r2-0.719715, pearson-0.852837, spearman-0.689223
Traing Log at fold-4 epoch-33: mse-0.163615, rmse-0.404494, r2-0.758699
Valid at fold-4: mse-0.227533
Traing Log at fold-4 epoch-34: mse-0.156893, rmse-0.396098, r2-0.768671
Valid at fold-4: mse-0.227707
Traing Log at fold-4 epoch-35: mse-0.156316, rmse-0.395368, r2-0.771317
Valid at fold-4: mse-0.216572
Update best_mse, Valid at fold-4 epoch-35: mse-0.216572, rmse-0.465373, ci--1, r2-0.729368, pearson-0.857704, spearman-0.695131
Traing Log at fold-4 epoch-36: mse-0.150923, rmse-0.388488, r2-0.779571
Valid at fold-4: mse-0.212613
Update best_mse, Valid at fold-4 epoch-36: mse-0.212613, rmse-0.4611, ci--1, r2-0.734314, pearson-0.861106, spearman-0.69722
Traing Log at fold-4 epoch-37: mse-0.148593, rmse-0.385477, r2-0.784445
Valid at fold-4: mse-0.207831
Update best_mse, Valid at fold-4 epoch-37: mse-0.207831, rmse-0.455885, ci--1, r2-0.740291, pearson-0.862894, spearman-0.689125
Traing Log at fold-4 epoch-38: mse-0.145404, rmse-0.381319, r2-0.790575
Valid at fold-4: mse-0.212561
Traing Log at fold-4 epoch-39: mse-0.141319, rmse-0.375924, r2-0.797354
Valid at fold-4: mse-0.212688
Traing Log at fold-4 epoch-40: mse-0.139835, rmse-0.373945, r2-0.798859
Valid at fold-4: mse-0.205826
Update best_mse, Valid at fold-4 epoch-40: mse-0.205826, rmse-0.453681, ci--1, r2-0.742795, pearson-0.863014, spearman-0.690185
Traing Log at fold-4 epoch-41: mse-0.135544, rmse-0.368164, r2-0.806871
Valid at fold-4: mse-0.208615
Traing Log at fold-4 epoch-42: mse-0.135438, rmse-0.368019, r2-0.807489
Valid at fold-4: mse-0.230697
Traing Log at fold-4 epoch-43: mse-0.135194, rmse-0.367688, r2-0.807239
Valid at fold-4: mse-0.216487
Traing Log at fold-4 epoch-44: mse-0.132269, rmse-0.363688, r2-0.813285
Valid at fold-4: mse-0.216644
Traing Log at fold-4 epoch-45: mse-0.130504, rmse-0.361253, r2-0.815199
Valid at fold-4: mse-0.218436
Traing Log at fold-4 epoch-46: mse-0.126903, rmse-0.356234, r2-0.821802
Valid at fold-4: mse-0.213683
Traing Log at fold-4 epoch-47: mse-0.126936, rmse-0.356281, r2-0.821606
Valid at fold-4: mse-0.215656
Traing Log at fold-4 epoch-48: mse-0.124576, rmse-0.352953, r2-0.825158
Valid at fold-4: mse-0.202251
Update best_mse, Valid at fold-4 epoch-48: mse-0.202251, rmse-0.449723, ci--1, r2-0.747263, pearson-0.865831, spearman-0.691983
Traing Log at fold-4 epoch-49: mse-0.12105, rmse-0.347922, r2-0.831187
Valid at fold-4: mse-0.231208
Traing Log at fold-4 epoch-50: mse-0.121131, rmse-0.348038, r2-0.830396
Valid at fold-4: mse-0.203938
Traing Log at fold-4 epoch-51: mse-0.118949, rmse-0.34489, r2-0.834982
Valid at fold-4: mse-0.211841
Traing Log at fold-4 epoch-52: mse-0.121245, rmse-0.348203, r2-0.830827
Valid at fold-4: mse-0.198432
Update best_mse, Valid at fold-4 epoch-52: mse-0.198432, rmse-0.445457, ci--1, r2-0.752036, pearson-0.870863, spearman-0.691731
Traing Log at fold-4 epoch-53: mse-0.116644, rmse-0.341532, r2-0.838079
Valid at fold-4: mse-0.206539
Traing Log at fold-4 epoch-54: mse-0.112982, rmse-0.336129, r2-0.84412
Valid at fold-4: mse-0.200121
Traing Log at fold-4 epoch-55: mse-0.113768, rmse-0.337295, r2-0.842619
Valid at fold-4: mse-0.202066
Traing Log at fold-4 epoch-56: mse-0.111078, rmse-0.333284, r2-0.847214
Valid at fold-4: mse-0.207264
Traing Log at fold-4 epoch-57: mse-0.109457, rmse-0.330843, r2-0.849534
Valid at fold-4: mse-0.198377
Update best_mse, Valid at fold-4 epoch-57: mse-0.198377, rmse-0.445395, ci--1, r2-0.752104, pearson-0.869288, spearman-0.697801
Traing Log at fold-4 epoch-58: mse-0.111065, rmse-0.333264, r2-0.847442
Valid at fold-4: mse-0.20139
Traing Log at fold-4 epoch-59: mse-0.105867, rmse-0.325372, r2-0.855007
Valid at fold-4: mse-0.209641
Traing Log at fold-4 epoch-60: mse-0.104274, rmse-0.322915, r2-0.857546
Valid at fold-4: mse-0.20654
Traing Log at fold-4 epoch-61: mse-0.106334, rmse-0.326089, r2-0.854539
Valid at fold-4: mse-0.199137
Traing Log at fold-4 epoch-62: mse-0.105996, rmse-0.32557, r2-0.85503
Valid at fold-4: mse-0.209192
Traing Log at fold-4 epoch-63: mse-0.103415, rmse-0.321582, r2-0.859617
Valid at fold-4: mse-0.206242
Traing Log at fold-4 epoch-64: mse-0.103706, rmse-0.322035, r2-0.858747
Valid at fold-4: mse-0.211376
Traing Log at fold-4 epoch-65: mse-0.101804, rmse-0.319067, r2-0.861629
Valid at fold-4: mse-0.199559
Traing Log at fold-4 epoch-66: mse-0.100787, rmse-0.31747, r2-0.863213
Valid at fold-4: mse-0.21753
Traing Log at fold-4 epoch-67: mse-0.099908, rmse-0.316082, r2-0.864323
Valid at fold-4: mse-0.202431
Traing Log at fold-4 epoch-68: mse-0.098231, rmse-0.313418, r2-0.867206
Valid at fold-4: mse-0.200884
Traing Log at fold-4 epoch-69: mse-0.097736, rmse-0.312628, r2-0.86784
Valid at fold-4: mse-0.200037
Traing Log at fold-4 epoch-70: mse-0.097697, rmse-0.312566, r2-0.867864
Valid at fold-4: mse-0.205188
Traing Log at fold-4 epoch-71: mse-0.097159, rmse-0.311703, r2-0.869022
Valid at fold-4: mse-0.20875
Traing Log at fold-4 epoch-72: mse-0.09722, rmse-0.311802, r2-0.868663
Valid at fold-4: mse-0.217675
Traing Log at fold-4 epoch-73: mse-0.094327, rmse-0.307126, r2-0.873141
Valid at fold-4: mse-0.192516
Update best_mse, Valid at fold-4 epoch-73: mse-0.192516, rmse-0.438767, ci--1, r2-0.759428, pearson-0.87401, spearman-0.695625
Traing Log at fold-4 epoch-74: mse-0.092526, rmse-0.304182, r2-0.876177
Valid at fold-4: mse-0.214154
Traing Log at fold-4 epoch-75: mse-0.093361, rmse-0.30555, r2-0.874014
Valid at fold-4: mse-0.205882
Traing Log at fold-4 epoch-76: mse-0.091387, rmse-0.302303, r2-0.877736
Valid at fold-4: mse-0.199124
Traing Log at fold-4 epoch-77: mse-0.09316, rmse-0.305222, r2-0.874913
Valid at fold-4: mse-0.201508
Traing Log at fold-4 epoch-78: mse-0.08827, rmse-0.297103, r2-0.882376
Valid at fold-4: mse-0.206103
Traing Log at fold-4 epoch-79: mse-0.089536, rmse-0.299226, r2-0.880292
Valid at fold-4: mse-0.204012
Traing Log at fold-4 epoch-80: mse-0.088228, rmse-0.297032, r2-0.882123
Valid at fold-4: mse-0.204553
Traing Log at fold-4 epoch-81: mse-0.087531, rmse-0.295856, r2-0.883209
Valid at fold-4: mse-0.203738
Traing Log at fold-4 epoch-82: mse-0.086886, rmse-0.294764, r2-0.884561
Valid at fold-4: mse-0.200376
Traing Log at fold-4 epoch-83: mse-0.087291, rmse-0.29545, r2-0.88322
Valid at fold-4: mse-0.204945
Traing Log at fold-4 epoch-84: mse-0.085254, rmse-0.291983, r2-0.886609
Valid at fold-4: mse-0.192648
Traing Log at fold-4 epoch-85: mse-0.083321, rmse-0.288654, r2-0.889565
Valid at fold-4: mse-0.214025
Traing Log at fold-4 epoch-86: mse-0.085708, rmse-0.292759, r2-0.88619
Valid at fold-4: mse-0.198751
Traing Log at fold-4 epoch-87: mse-0.082504, rmse-0.287235, r2-0.890691
Valid at fold-4: mse-0.194703
Traing Log at fold-4 epoch-88: mse-0.084884, rmse-0.291349, r2-0.887186
Valid at fold-4: mse-0.200332
Traing Log at fold-4 epoch-89: mse-0.082752, rmse-0.287667, r2-0.890143
Valid at fold-4: mse-0.210248
Traing Log at fold-4 epoch-90: mse-0.080343, rmse-0.283449, r2-0.89383
Valid at fold-4: mse-0.202865
Traing Log at fold-4 epoch-91: mse-0.082194, rmse-0.286694, r2-0.891235
Valid at fold-4: mse-0.198531
Traing Log at fold-4 epoch-92: mse-0.081241, rmse-0.285028, r2-0.892935
Valid at fold-4: mse-0.205358
Traing Log at fold-4 epoch-93: mse-0.079433, rmse-0.281838, r2-0.895198
Valid at fold-4: mse-0.19198
Update best_mse, Valid at fold-4 epoch-93: mse-0.19198, rmse-0.438156, ci--1, r2-0.760098, pearson-0.872551, spearman-0.702332
Traing Log at fold-4 epoch-94: mse-0.079291, rmse-0.281587, r2-0.895362
Valid at fold-4: mse-0.194397
Traing Log at fold-4 epoch-95: mse-0.079291, rmse-0.281586, r2-0.895395
Valid at fold-4: mse-0.195763
Traing Log at fold-4 epoch-96: mse-0.079585, rmse-0.282109, r2-0.894761
Valid at fold-4: mse-0.201586
Traing Log at fold-4 epoch-97: mse-0.079485, rmse-0.281931, r2-0.895156
Valid at fold-4: mse-0.200762
Traing Log at fold-4 epoch-98: mse-0.077999, rmse-0.279283, r2-0.897293
Valid at fold-4: mse-0.206616
Traing Log at fold-4 epoch-99: mse-0.077132, rmse-0.277726, r2-0.898492
Valid at fold-4: mse-0.193849
Traing Log at fold-4 epoch-100: mse-0.076732, rmse-0.277005, r2-0.899116
Valid at fold-4: mse-0.198226
Traing Log at fold-4 epoch-101: mse-0.076985, rmse-0.277461, r2-0.898959
Valid at fold-4: mse-0.19425
Traing Log at fold-4 epoch-102: mse-0.076484, rmse-0.276558, r2-0.8993
Valid at fold-4: mse-0.197426
Traing Log at fold-4 epoch-103: mse-0.076433, rmse-0.276464, r2-0.89949
Valid at fold-4: mse-0.203702
Traing Log at fold-4 epoch-104: mse-0.07497, rmse-0.273807, r2-0.901629
Valid at fold-4: mse-0.200805
Traing Log at fold-4 epoch-105: mse-0.074459, rmse-0.272871, r2-0.90244
Valid at fold-4: mse-0.198105
Traing Log at fold-4 epoch-106: mse-0.075304, rmse-0.274417, r2-0.900774
Valid at fold-4: mse-0.198823
Traing Log at fold-4 epoch-107: mse-0.074343, rmse-0.272658, r2-0.902726
Valid at fold-4: mse-0.190474
Update best_mse, Valid at fold-4 epoch-107: mse-0.190474, rmse-0.436433, ci--1, r2-0.76198, pearson-0.87332, spearman-0.702817
Traing Log at fold-4 epoch-108: mse-0.073604, rmse-0.271301, r2-0.903556
Valid at fold-4: mse-0.201118
Traing Log at fold-4 epoch-109: mse-0.074201, rmse-0.272399, r2-0.903043
Valid at fold-4: mse-0.193909
Traing Log at fold-4 epoch-110: mse-0.072112, rmse-0.268537, r2-0.905336
Valid at fold-4: mse-0.205566
Traing Log at fold-4 epoch-111: mse-0.073721, rmse-0.271516, r2-0.903911
Valid at fold-4: mse-0.198128
Traing Log at fold-4 epoch-112: mse-0.072865, rmse-0.269936, r2-0.904478
Valid at fold-4: mse-0.191838
Traing Log at fold-4 epoch-113: mse-0.073065, rmse-0.270306, r2-0.90454
Valid at fold-4: mse-0.189295
Update best_mse, Valid at fold-4 epoch-113: mse-0.189295, rmse-0.435081, ci--1, r2-0.763453, pearson-0.875334, spearman-0.704912
Traing Log at fold-4 epoch-114: mse-0.072129, rmse-0.268568, r2-0.905425
Valid at fold-4: mse-0.191819
Traing Log at fold-4 epoch-115: mse-0.069745, rmse-0.264093, r2-0.909107
Valid at fold-4: mse-0.194886
Traing Log at fold-4 epoch-116: mse-0.069557, rmse-0.263737, r2-0.909431
Valid at fold-4: mse-0.203745
Traing Log at fold-4 epoch-117: mse-0.070347, rmse-0.265231, r2-0.908007
Valid at fold-4: mse-0.192505
Traing Log at fold-4 epoch-118: mse-0.070783, rmse-0.266051, r2-0.90762
Valid at fold-4: mse-0.192896
Traing Log at fold-4 epoch-119: mse-0.070903, rmse-0.266277, r2-0.907701
Valid at fold-4: mse-0.194025
Traing Log at fold-4 epoch-120: mse-0.069347, rmse-0.263338, r2-0.909414
Valid at fold-4: mse-0.195416
Traing Log at fold-4 epoch-121: mse-0.06849, rmse-0.261707, r2-0.910784
Valid at fold-4: mse-0.192242
Traing Log at fold-4 epoch-122: mse-0.068437, rmse-0.261605, r2-0.911011
Valid at fold-4: mse-0.200021
Traing Log at fold-4 epoch-123: mse-0.068801, rmse-0.262299, r2-0.910673
Valid at fold-4: mse-0.189699
Traing Log at fold-4 epoch-124: mse-0.067944, rmse-0.260661, r2-0.911546
Valid at fold-4: mse-0.189318
Traing Log at fold-4 epoch-125: mse-0.067274, rmse-0.259371, r2-0.912813
Valid at fold-4: mse-0.196382
Traing Log at fold-4 epoch-126: mse-0.067384, rmse-0.259584, r2-0.912294
Valid at fold-4: mse-0.19096
Traing Log at fold-4 epoch-127: mse-0.06543, rmse-0.255794, r2-0.915174
Valid at fold-4: mse-0.191166
Traing Log at fold-4 epoch-128: mse-0.0662, rmse-0.257294, r2-0.914268
Valid at fold-4: mse-0.197643
Traing Log at fold-4 epoch-129: mse-0.066924, rmse-0.258698, r2-0.912871
Valid at fold-4: mse-0.191037
Traing Log at fold-4 epoch-130: mse-0.066902, rmse-0.258654, r2-0.913229
Valid at fold-4: mse-0.189968
Traing Log at fold-4 epoch-131: mse-0.065433, rmse-0.255798, r2-0.915198
Valid at fold-4: mse-0.193918
Traing Log at fold-4 epoch-132: mse-0.064946, rmse-0.254844, r2-0.915696
Valid at fold-4: mse-0.194435
Traing Log at fold-4 epoch-133: mse-0.06697, rmse-0.258786, r2-0.913263
Valid at fold-4: mse-0.190855
Traing Log at fold-4 epoch-134: mse-0.065741, rmse-0.256401, r2-0.91487
Valid at fold-4: mse-0.189768
Traing stop at epoch-134, model save at-./savemodel/davis-novel-prot-fold4-Nov12_16-42-47.pth
Save log over at ./log/Nov12_16-42-47-davis-novel-prot-fold4.csv

============================================================
Testing fold 4 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-4, mse: 0.425451, rmse: 0.652266, ci: 0.7973, r2: 0.394051, pearson: 0.64172, spearman: 0.559086

Fold 4 results saved to: ./log/Test-davis-novel-prot-fold4-Nov12_16-42-47.csv
============================================================
Training fold 4 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading history steps 296-296, summary, console lines 312-317
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–â–ƒâ–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–‚â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–â–ƒâ–„â–…â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.18929
wandb:  best_valid/pearson 0.87533
wandb:       best_valid/r2 0.76345
wandb:     best_valid/rmse 0.43508
wandb: best_valid/spearman 0.70491
wandb:               epoch 134
wandb:       final_test_ci 0.7973
wandb:      final_test_mse 0.42545
wandb:  final_test_pearson 0.64172
wandb:       final_test_r2 0.39405
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run davis-novel-prot-fold4 at: https://wandb.ai/tringuyen/LLMDTA/runs/b35aeo2i
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251112_164248-b35aeo2i/logs
Weights & Biases run finished

Training for fold 4 completed successfully.
Python script exit code: 0
==========================================
End Time: Wed Nov 12 10:55:39 PM AEDT 2025
==========================================
