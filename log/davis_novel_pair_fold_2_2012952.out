==========================================
Job ID: 2012952
Array Task ID: 2
Node: v100l-f-02
Start Time: Wed Nov 12 04:40:39 PM AEDT 2025
==========================================
Activating conda environment...
Conda environment activated: LLMDTA
Checking GPU...
Wed Nov 12 16:40:40 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 565.57.01              Driver Version: 565.57.01      CUDA Version: 12.7     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  Tesla V100-SXM2-32GB           On  |   00000000:06:00.0 Off |                    0 |
| N/A   34C    P0             43W /  300W |       1MiB /  32768MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
Setting environment variables...

Starting training for fold 2...


============================================================
Starting training for Fold 2
Dataset: davis, Running Set: novel-pair
Epochs: 200, Batch Size: 16
============================================================

Executing: python -u code/train.py --fold 2 --cuda 0 --dataset davis --running_set novel-pair --epochs 200 --batch_size 16 --wandb_project LLMDTA
============================================================
Training Fold 2/4
Dataset: davis-novel-pair
Device: cuda (CUDA_VISIBLE_DEVICES=0)
Pretrain-./data/davis/davis_drug_pretrain.pkl
Pretrain-./data/davis/davis_esm_pretrain.pkl
============================================================
wandb: Currently logged in as: tringuyen to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: WARNING Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.
wandb: setting up run ekv2rr40
wandb: Tracking run with wandb version 0.23.0
wandb: Run data is saved locally in /vast/minhtrin/DTA/Temp/wandb/run-20251112_164046-ekv2rr40
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run davis-novel-pair-fold2
wandb: â­ï¸ View project at https://wandb.ai/tringuyen/LLMDTA
wandb: ğŸš€ View run at https://wandb.ai/tringuyen/LLMDTA/runs/ekv2rr40
Weights & Biases initialized: LLMDTA
Loading fold 2 data...
  Train: ./data/dta-5fold-dataset/davis/novel-pair/fold_2_train.csv
  Valid: ./data/dta-5fold-dataset/davis/novel-pair/fold_2_valid.csv
  Test:  ./data/dta-5fold-dataset/davis/novel-pair/fold_2_test.csv
Dataset loaded: 10865 train, 14412 valid, 4779 test samples
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Traing Log at fold-2 epoch-1: mse-2.311657, rmse-1.520413, r2--0.217578
Valid at fold-2: mse-2.063677
Update best_mse, Valid at fold-2 epoch-1: mse-2.063677, rmse-1.43655, ci--1, r2--1.597904, pearson-0.379094, spearman-0.363826
Traing Log at fold-2 epoch-2: mse-0.825081, rmse-0.908339, r2--0.278697
Valid at fold-2: mse-1.893755
Update best_mse, Valid at fold-2 epoch-2: mse-1.893755, rmse-1.376138, ci--1, r2--1.383994, pearson-0.284516, spearman-0.261737
Traing Log at fold-2 epoch-3: mse-0.676419, rmse-0.822447, r2--0.180516
Valid at fold-2: mse-1.82886
Update best_mse, Valid at fold-2 epoch-3: mse-1.82886, rmse-1.352353, ci--1, r2--1.302299, pearson-0.467726, spearman-0.416121
Traing Log at fold-2 epoch-4: mse-0.573557, rmse-0.757335, r2--0.125098
Valid at fold-2: mse-0.994608
Update best_mse, Valid at fold-2 epoch-4: mse-0.994608, rmse-0.9973, ci--1, r2--0.252083, pearson-0.479189, spearman-0.414691
Traing Log at fold-2 epoch-5: mse-0.510804, rmse-0.714706, r2--0.031422
Valid at fold-2: mse-1.061308
Traing Log at fold-2 epoch-6: mse-0.472429, rmse-0.687335, r2-0.015311
Valid at fold-2: mse-0.749156
Update best_mse, Valid at fold-2 epoch-6: mse-0.749156, rmse-0.865538, ci--1, r2-0.056909, pearson-0.587108, spearman-0.478487
Traing Log at fold-2 epoch-7: mse-0.435948, rmse-0.660263, r2-0.090505
Valid at fold-2: mse-0.653461
Update best_mse, Valid at fold-2 epoch-7: mse-0.653461, rmse-0.808369, ci--1, r2-0.177377, pearson-0.55623, spearman-0.450687
Traing Log at fold-2 epoch-8: mse-0.390824, rmse-0.625159, r2-0.143088
Valid at fold-2: mse-0.624424
Update best_mse, Valid at fold-2 epoch-8: mse-0.624424, rmse-0.790205, ci--1, r2-0.213931, pearson-0.615697, spearman-0.525043
Traing Log at fold-2 epoch-9: mse-0.363957, rmse-0.603289, r2-0.209595
Valid at fold-2: mse-0.504617
Update best_mse, Valid at fold-2 epoch-9: mse-0.504617, rmse-0.710364, ci--1, r2-0.364753, pearson-0.625803, spearman-0.506659
Traing Log at fold-2 epoch-10: mse-0.352115, rmse-0.593393, r2-0.236555
Valid at fold-2: mse-0.525284
Traing Log at fold-2 epoch-11: mse-0.332529, rmse-0.576653, r2-0.283768
Valid at fold-2: mse-0.54003
Traing Log at fold-2 epoch-12: mse-0.316619, rmse-0.562689, r2-0.316084
Valid at fold-2: mse-0.509218
Traing Log at fold-2 epoch-13: mse-0.301739, rmse-0.549308, r2-0.367733
Valid at fold-2: mse-0.475006
Update best_mse, Valid at fold-2 epoch-13: mse-0.475006, rmse-0.689207, ci--1, r2-0.402029, pearson-0.642528, spearman-0.50266
Traing Log at fold-2 epoch-14: mse-0.287925, rmse-0.536586, r2-0.400996
Valid at fold-2: mse-0.457789
Update best_mse, Valid at fold-2 epoch-14: mse-0.457789, rmse-0.676601, ci--1, r2-0.423703, pearson-0.655787, spearman-0.538481
Traing Log at fold-2 epoch-15: mse-0.272478, rmse-0.521994, r2-0.439291
Valid at fold-2: mse-0.463297
Traing Log at fold-2 epoch-16: mse-0.266431, rmse-0.516169, r2-0.460275
Valid at fold-2: mse-0.494445
Traing Log at fold-2 epoch-17: mse-0.258699, rmse-0.508625, r2-0.476775
Valid at fold-2: mse-0.44562
Update best_mse, Valid at fold-2 epoch-17: mse-0.44562, rmse-0.667548, ci--1, r2-0.439022, pearson-0.673041, spearman-0.528327
Traing Log at fold-2 epoch-18: mse-0.249487, rmse-0.499487, r2-0.507177
Valid at fold-2: mse-0.44891
Traing Log at fold-2 epoch-19: mse-0.235636, rmse-0.485424, r2-0.538292
Valid at fold-2: mse-0.439319
Update best_mse, Valid at fold-2 epoch-19: mse-0.439319, rmse-0.662811, ci--1, r2-0.446954, pearson-0.673385, spearman-0.536803
Traing Log at fold-2 epoch-20: mse-0.230502, rmse-0.480106, r2-0.558464
Valid at fold-2: mse-0.424926
Update best_mse, Valid at fold-2 epoch-20: mse-0.424926, rmse-0.651863, ci--1, r2-0.465073, pearson-0.684745, spearman-0.543189
Traing Log at fold-2 epoch-21: mse-0.223411, rmse-0.472664, r2-0.574032
Valid at fold-2: mse-0.417137
Update best_mse, Valid at fold-2 epoch-21: mse-0.417137, rmse-0.645862, ci--1, r2-0.474878, pearson-0.692359, spearman-0.548573
Traing Log at fold-2 epoch-22: mse-0.216427, rmse-0.465217, r2-0.589776
Valid at fold-2: mse-0.410582
Update best_mse, Valid at fold-2 epoch-22: mse-0.410582, rmse-0.640767, ci--1, r2-0.48313, pearson-0.699684, spearman-0.549134
Traing Log at fold-2 epoch-23: mse-0.212445, rmse-0.460917, r2-0.602724
Valid at fold-2: mse-0.415274
Traing Log at fold-2 epoch-24: mse-0.203194, rmse-0.450771, r2-0.628387
Valid at fold-2: mse-0.408227
Update best_mse, Valid at fold-2 epoch-24: mse-0.408227, rmse-0.638927, ci--1, r2-0.486095, pearson-0.702342, spearman-0.556505
Traing Log at fold-2 epoch-25: mse-0.191098, rmse-0.437148, r2-0.656044
Valid at fold-2: mse-0.412773
Traing Log at fold-2 epoch-26: mse-0.194156, rmse-0.440632, r2-0.649786
Valid at fold-2: mse-0.393985
Update best_mse, Valid at fold-2 epoch-26: mse-0.393985, rmse-0.627683, ci--1, r2-0.504023, pearson-0.710324, spearman-0.561026
Traing Log at fold-2 epoch-27: mse-0.184355, rmse-0.429366, r2-0.66898
Valid at fold-2: mse-0.416556
Traing Log at fold-2 epoch-28: mse-0.181792, rmse-0.426371, r2-0.679416
Valid at fold-2: mse-0.417801
Traing Log at fold-2 epoch-29: mse-0.174171, rmse-0.417338, r2-0.691758
Valid at fold-2: mse-0.411771
Traing Log at fold-2 epoch-30: mse-0.174598, rmse-0.417849, r2-0.693303
Valid at fold-2: mse-0.403049
Traing Log at fold-2 epoch-31: mse-0.16588, rmse-0.407284, r2-0.715047
Valid at fold-2: mse-0.385636
Update best_mse, Valid at fold-2 epoch-31: mse-0.385636, rmse-0.620996, ci--1, r2-0.514534, pearson-0.72215, spearman-0.587151
Traing Log at fold-2 epoch-32: mse-0.16769, rmse-0.4095, r2-0.709469
Valid at fold-2: mse-0.398141
Traing Log at fold-2 epoch-33: mse-0.163491, rmse-0.40434, r2-0.719769
Valid at fold-2: mse-0.385851
Traing Log at fold-2 epoch-34: mse-0.156017, rmse-0.394989, r2-0.732028
Valid at fold-2: mse-0.385236
Update best_mse, Valid at fold-2 epoch-34: mse-0.385236, rmse-0.620673, ci--1, r2-0.515038, pearson-0.724272, spearman-0.582893
Traing Log at fold-2 epoch-35: mse-0.148632, rmse-0.385528, r2-0.748579
Valid at fold-2: mse-0.381516
Update best_mse, Valid at fold-2 epoch-35: mse-0.381516, rmse-0.61767, ci--1, r2-0.51972, pearson-0.724601, spearman-0.580715
Traing Log at fold-2 epoch-36: mse-0.148088, rmse-0.384822, r2-0.751746
Valid at fold-2: mse-0.396672
Traing Log at fold-2 epoch-37: mse-0.150229, rmse-0.387594, r2-0.746103
Valid at fold-2: mse-0.394365
Traing Log at fold-2 epoch-38: mse-0.141912, rmse-0.376712, r2-0.764929
Valid at fold-2: mse-0.378089
Update best_mse, Valid at fold-2 epoch-38: mse-0.378089, rmse-0.61489, ci--1, r2-0.524034, pearson-0.724763, spearman-0.587197
Traing Log at fold-2 epoch-39: mse-0.139335, rmse-0.373276, r2-0.768638
Valid at fold-2: mse-0.384768
Traing Log at fold-2 epoch-40: mse-0.138014, rmse-0.371502, r2-0.772298
Valid at fold-2: mse-0.394807
Traing Log at fold-2 epoch-41: mse-0.13486, rmse-0.367233, r2-0.777182
Valid at fold-2: mse-0.39302
Traing Log at fold-2 epoch-42: mse-0.132535, rmse-0.364054, r2-0.783494
Valid at fold-2: mse-0.392699
Traing Log at fold-2 epoch-43: mse-0.131566, rmse-0.36272, r2-0.783114
Valid at fold-2: mse-0.399781
Traing Log at fold-2 epoch-44: mse-0.130382, rmse-0.361085, r2-0.788151
Valid at fold-2: mse-0.376712
Update best_mse, Valid at fold-2 epoch-44: mse-0.376712, rmse-0.613769, ci--1, r2-0.525768, pearson-0.729492, spearman-0.589136
Traing Log at fold-2 epoch-45: mse-0.125171, rmse-0.353795, r2-0.796678
Valid at fold-2: mse-0.386854
Traing Log at fold-2 epoch-46: mse-0.123957, rmse-0.352075, r2-0.799209
Valid at fold-2: mse-0.382116
Traing Log at fold-2 epoch-47: mse-0.123587, rmse-0.35155, r2-0.801072
Valid at fold-2: mse-0.376801
Traing Log at fold-2 epoch-48: mse-0.122662, rmse-0.350232, r2-0.803207
Valid at fold-2: mse-0.37208
Update best_mse, Valid at fold-2 epoch-48: mse-0.37208, rmse-0.609983, ci--1, r2-0.5316, pearson-0.737281, spearman-0.607259
Traing Log at fold-2 epoch-49: mse-0.118304, rmse-0.343954, r2-0.812268
Valid at fold-2: mse-0.373891
Traing Log at fold-2 epoch-50: mse-0.11745, rmse-0.34271, r2-0.811609
Valid at fold-2: mse-0.373677
Traing Log at fold-2 epoch-51: mse-0.117304, rmse-0.342497, r2-0.812681
Valid at fold-2: mse-0.36702
Update best_mse, Valid at fold-2 epoch-51: mse-0.36702, rmse-0.605822, ci--1, r2-0.537969, pearson-0.736633, spearman-0.611804
Traing Log at fold-2 epoch-52: mse-0.113481, rmse-0.336869, r2-0.818378
Valid at fold-2: mse-0.362481
Update best_mse, Valid at fold-2 epoch-52: mse-0.362481, rmse-0.602064, ci--1, r2-0.543684, pearson-0.745936, spearman-0.600652
Traing Log at fold-2 epoch-53: mse-0.113847, rmse-0.337412, r2-0.819464
Valid at fold-2: mse-0.369701
Traing Log at fold-2 epoch-54: mse-0.11391, rmse-0.337506, r2-0.819224
Valid at fold-2: mse-0.373903
Traing Log at fold-2 epoch-55: mse-0.105647, rmse-0.325034, r2-0.83364
Valid at fold-2: mse-0.364199
Traing Log at fold-2 epoch-56: mse-0.106674, rmse-0.32661, r2-0.83166
Valid at fold-2: mse-0.369796
Traing Log at fold-2 epoch-57: mse-0.1065, rmse-0.326344, r2-0.832829
Valid at fold-2: mse-0.374822
Traing Log at fold-2 epoch-58: mse-0.107402, rmse-0.327723, r2-0.831392
Valid at fold-2: mse-0.372643
Traing Log at fold-2 epoch-59: mse-0.103847, rmse-0.322253, r2-0.837888
Valid at fold-2: mse-0.360581
Update best_mse, Valid at fold-2 epoch-59: mse-0.360581, rmse-0.600484, ci--1, r2-0.546075, pearson-0.742078, spearman-0.613592
Traing Log at fold-2 epoch-60: mse-0.103778, rmse-0.322147, r2-0.837085
Valid at fold-2: mse-0.36461
Traing Log at fold-2 epoch-61: mse-0.100962, rmse-0.317745, r2-0.843022
Valid at fold-2: mse-0.363549
Traing Log at fold-2 epoch-62: mse-0.101363, rmse-0.318376, r2-0.842095
Valid at fold-2: mse-0.372028
Traing Log at fold-2 epoch-63: mse-0.098087, rmse-0.313188, r2-0.847383
Valid at fold-2: mse-0.363994
Traing Log at fold-2 epoch-64: mse-0.10143, rmse-0.318481, r2-0.842348
Valid at fold-2: mse-0.365279
Traing Log at fold-2 epoch-65: mse-0.09939, rmse-0.315262, r2-0.845857
Valid at fold-2: mse-0.362957
Traing Log at fold-2 epoch-66: mse-0.097377, rmse-0.312052, r2-0.84886
Valid at fold-2: mse-0.368393
Traing Log at fold-2 epoch-67: mse-0.096549, rmse-0.310724, r2-0.851281
Valid at fold-2: mse-0.367451
Traing Log at fold-2 epoch-68: mse-0.095483, rmse-0.309003, r2-0.851546
Valid at fold-2: mse-0.369132
Traing Log at fold-2 epoch-69: mse-0.09347, rmse-0.305728, r2-0.856119
Valid at fold-2: mse-0.368363
Traing Log at fold-2 epoch-70: mse-0.094214, rmse-0.306944, r2-0.854677
Valid at fold-2: mse-0.366389
Traing Log at fold-2 epoch-71: mse-0.092853, rmse-0.304718, r2-0.857479
Valid at fold-2: mse-0.368816
Traing Log at fold-2 epoch-72: mse-0.091432, rmse-0.302378, r2-0.860119
Valid at fold-2: mse-0.355038
Update best_mse, Valid at fold-2 epoch-72: mse-0.355038, rmse-0.59585, ci--1, r2-0.553053, pearson-0.746668, spearman-0.620958
Traing Log at fold-2 epoch-73: mse-0.091662, rmse-0.302757, r2-0.858454
Valid at fold-2: mse-0.366787
Traing Log at fold-2 epoch-74: mse-0.088971, rmse-0.298281, r2-0.863653
Valid at fold-2: mse-0.358561
Traing Log at fold-2 epoch-75: mse-0.087386, rmse-0.295612, r2-0.866838
Valid at fold-2: mse-0.358778
Traing Log at fold-2 epoch-76: mse-0.08785, rmse-0.296395, r2-0.865862
Valid at fold-2: mse-0.353401
Update best_mse, Valid at fold-2 epoch-76: mse-0.353401, rmse-0.594475, ci--1, r2-0.555114, pearson-0.748846, spearman-0.626633
Traing Log at fold-2 epoch-77: mse-0.086088, rmse-0.293408, r2-0.868433
Valid at fold-2: mse-0.363501
Traing Log at fold-2 epoch-78: mse-0.086396, rmse-0.293933, r2-0.86906
Valid at fold-2: mse-0.358722
Traing Log at fold-2 epoch-79: mse-0.081351, rmse-0.285221, r2-0.875982
Valid at fold-2: mse-0.358286
Traing Log at fold-2 epoch-80: mse-0.082402, rmse-0.287058, r2-0.874568
Valid at fold-2: mse-0.358457
Traing Log at fold-2 epoch-81: mse-0.082993, rmse-0.288084, r2-0.874879
Valid at fold-2: mse-0.368734
Traing Log at fold-2 epoch-82: mse-0.082534, rmse-0.287287, r2-0.874962
Valid at fold-2: mse-0.355026
Traing Log at fold-2 epoch-83: mse-0.080477, rmse-0.283685, r2-0.878684
Valid at fold-2: mse-0.360628
Traing Log at fold-2 epoch-84: mse-0.082673, rmse-0.28753, r2-0.874274
Valid at fold-2: mse-0.34787
Update best_mse, Valid at fold-2 epoch-84: mse-0.34787, rmse-0.589805, ci--1, r2-0.562076, pearson-0.752288, spearman-0.622155
Traing Log at fold-2 epoch-85: mse-0.080527, rmse-0.283772, r2-0.878091
Valid at fold-2: mse-0.366805
Traing Log at fold-2 epoch-86: mse-0.08156, rmse-0.285588, r2-0.876012
Valid at fold-2: mse-0.367156
Traing Log at fold-2 epoch-87: mse-0.079842, rmse-0.282563, r2-0.879947
Valid at fold-2: mse-0.353743
Traing Log at fold-2 epoch-88: mse-0.080227, rmse-0.283244, r2-0.878765
Valid at fold-2: mse-0.356193
Traing Log at fold-2 epoch-89: mse-0.078357, rmse-0.279923, r2-0.882022
Valid at fold-2: mse-0.359651
Traing Log at fold-2 epoch-90: mse-0.077661, rmse-0.278677, r2-0.883257
Valid at fold-2: mse-0.341339
Update best_mse, Valid at fold-2 epoch-90: mse-0.341339, rmse-0.584242, ci--1, r2-0.570298, pearson-0.75654, spearman-0.634194
Traing Log at fold-2 epoch-91: mse-0.078678, rmse-0.280495, r2-0.881062
Valid at fold-2: mse-0.348876
Traing Log at fold-2 epoch-92: mse-0.077385, rmse-0.278181, r2-0.883342
Valid at fold-2: mse-0.345618
Traing Log at fold-2 epoch-93: mse-0.074932, rmse-0.273737, r2-0.887535
Valid at fold-2: mse-0.351549
Traing Log at fold-2 epoch-94: mse-0.077387, rmse-0.278185, r2-0.883416
Valid at fold-2: mse-0.356316
Traing Log at fold-2 epoch-95: mse-0.073197, rmse-0.27055, r2-0.891174
Valid at fold-2: mse-0.3491
Traing Log at fold-2 epoch-96: mse-0.074747, rmse-0.273399, r2-0.88811
Valid at fold-2: mse-0.355331
Traing Log at fold-2 epoch-97: mse-0.072, rmse-0.268327, r2-0.892275
Valid at fold-2: mse-0.371133
Traing Log at fold-2 epoch-98: mse-0.07355, rmse-0.271202, r2-0.890349
Valid at fold-2: mse-0.374842
Traing Log at fold-2 epoch-99: mse-0.072446, rmse-0.269158, r2-0.891292
Valid at fold-2: mse-0.355403
Traing Log at fold-2 epoch-100: mse-0.071383, rmse-0.267176, r2-0.893148
Valid at fold-2: mse-0.360233
Traing Log at fold-2 epoch-101: mse-0.072498, rmse-0.269254, r2-0.891464
Valid at fold-2: mse-0.360336
Traing Log at fold-2 epoch-102: mse-0.075348, rmse-0.274496, r2-0.887579
Valid at fold-2: mse-0.342599
Traing Log at fold-2 epoch-103: mse-0.073419, rmse-0.270959, r2-0.889802
Valid at fold-2: mse-0.360635
Traing Log at fold-2 epoch-104: mse-0.068367, rmse-0.26147, r2-0.898592
Valid at fold-2: mse-0.372151
Traing Log at fold-2 epoch-105: mse-0.069571, rmse-0.263764, r2-0.896616
Valid at fold-2: mse-0.347173
Traing Log at fold-2 epoch-106: mse-0.071979, rmse-0.268289, r2-0.89281
Valid at fold-2: mse-0.340695
Update best_mse, Valid at fold-2 epoch-106: mse-0.340695, rmse-0.58369, ci--1, r2-0.571109, pearson-0.759235, spearman-0.637165
Traing Log at fold-2 epoch-107: mse-0.067086, rmse-0.25901, r2-0.900211
Valid at fold-2: mse-0.352201
Traing Log at fold-2 epoch-108: mse-0.071338, rmse-0.267092, r2-0.893595
Valid at fold-2: mse-0.350074
Traing Log at fold-2 epoch-109: mse-0.069334, rmse-0.263314, r2-0.897059
Valid at fold-2: mse-0.345452
Traing Log at fold-2 epoch-110: mse-0.067845, rmse-0.26047, r2-0.899402
Valid at fold-2: mse-0.337883
Update best_mse, Valid at fold-2 epoch-110: mse-0.337883, rmse-0.581277, ci--1, r2-0.574649, pearson-0.758952, spearman-0.635788
Traing Log at fold-2 epoch-111: mse-0.067469, rmse-0.259748, r2-0.899737
Valid at fold-2: mse-0.356275
Traing Log at fold-2 epoch-112: mse-0.0679, rmse-0.260576, r2-0.899214
Valid at fold-2: mse-0.351313
Traing Log at fold-2 epoch-113: mse-0.066907, rmse-0.258664, r2-0.90086
Valid at fold-2: mse-0.355057
Traing Log at fold-2 epoch-114: mse-0.068892, rmse-0.262474, r2-0.897424
Valid at fold-2: mse-0.348167
Traing Log at fold-2 epoch-115: mse-0.06706, rmse-0.258959, r2-0.900786
Valid at fold-2: mse-0.348233
Traing Log at fold-2 epoch-116: mse-0.064691, rmse-0.254344, r2-0.904494
Valid at fold-2: mse-0.354089
Traing Log at fold-2 epoch-117: mse-0.064387, rmse-0.253747, r2-0.904964
Valid at fold-2: mse-0.341736
Traing Log at fold-2 epoch-118: mse-0.066066, rmse-0.257034, r2-0.902042
Valid at fold-2: mse-0.356598
Traing Log at fold-2 epoch-119: mse-0.065035, rmse-0.25502, r2-0.903878
Valid at fold-2: mse-0.353827
Traing Log at fold-2 epoch-120: mse-0.064612, rmse-0.254189, r2-0.904678
Valid at fold-2: mse-0.355598
Traing Log at fold-2 epoch-121: mse-0.064051, rmse-0.253084, r2-0.905284
Valid at fold-2: mse-0.345295
Traing Log at fold-2 epoch-122: mse-0.063068, rmse-0.251134, r2-0.906876
Valid at fold-2: mse-0.338961
Traing Log at fold-2 epoch-123: mse-0.063728, rmse-0.252443, r2-0.905636
Valid at fold-2: mse-0.353879
Traing Log at fold-2 epoch-124: mse-0.063849, rmse-0.252683, r2-0.906528
Valid at fold-2: mse-0.344631
Traing Log at fold-2 epoch-125: mse-0.060496, rmse-0.245959, r2-0.910311
Valid at fold-2: mse-0.35811
Traing Log at fold-2 epoch-126: mse-0.062319, rmse-0.249637, r2-0.908546
Valid at fold-2: mse-0.35504
Traing Log at fold-2 epoch-127: mse-0.06135, rmse-0.24769, r2-0.909804
Valid at fold-2: mse-0.346425
Traing Log at fold-2 epoch-128: mse-0.062308, rmse-0.249616, r2-0.908704
Valid at fold-2: mse-0.343449
Traing Log at fold-2 epoch-129: mse-0.061423, rmse-0.247836, r2-0.909059
Valid at fold-2: mse-0.352068
Traing Log at fold-2 epoch-130: mse-0.061638, rmse-0.248271, r2-0.910077
Valid at fold-2: mse-0.347878
Traing Log at fold-2 epoch-131: mse-0.062482, rmse-0.249965, r2-0.907844
Valid at fold-2: mse-0.341119
Traing stop at epoch-131, model save at-./savemodel/davis-novel-pair-fold2-Nov12_16-40-46.pth
Save log over at ./log/Nov12_16-40-46-davis-novel-pair-fold2.csv

============================================================
Testing fold 2 with best model...
============================================================
/home/minhtrin/.conda/envs/LLMDTA/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.
  WeightNorm.apply(module, name, dim)
Test at fold-2, mse: 0.650169, rmse: 0.80633, ci: 0.710149, r2: 0.252304, pearson: 0.502302, spearman: 0.411809

Fold 2 results saved to: ./log/Test-davis-novel-pair-fold2-Nov12_16-40-46.csv
============================================================
Training fold 2 completed successfully!
============================================================
wandb: updating run metadata
wandb: uploading output.log; uploading wandb-summary.json
wandb: uploading config.yaml; uploading history steps 294-294, summary, console lines 310-315
wandb: uploading data
wandb: 
wandb: Run history:
wandb:      best_valid/mse â–ˆâ–‡â–‡â–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  best_valid/pearson â–‚â–â–„â–„â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:       best_valid/r2 â–â–‚â–‚â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:     best_valid/rmse â–ˆâ–ˆâ–‡â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: best_valid/spearman â–ƒâ–â–„â–„â–…â–…â–†â–†â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:               epoch â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:             test/ci â–
wandb:            test/mse â–
wandb:        test/pearson â–
wandb:             test/r2 â–
wandb:                 +13 ...
wandb: 
wandb: Run summary:
wandb:      best_valid/mse 0.33788
wandb:  best_valid/pearson 0.75895
wandb:       best_valid/r2 0.57465
wandb:     best_valid/rmse 0.58128
wandb: best_valid/spearman 0.63579
wandb:               epoch 131
wandb:       final_test_ci 0.71015
wandb:      final_test_mse 0.65017
wandb:  final_test_pearson 0.5023
wandb:       final_test_r2 0.2523
wandb:                 +19 ...
wandb: 
wandb: ğŸš€ View run davis-novel-pair-fold2 at: https://wandb.ai/tringuyen/LLMDTA/runs/ekv2rr40
wandb: â­ï¸ View project at: https://wandb.ai/tringuyen/LLMDTA
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20251112_164046-ekv2rr40/logs
Weights & Biases run finished

Training for fold 2 completed successfully.
Python script exit code: 0
==========================================
End Time: Wed Nov 12 10:42:20 PM AEDT 2025
==========================================
